[02/26 20:40:15] detectron2 INFO: Rank of current process: 0. World size: 1
[02/26 20:40:15] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/26 20:40:15] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/26 20:40:15] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/26 20:40:15] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/26 20:40:15] detectron2 INFO: Full config saved to ./output/config.yaml
[02/26 20:40:15] d2.utils.env INFO: Using a generated random seed 15784744
[02/26 20:40:17] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/26 20:40:20] d2.data.datasets.coco INFO: Loading /media/nahyun/HDD//data_100/instances_train.json takes 2.82 seconds.
[02/26 20:40:20] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 20:40:20] d2.data.datasets.coco INFO: Loaded 19191 images in COCO format from /media/nahyun/HDD//data_100/instances_train.json
[02/26 20:40:21] d2.data.build INFO: Removed 0 images with no usable annotations. 19191 images left.
[02/26 20:40:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/26 20:40:21] d2.data.build INFO: Using training sampler TrainingSampler
[02/26 20:40:21] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 20:40:21] d2.data.common INFO: Serializing 19191 elements to byte tensors and concatenating them all ...
[02/26 20:40:22] d2.data.common INFO: Serialized dataset takes 80.55 MiB
[02/26 20:40:22] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/26 20:40:22] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 20:40:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/nahyun/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 20:40:22] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/26 20:40:22] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[02/26 20:40:22] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[02/26 20:40:22] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[02/26 20:40:22] d2.engine.train_loop INFO: Starting training from iteration 0
[02/26 20:40:45] d2.utils.events INFO:  eta: 1:09:46  iter: 19  total_loss: 2.878  loss_cls: 1.785  loss_box_reg: 1.092  time: 1.0265  last_time: 0.9618  data_time: 0.1988  last_data_time: 0.1555   lr: 0.00019981  max_mem: 21308M
[02/26 20:41:05] d2.utils.events INFO:  eta: 1:09:41  iter: 39  total_loss: 1.882  loss_cls: 1.181  loss_box_reg: 0.6975  time: 1.0062  last_time: 0.9172  data_time: 0.1854  last_data_time: 0.1555   lr: 0.00039961  max_mem: 21308M
[02/26 20:41:25] d2.utils.events INFO:  eta: 1:09:20  iter: 59  total_loss: 1.86  loss_cls: 1.179  loss_box_reg: 0.6767  time: 0.9964  last_time: 1.0006  data_time: 0.1673  last_data_time: 0.1892   lr: 0.00059941  max_mem: 21308M
[02/26 20:41:44] d2.utils.events INFO:  eta: 1:09:00  iter: 79  total_loss: 1.769  loss_cls: 1.13  loss_box_reg: 0.6374  time: 0.9937  last_time: 0.9924  data_time: 0.1791  last_data_time: 0.1806   lr: 0.00079921  max_mem: 21308M
[02/26 20:42:04] d2.utils.events INFO:  eta: 1:08:35  iter: 99  total_loss: 1.781  loss_cls: 1.151  loss_box_reg: 0.6322  time: 0.9893  last_time: 1.0292  data_time: 0.1633  last_data_time: 0.2170   lr: 0.00099901  max_mem: 21308M
[02/26 20:42:23] d2.utils.events INFO:  eta: 1:07:57  iter: 119  total_loss: 1.752  loss_cls: 1.133  loss_box_reg: 0.6199  time: 0.9855  last_time: 0.9377  data_time: 0.1544  last_data_time: 0.1230   lr: 0.0011988  max_mem: 21308M
[02/26 20:42:34] d2.engine.hooks INFO: Overall training speed: 128 iterations in 0:02:06 (0.9912 s / it)
[02/26 20:42:34] d2.engine.hooks INFO: Total training time: 0:02:06 (0:00:00 on hooks)
[02/26 20:42:34] d2.utils.events INFO:  eta: 1:07:43  iter: 130  total_loss: 1.764  loss_cls: 1.147  loss_box_reg: 0.6236  time: 0.9838  last_time: 0.9794  data_time: 0.1471  last_data_time: 0.1644   lr: 0.0012987  max_mem: 21308M
[02/26 20:44:06] detectron2 INFO: Rank of current process: 0. World size: 1
[02/26 20:44:07] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/26 20:44:07] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/26 20:44:07] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/26 20:44:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/26 20:44:07] detectron2 INFO: Full config saved to ./output/config.yaml
[02/26 20:44:07] d2.utils.env INFO: Using a generated random seed 7327271
[02/26 20:44:08] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/26 20:44:10] d2.data.datasets.coco INFO: Loading /media/nahyun/HDD//data_100/instances_train.json takes 2.23 seconds.
[02/26 20:44:10] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 20:44:10] d2.data.datasets.coco INFO: Loaded 19191 images in COCO format from /media/nahyun/HDD//data_100/instances_train.json
[02/26 20:44:12] d2.data.build INFO: Removed 0 images with no usable annotations. 19191 images left.
[02/26 20:44:12] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/26 20:44:12] d2.data.build INFO: Using training sampler TrainingSampler
[02/26 20:44:12] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 20:44:12] d2.data.common INFO: Serializing 19191 elements to byte tensors and concatenating them all ...
[02/26 20:44:12] d2.data.common INFO: Serialized dataset takes 80.55 MiB
[02/26 20:44:12] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/26 20:44:12] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl ...
[02/26 20:44:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/nahyun/.torch/iopath_cache/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl ...
[02/26 20:44:13] fvcore.common.checkpoint INFO: Reading a file from 'Detectron2 Model Zoo'
[02/26 20:44:13] fvcore.common.checkpoint WARNING: Skip loading parameter 'head.cls_score.weight' to the model due to incompatible shapes: (720, 256, 3, 3) in the checkpoint but (900, 256, 3, 3) in the model! You might want to double check if this is expected.
[02/26 20:44:13] fvcore.common.checkpoint WARNING: Skip loading parameter 'head.cls_score.bias' to the model due to incompatible shapes: (720,) in the checkpoint but (900,) in the model! You might want to double check if this is expected.
[02/26 20:44:13] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mhead.cls_score.{bias, weight}[0m
[02/26 20:44:13] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mpixel_mean[0m
  [35mpixel_std[0m
[02/26 20:44:13] d2.engine.train_loop INFO: Starting training from iteration 0
[02/26 20:44:34] d2.utils.events INFO:  eta: 1:07:57  iter: 19  total_loss: 2.17  loss_cls: 1.793  loss_box_reg: 0.379  time: 0.9955  last_time: 0.9267  data_time: 0.1551  last_data_time: 0.1163   lr: 0.00019981  max_mem: 21301M
[02/26 20:44:53] d2.utils.events INFO:  eta: 1:07:38  iter: 39  total_loss: 1.424  loss_cls: 1.201  loss_box_reg: 0.2248  time: 0.9753  last_time: 0.9871  data_time: 0.1490  last_data_time: 0.2190   lr: 0.00039961  max_mem: 21301M
[02/26 20:45:12] d2.utils.events INFO:  eta: 1:07:25  iter: 59  total_loss: 1.354  loss_cls: 1.143  loss_box_reg: 0.2054  time: 0.9698  last_time: 0.9610  data_time: 0.1493  last_data_time: 0.1461   lr: 0.00059941  max_mem: 21301M
[02/26 20:45:31] d2.utils.events INFO:  eta: 1:07:06  iter: 79  total_loss: 1.325  loss_cls: 1.123  loss_box_reg: 0.1967  time: 0.9652  last_time: 0.9729  data_time: 0.1419  last_data_time: 0.1574   lr: 0.00079921  max_mem: 21301M
[02/26 20:45:50] d2.utils.events INFO:  eta: 1:06:47  iter: 99  total_loss: 1.266  loss_cls: 1.063  loss_box_reg: 0.1974  time: 0.9636  last_time: 0.9572  data_time: 0.1453  last_data_time: 0.1890   lr: 0.00099901  max_mem: 21301M
[02/26 20:46:09] d2.utils.events INFO:  eta: 1:06:15  iter: 119  total_loss: 1.153  loss_cls: 0.9687  loss_box_reg: 0.1822  time: 0.9595  last_time: 0.9547  data_time: 0.1341  last_data_time: 0.1391   lr: 0.0011988  max_mem: 21301M
[02/26 20:46:28] d2.utils.events INFO:  eta: 1:05:55  iter: 139  total_loss: 1.052  loss_cls: 0.8749  loss_box_reg: 0.1773  time: 0.9584  last_time: 0.9305  data_time: 0.1427  last_data_time: 0.1135   lr: 0.0013986  max_mem: 21301M
[02/26 20:46:47] d2.utils.events INFO:  eta: 1:05:35  iter: 159  total_loss: 0.9654  loss_cls: 0.7851  loss_box_reg: 0.1778  time: 0.9583  last_time: 1.0063  data_time: 0.1387  last_data_time: 0.1903   lr: 0.0015984  max_mem: 21301M
[02/26 20:47:06] d2.utils.events INFO:  eta: 1:05:16  iter: 179  total_loss: 0.8925  loss_cls: 0.7172  loss_box_reg: 0.1805  time: 0.9581  last_time: 0.9624  data_time: 0.1380  last_data_time: 0.1443   lr: 0.0017982  max_mem: 21301M
[02/26 20:47:25] d2.utils.events INFO:  eta: 1:04:50  iter: 199  total_loss: 0.8398  loss_cls: 0.6691  loss_box_reg: 0.173  time: 0.9557  last_time: 0.9432  data_time: 0.1232  last_data_time: 0.1255   lr: 0.001998  max_mem: 21301M
[02/26 20:47:44] d2.utils.events INFO:  eta: 1:04:28  iter: 219  total_loss: 0.812  loss_cls: 0.6415  loss_box_reg: 0.1663  time: 0.9534  last_time: 0.9243  data_time: 0.1176  last_data_time: 0.1050   lr: 0.0021978  max_mem: 21301M
[02/26 20:48:03] d2.utils.events INFO:  eta: 1:04:08  iter: 239  total_loss: 0.7689  loss_cls: 0.6009  loss_box_reg: 0.168  time: 0.9528  last_time: 0.9433  data_time: 0.1272  last_data_time: 0.1255   lr: 0.0023976  max_mem: 21301M
[02/26 20:48:22] d2.utils.events INFO:  eta: 1:03:49  iter: 259  total_loss: 0.7378  loss_cls: 0.5728  loss_box_reg: 0.1663  time: 0.9528  last_time: 0.9659  data_time: 0.1377  last_data_time: 0.1476   lr: 0.0025974  max_mem: 21301M
[02/26 20:48:40] d2.utils.events INFO:  eta: 1:03:22  iter: 279  total_loss: 0.7077  loss_cls: 0.542  loss_box_reg: 0.1637  time: 0.9517  last_time: 0.9363  data_time: 0.1256  last_data_time: 0.1182   lr: 0.0027972  max_mem: 21301M
[02/26 20:48:59] d2.utils.events INFO:  eta: 1:03:01  iter: 299  total_loss: 0.6728  loss_cls: 0.5075  loss_box_reg: 0.1658  time: 0.9511  last_time: 0.9396  data_time: 0.1246  last_data_time: 0.1211   lr: 0.002997  max_mem: 21301M
[02/26 20:49:18] d2.utils.events INFO:  eta: 1:02:36  iter: 319  total_loss: 0.6258  loss_cls: 0.4608  loss_box_reg: 0.1611  time: 0.9503  last_time: 0.9362  data_time: 0.1221  last_data_time: 0.1183   lr: 0.0031968  max_mem: 21301M
[02/26 20:49:37] d2.utils.events INFO:  eta: 1:02:13  iter: 339  total_loss: 0.589  loss_cls: 0.4353  loss_box_reg: 0.1529  time: 0.9491  last_time: 0.9125  data_time: 0.1174  last_data_time: 0.0937   lr: 0.0033966  max_mem: 21301M
[02/26 20:49:56] d2.utils.events INFO:  eta: 1:01:52  iter: 359  total_loss: 0.5662  loss_cls: 0.4052  loss_box_reg: 0.1614  time: 0.9485  last_time: 0.9359  data_time: 0.1194  last_data_time: 0.1174   lr: 0.0035964  max_mem: 21301M
[02/26 20:50:14] d2.utils.events INFO:  eta: 1:01:31  iter: 379  total_loss: 0.5258  loss_cls: 0.3771  loss_box_reg: 0.1542  time: 0.9477  last_time: 0.9089  data_time: 0.1228  last_data_time: 0.0907   lr: 0.0037962  max_mem: 21301M
[02/26 20:50:33] d2.utils.events INFO:  eta: 1:01:09  iter: 399  total_loss: 0.5165  loss_cls: 0.3626  loss_box_reg: 0.1572  time: 0.9467  last_time: 0.9104  data_time: 0.1138  last_data_time: 0.0921   lr: 0.003996  max_mem: 21301M
[02/26 20:50:51] d2.utils.events INFO:  eta: 1:00:44  iter: 419  total_loss: 0.4811  loss_cls: 0.3292  loss_box_reg: 0.1483  time: 0.9455  last_time: 0.9481  data_time: 0.1181  last_data_time: 0.1291   lr: 0.0041958  max_mem: 21301M
[02/26 20:51:10] d2.utils.events INFO:  eta: 1:00:22  iter: 439  total_loss: 0.4734  loss_cls: 0.3192  loss_box_reg: 0.1551  time: 0.9445  last_time: 0.9159  data_time: 0.1073  last_data_time: 0.0978   lr: 0.0043956  max_mem: 21301M
[02/26 20:51:28] d2.utils.events INFO:  eta: 1:00:01  iter: 459  total_loss: 0.4433  loss_cls: 0.2953  loss_box_reg: 0.1485  time: 0.9435  last_time: 0.9434  data_time: 0.1063  last_data_time: 0.1245   lr: 0.0045954  max_mem: 21301M
[02/26 20:51:47] d2.utils.events INFO:  eta: 0:59:40  iter: 479  total_loss: 0.4392  loss_cls: 0.2881  loss_box_reg: 0.1525  time: 0.9427  last_time: 0.8812  data_time: 0.1096  last_data_time: 0.0631   lr: 0.0047952  max_mem: 21301M
[02/26 20:52:05] d2.utils.events INFO:  eta: 0:59:18  iter: 499  total_loss: 0.4183  loss_cls: 0.2716  loss_box_reg: 0.1487  time: 0.9422  last_time: 0.9314  data_time: 0.1121  last_data_time: 0.1120   lr: 0.004995  max_mem: 21301M
[02/26 20:52:24] d2.utils.events INFO:  eta: 0:58:57  iter: 519  total_loss: 0.3965  loss_cls: 0.2528  loss_box_reg: 0.1449  time: 0.9415  last_time: 0.9116  data_time: 0.1185  last_data_time: 0.1408   lr: 0.0051948  max_mem: 21301M
[02/26 20:52:42] d2.utils.events INFO:  eta: 0:58:34  iter: 539  total_loss: 0.3964  loss_cls: 0.249  loss_box_reg: 0.1488  time: 0.9408  last_time: 0.9169  data_time: 0.1085  last_data_time: 0.0977   lr: 0.0053946  max_mem: 21301M
[02/26 20:53:01] d2.utils.events INFO:  eta: 0:58:14  iter: 559  total_loss: 0.3916  loss_cls: 0.2423  loss_box_reg: 0.1477  time: 0.9404  last_time: 0.9433  data_time: 0.1175  last_data_time: 0.1242   lr: 0.0055944  max_mem: 21301M
[02/26 20:53:19] d2.utils.events INFO:  eta: 0:57:55  iter: 579  total_loss: 0.3739  loss_cls: 0.231  loss_box_reg: 0.1426  time: 0.9401  last_time: 0.9613  data_time: 0.1163  last_data_time: 0.1418   lr: 0.0057942  max_mem: 21301M
[02/26 20:53:38] d2.utils.events INFO:  eta: 0:57:32  iter: 599  total_loss: 0.3588  loss_cls: 0.222  loss_box_reg: 0.141  time: 0.9393  last_time: 0.9055  data_time: 0.1057  last_data_time: 0.0867   lr: 0.005994  max_mem: 21301M
[02/26 20:53:56] d2.utils.events INFO:  eta: 0:57:12  iter: 619  total_loss: 0.3738  loss_cls: 0.2234  loss_box_reg: 0.1524  time: 0.9388  last_time: 1.0002  data_time: 0.1113  last_data_time: 0.1825   lr: 0.0061938  max_mem: 21301M
[02/26 20:54:15] d2.utils.events INFO:  eta: 0:56:51  iter: 639  total_loss: 0.3655  loss_cls: 0.2164  loss_box_reg: 0.148  time: 0.9384  last_time: 0.8989  data_time: 0.1109  last_data_time: 0.0811   lr: 0.0063936  max_mem: 21301M
[02/26 20:54:33] d2.utils.events INFO:  eta: 0:56:31  iter: 659  total_loss: 0.3639  loss_cls: 0.2176  loss_box_reg: 0.1497  time: 0.9379  last_time: 0.9892  data_time: 0.1056  last_data_time: 0.1709   lr: 0.0065934  max_mem: 21301M
[02/26 20:54:52] d2.utils.events INFO:  eta: 0:56:13  iter: 679  total_loss: 0.3448  loss_cls: 0.2018  loss_box_reg: 0.1446  time: 0.9375  last_time: 0.9095  data_time: 0.1094  last_data_time: 0.0910   lr: 0.0067932  max_mem: 21301M
[02/26 20:55:10] d2.utils.events INFO:  eta: 0:55:53  iter: 699  total_loss: 0.3345  loss_cls: 0.1932  loss_box_reg: 0.1418  time: 0.9370  last_time: 0.8906  data_time: 0.1061  last_data_time: 0.0727   lr: 0.006993  max_mem: 21301M
[02/26 20:55:28] d2.utils.events INFO:  eta: 0:55:32  iter: 719  total_loss: 0.3249  loss_cls: 0.1877  loss_box_reg: 0.1383  time: 0.9364  last_time: 0.9294  data_time: 0.1023  last_data_time: 0.1104   lr: 0.0071928  max_mem: 21301M
[02/26 20:55:47] d2.utils.events INFO:  eta: 0:55:13  iter: 739  total_loss: 0.3176  loss_cls: 0.1817  loss_box_reg: 0.1383  time: 0.9359  last_time: 0.9266  data_time: 0.0985  last_data_time: 0.1091   lr: 0.0073926  max_mem: 21301M
[02/26 20:56:05] d2.utils.events INFO:  eta: 0:54:52  iter: 759  total_loss: 0.328  loss_cls: 0.184  loss_box_reg: 0.1431  time: 0.9353  last_time: 0.9224  data_time: 0.0978  last_data_time: 0.1049   lr: 0.0075924  max_mem: 21301M
[02/26 20:56:23] d2.utils.events INFO:  eta: 0:54:32  iter: 779  total_loss: 0.3255  loss_cls: 0.1822  loss_box_reg: 0.1379  time: 0.9349  last_time: 0.9302  data_time: 0.1028  last_data_time: 0.1125   lr: 0.0077922  max_mem: 21301M
[02/26 20:56:42] d2.utils.events INFO:  eta: 0:54:11  iter: 799  total_loss: 0.3217  loss_cls: 0.1787  loss_box_reg: 0.1409  time: 0.9342  last_time: 0.9530  data_time: 0.0968  last_data_time: 0.1340   lr: 0.007992  max_mem: 21301M
[02/26 20:57:00] d2.utils.events INFO:  eta: 0:53:50  iter: 819  total_loss: 0.3138  loss_cls: 0.1756  loss_box_reg: 0.1403  time: 0.9338  last_time: 0.9166  data_time: 0.1007  last_data_time: 0.0970   lr: 0.0081918  max_mem: 21301M
[02/26 20:57:18] d2.utils.events INFO:  eta: 0:53:30  iter: 839  total_loss: 0.3042  loss_cls: 0.1691  loss_box_reg: 0.1354  time: 0.9334  last_time: 0.8902  data_time: 0.0988  last_data_time: 0.0712   lr: 0.0083916  max_mem: 21301M
[02/26 20:57:37] d2.utils.events INFO:  eta: 0:53:11  iter: 859  total_loss: 0.3023  loss_cls: 0.1637  loss_box_reg: 0.1369  time: 0.9329  last_time: 0.9262  data_time: 0.1006  last_data_time: 0.1075   lr: 0.0085914  max_mem: 21301M
[02/26 20:57:55] d2.utils.events INFO:  eta: 0:52:51  iter: 879  total_loss: 0.2888  loss_cls: 0.1573  loss_box_reg: 0.1337  time: 0.9325  last_time: 0.8529  data_time: 0.1027  last_data_time: 0.0823   lr: 0.0087912  max_mem: 21301M
[02/26 20:58:13] d2.utils.events INFO:  eta: 0:52:31  iter: 899  total_loss: 0.3043  loss_cls: 0.1624  loss_box_reg: 0.1396  time: 0.9322  last_time: 0.8896  data_time: 0.1012  last_data_time: 0.0722   lr: 0.008991  max_mem: 21301M
[02/26 20:58:31] d2.utils.events INFO:  eta: 0:52:10  iter: 919  total_loss: 0.2983  loss_cls: 0.1613  loss_box_reg: 0.1378  time: 0.9314  last_time: 0.8768  data_time: 0.0939  last_data_time: 0.1044   lr: 0.0091908  max_mem: 21301M
[02/26 20:58:49] d2.utils.events INFO:  eta: 0:51:49  iter: 939  total_loss: 0.2885  loss_cls: 0.1495  loss_box_reg: 0.1362  time: 0.9308  last_time: 0.8717  data_time: 0.0905  last_data_time: 0.1010   lr: 0.0093906  max_mem: 21301M
[02/26 20:59:07] d2.utils.events INFO:  eta: 0:51:28  iter: 959  total_loss: 0.2922  loss_cls: 0.1567  loss_box_reg: 0.1358  time: 0.9302  last_time: 0.9257  data_time: 0.0870  last_data_time: 0.1073   lr: 0.0095904  max_mem: 21301M
[02/26 20:59:25] d2.utils.events INFO:  eta: 0:51:09  iter: 979  total_loss: 0.2964  loss_cls: 0.1578  loss_box_reg: 0.139  time: 0.9297  last_time: 0.9379  data_time: 0.0906  last_data_time: 0.1200   lr: 0.0097902  max_mem: 21301M
[02/26 20:59:44] d2.utils.events INFO:  eta: 0:50:49  iter: 999  total_loss: 0.2755  loss_cls: 0.1437  loss_box_reg: 0.1314  time: 0.9292  last_time: 0.9242  data_time: 0.0929  last_data_time: 0.1043   lr: 0.00999  max_mem: 21301M
[02/26 21:00:02] d2.utils.events INFO:  eta: 0:50:25  iter: 1019  total_loss: 0.2831  loss_cls: 0.1461  loss_box_reg: 0.138  time: 0.9287  last_time: 0.8389  data_time: 0.0953  last_data_time: 0.0688   lr: 0.01  max_mem: 21301M
[02/26 21:00:20] d2.utils.events INFO:  eta: 0:50:03  iter: 1039  total_loss: 0.2776  loss_cls: 0.1479  loss_box_reg: 0.1318  time: 0.9282  last_time: 0.8714  data_time: 0.0874  last_data_time: 0.0537   lr: 0.01  max_mem: 21301M
[02/26 21:00:38] d2.utils.events INFO:  eta: 0:49:41  iter: 1059  total_loss: 0.2848  loss_cls: 0.1467  loss_box_reg: 0.1366  time: 0.9277  last_time: 0.8997  data_time: 0.0873  last_data_time: 0.0816   lr: 0.01  max_mem: 21301M
[02/26 21:00:56] d2.utils.events INFO:  eta: 0:49:20  iter: 1079  total_loss: 0.2836  loss_cls: 0.1448  loss_box_reg: 0.1373  time: 0.9273  last_time: 0.9236  data_time: 0.0910  last_data_time: 0.1044   lr: 0.01  max_mem: 21301M
[02/26 21:01:14] d2.utils.events INFO:  eta: 0:49:00  iter: 1099  total_loss: 0.2799  loss_cls: 0.1432  loss_box_reg: 0.139  time: 0.9270  last_time: 0.8822  data_time: 0.0934  last_data_time: 0.0633   lr: 0.01  max_mem: 21301M
[02/26 21:01:32] d2.utils.events INFO:  eta: 0:48:40  iter: 1119  total_loss: 0.2709  loss_cls: 0.1368  loss_box_reg: 0.1354  time: 0.9266  last_time: 0.9172  data_time: 0.0885  last_data_time: 0.0996   lr: 0.01  max_mem: 21301M
[02/26 21:01:50] d2.utils.events INFO:  eta: 0:48:19  iter: 1139  total_loss: 0.2772  loss_cls: 0.1412  loss_box_reg: 0.1364  time: 0.9260  last_time: 0.8935  data_time: 0.0796  last_data_time: 0.0737   lr: 0.01  max_mem: 21301M
[02/26 21:02:08] d2.utils.events INFO:  eta: 0:47:56  iter: 1159  total_loss: 0.2672  loss_cls: 0.134  loss_box_reg: 0.1332  time: 0.9253  last_time: 0.8973  data_time: 0.0803  last_data_time: 0.0782   lr: 0.01  max_mem: 21301M
[02/26 21:02:26] d2.utils.events INFO:  eta: 0:47:33  iter: 1179  total_loss: 0.2688  loss_cls: 0.1349  loss_box_reg: 0.1314  time: 0.9248  last_time: 0.8830  data_time: 0.0821  last_data_time: 0.0641   lr: 0.01  max_mem: 21301M
[02/26 21:02:44] d2.utils.events INFO:  eta: 0:47:12  iter: 1199  total_loss: 0.2701  loss_cls: 0.1327  loss_box_reg: 0.1334  time: 0.9244  last_time: 0.9272  data_time: 0.0866  last_data_time: 0.1101   lr: 0.01  max_mem: 21301M
[02/26 21:03:02] d2.utils.events INFO:  eta: 0:46:52  iter: 1219  total_loss: 0.2568  loss_cls: 0.1295  loss_box_reg: 0.1284  time: 0.9240  last_time: 0.9281  data_time: 0.0857  last_data_time: 0.1110   lr: 0.01  max_mem: 21301M
[02/26 21:03:20] d2.utils.events INFO:  eta: 0:46:31  iter: 1239  total_loss: 0.2551  loss_cls: 0.1291  loss_box_reg: 0.1275  time: 0.9237  last_time: 0.9196  data_time: 0.0877  last_data_time: 0.1009   lr: 0.01  max_mem: 21301M
[02/26 21:03:38] d2.utils.events INFO:  eta: 0:46:11  iter: 1259  total_loss: 0.2601  loss_cls: 0.1289  loss_box_reg: 0.1294  time: 0.9234  last_time: 0.9023  data_time: 0.0874  last_data_time: 0.0855   lr: 0.01  max_mem: 21301M
[02/26 21:03:56] d2.utils.events INFO:  eta: 0:45:51  iter: 1279  total_loss: 0.2529  loss_cls: 0.1254  loss_box_reg: 0.126  time: 0.9228  last_time: 0.9043  data_time: 0.0771  last_data_time: 0.0850   lr: 0.01  max_mem: 21301M
[02/26 21:04:14] d2.utils.events INFO:  eta: 0:45:30  iter: 1299  total_loss: 0.2579  loss_cls: 0.1256  loss_box_reg: 0.1305  time: 0.9225  last_time: 0.9308  data_time: 0.0845  last_data_time: 0.1119   lr: 0.01  max_mem: 21301M
[02/26 21:04:32] d2.utils.events INFO:  eta: 0:45:10  iter: 1319  total_loss: 0.2478  loss_cls: 0.12  loss_box_reg: 0.1274  time: 0.9221  last_time: 0.9157  data_time: 0.0818  last_data_time: 0.0969   lr: 0.01  max_mem: 21301M
[02/26 21:04:50] d2.utils.events INFO:  eta: 0:44:50  iter: 1339  total_loss: 0.2653  loss_cls: 0.1317  loss_box_reg: 0.133  time: 0.9217  last_time: 0.9127  data_time: 0.0849  last_data_time: 0.0928   lr: 0.01  max_mem: 21301M
[02/26 21:05:08] d2.utils.events INFO:  eta: 0:44:29  iter: 1359  total_loss: 0.2435  loss_cls: 0.1198  loss_box_reg: 0.1244  time: 0.9214  last_time: 0.9062  data_time: 0.0873  last_data_time: 0.0866   lr: 0.01  max_mem: 21301M
[02/26 21:05:25] d2.utils.events INFO:  eta: 0:44:09  iter: 1379  total_loss: 0.2413  loss_cls: 0.1176  loss_box_reg: 0.1246  time: 0.9210  last_time: 0.8788  data_time: 0.0740  last_data_time: 0.0599   lr: 0.01  max_mem: 21301M
[02/26 21:05:43] d2.utils.events INFO:  eta: 0:43:48  iter: 1399  total_loss: 0.2477  loss_cls: 0.1193  loss_box_reg: 0.1273  time: 0.9204  last_time: 0.8817  data_time: 0.0607  last_data_time: 0.0627   lr: 0.01  max_mem: 21301M
[02/26 21:06:01] d2.utils.events INFO:  eta: 0:43:24  iter: 1419  total_loss: 0.2554  loss_cls: 0.1252  loss_box_reg: 0.1329  time: 0.9198  last_time: 0.8846  data_time: 0.0630  last_data_time: 0.0662   lr: 0.01  max_mem: 21301M
[02/26 21:06:07] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0001426.pth
[02/26 21:06:08] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 21:06:08] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/26 21:06:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/26 21:06:08] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 21:06:08] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/26 21:06:08] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/26 21:06:08] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/26 21:06:09] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0004 s/iter. Inference: 0.0289 s/iter. Eval: 0.0002 s/iter. Total: 0.0295 s/iter. ETA=0:00:04
[02/26 21:06:13] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.626764 (0.029850 s / iter per device, on 1 devices)
[02/26 21:06:13] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.028909 s / iter per device, on 1 devices)
[02/26 21:06:13] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/26 21:06:13] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/26 21:06:13] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/26 21:06:13] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/26 21:06:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.20 seconds.
[02/26 21:06:13] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/26 21:06:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.11 seconds.
[02/26 21:06:13] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 22.083 | 32.484 | 24.792 | 11.395 | 33.734 | 44.987 |
[02/26 21:06:13] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 22.249 | 001_binder_clips_median      | 20.567 | 002_binder_clips_small       | 13.425 |
| 003_bombik_bucket          | 15.578 | 004_bonne_maman_blueberry    | 1.681  | 005_bonne_maman_raspberry    | 6.167  |
| 006_bonne_maman_strawberry | 0.299  | 007_costa_caramel            | 32.650 | 008_essential_oil_bergamot   | 25.089 |
| 009_garlic_toast_spread    | 5.743  | 010_handcream_avocado        | 0.761  | 011_hb_calcium               | 15.264 |
| 012_hb_grapeseed           | 11.089 | 013_hb_marine_collagen       | 8.978  | 014_hellmanns_mayonnaise     | 9.976  |
| 015_illy_blend             | 9.442  | 016_japanese_finger_cookies  | 4.710  | 017_john_west_canned_tuna    | 6.135  |
| 018_kerastase_shampoo      | 14.707 | 019_kiehls_facial_cream      | 31.713 | 020_kiihne_balsamic          | 20.546 |
| 021_kiihne_honey_mustard   | 29.396 | 022_lindor_matcha            | 31.347 | 023_lindor_salted_caramel    | 40.468 |
| 024_lush_mask              | 68.726 | 025_pasta_sauce_black_pepper | 7.531  | 026_pasta_sauce_tomato       | 10.250 |
| 027_pepsi                  | 60.291 | 028_portable_yogurt_machine  | 16.913 | 029_selfile_stick            | 2.150  |
| 030_sour_lemon_drops       | 7.371  | 031_sticky_notes             | 21.023 | 032_stridex_green            | 49.718 |
| 033_thermos_flask_cream    | 41.668 | 034_thermos_flask_muji       | 10.285 | 035_thermos_flask_sliver     | 0.479  |
| 036_tragata_olive_oil      | 12.000 | 037_tulip_luncheon_meat      | 7.526  | 038_unicharm_cotton_pad      | 54.310 |
| 039_vinda_tissue           | 45.586 | 040_wrigley_doublemint_gum   | 3.134  | 041_baseball_cap_black       | 33.328 |
| 042_baseball_cap_pink      | 44.640 | 043_bfe_facial_mask          | 36.760 | 044_corgi_doll               | 22.987 |
| 045_dinosaur_doll          | 50.324 | 046_geo_mocha                | 11.724 | 047_geo_roast_charcoal       | 15.618 |
| 048_instant_noodle_black   | 7.802  | 049_instant_noodle_red       | 35.445 | 050_nabati_cheese_wafer      | 52.862 |
| 051_truffettes             | 28.180 | 052_acnes_cream              | 37.508 | 053_aveda_conditioner        | 43.778 |
| 054_banana_milk_drink      | 9.531  | 055_candle_beast             | 24.596 | 056_china_persimmon          | 34.654 |
| 057_danisa_butter_cookies  | 5.730  | 058_effaclar_duo             | 11.162 | 059_evelom_cleanser          | 57.907 |
| 060_glasses_box_blone      | 40.496 | 061_handcream_iris           | 0.000  | 062_handcream_lavender       | 0.000  |
| 063_handcream_rosewater    | 2.621  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 17.290 |
| 066_japanese_chocolate     | 51.097 | 067_kerastase_hair_treatment | 22.526 | 068_kiehls_serum             | 38.987 |
| 069_korean_beef_marinade   | 33.887 | 070_korean_doenjang          | 10.019 | 071_korean_gochujang         | 0.000  |
| 072_korean_ssamjang        | 25.089 | 073_loccitane_soap           | 32.022 | 074_marvis_toothpaste_purple | 44.593 |
| 075_mouse_thinkpad         | 12.073 | 076_oatly_chocolate          | 21.536 | 077_oatly_original           | 24.795 |
| 078_ousa_grated_cheese     | 5.370  | 079_polaroid_film            | 0.923  | 080_skinceuticals_be         | 60.342 |
| 081_skinceuticals_cf       | 28.460 | 082_skinceuticals_phyto      | 25.267 | 083_stapler_black            | 15.927 |
| 084_stapler_blue           | 29.364 | 085_sunscreen_blue           | 19.048 | 086_tempo_pocket_tissue      | 3.189  |
| 087_thermos_flask_purple   | 55.992 | 088_uha_matcha               | 7.747  | 089_urban_decay_spray        | 33.618 |
| 090_vitaboost_multivitamin | 21.541 | 091_watercolor_penbox        | 1.256  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 31.580 | 094_kaneyo_kitchen_bleach    | 36.922 | 095_lays_chip_bag_blue       | 18.640 |
| 096_lays_chip_bag_green    | 15.436 | 097_lays_chip_tube_auburn    | 19.114 | 098_lays_chip_tube_green     | 40.065 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/26 21:06:13] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/26 21:06:13] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/26 21:06:13] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/26 21:06:13] d2.evaluation.testing INFO: copypaste: 22.0831,32.4842,24.7916,11.3953,33.7342,44.9868
[02/26 21:06:24] d2.utils.events INFO:  eta: 0:43:03  iter: 1439  total_loss: 0.2491  loss_cls: 0.1184  loss_box_reg: 0.1281  time: 0.9193  last_time: 0.8803  data_time: 0.0622  last_data_time: 0.0589   lr: 0.01  max_mem: 21301M
[02/26 21:06:42] d2.utils.events INFO:  eta: 0:42:42  iter: 1459  total_loss: 0.2427  loss_cls: 0.1179  loss_box_reg: 0.1231  time: 0.9187  last_time: 0.8836  data_time: 0.0640  last_data_time: 0.0660   lr: 0.01  max_mem: 21301M
[02/26 21:06:59] d2.utils.events INFO:  eta: 0:42:22  iter: 1479  total_loss: 0.2386  loss_cls: 0.1146  loss_box_reg: 0.1233  time: 0.9181  last_time: 0.8745  data_time: 0.0590  last_data_time: 0.0568   lr: 0.01  max_mem: 21301M
[02/26 21:07:17] d2.utils.events INFO:  eta: 0:41:59  iter: 1499  total_loss: 0.2443  loss_cls: 0.1181  loss_box_reg: 0.125  time: 0.9176  last_time: 0.8744  data_time: 0.0613  last_data_time: 0.0573   lr: 0.01  max_mem: 21301M
[02/26 21:07:34] d2.utils.events INFO:  eta: 0:41:38  iter: 1519  total_loss: 0.2361  loss_cls: 0.1114  loss_box_reg: 0.1257  time: 0.9170  last_time: 0.8748  data_time: 0.0593  last_data_time: 0.0551   lr: 0.01  max_mem: 21301M
[02/26 21:07:52] d2.utils.events INFO:  eta: 0:41:17  iter: 1539  total_loss: 0.2353  loss_cls: 0.112  loss_box_reg: 0.1244  time: 0.9165  last_time: 0.8748  data_time: 0.0589  last_data_time: 0.0565   lr: 0.01  max_mem: 21301M
[02/26 21:08:09] d2.utils.events INFO:  eta: 0:40:56  iter: 1559  total_loss: 0.2389  loss_cls: 0.1124  loss_box_reg: 0.1273  time: 0.9159  last_time: 0.8846  data_time: 0.0594  last_data_time: 0.0661   lr: 0.01  max_mem: 21301M
[02/26 21:08:27] d2.utils.events INFO:  eta: 0:40:34  iter: 1579  total_loss: 0.236  loss_cls: 0.1129  loss_box_reg: 0.1251  time: 0.9154  last_time: 0.8280  data_time: 0.0594  last_data_time: 0.0569   lr: 0.01  max_mem: 21301M
[02/26 21:08:44] d2.utils.events INFO:  eta: 0:40:13  iter: 1599  total_loss: 0.2377  loss_cls: 0.1114  loss_box_reg: 0.1236  time: 0.9149  last_time: 0.8705  data_time: 0.0618  last_data_time: 0.0524   lr: 0.01  max_mem: 21301M
[02/26 21:09:02] d2.utils.events INFO:  eta: 0:39:50  iter: 1619  total_loss: 0.2384  loss_cls: 0.1137  loss_box_reg: 0.1246  time: 0.9145  last_time: 0.8823  data_time: 0.0634  last_data_time: 0.0652   lr: 0.01  max_mem: 21301M
[02/26 21:09:19] d2.utils.events INFO:  eta: 0:39:29  iter: 1639  total_loss: 0.2399  loss_cls: 0.1143  loss_box_reg: 0.1241  time: 0.9141  last_time: 0.8841  data_time: 0.0663  last_data_time: 0.0672   lr: 0.01  max_mem: 21301M
[02/26 21:09:37] d2.utils.events INFO:  eta: 0:39:05  iter: 1659  total_loss: 0.2414  loss_cls: 0.1124  loss_box_reg: 0.126  time: 0.9136  last_time: 0.8765  data_time: 0.0611  last_data_time: 0.0574   lr: 0.01  max_mem: 21301M
[02/26 21:09:55] d2.utils.events INFO:  eta: 0:38:44  iter: 1679  total_loss: 0.2347  loss_cls: 0.1103  loss_box_reg: 0.1251  time: 0.9132  last_time: 0.8749  data_time: 0.0609  last_data_time: 0.0566   lr: 0.01  max_mem: 21301M
[02/26 21:10:12] d2.utils.events INFO:  eta: 0:38:23  iter: 1699  total_loss: 0.2308  loss_cls: 0.1063  loss_box_reg: 0.1223  time: 0.9127  last_time: 0.8945  data_time: 0.0621  last_data_time: 0.0741   lr: 0.01  max_mem: 21301M
[02/26 21:10:30] d2.utils.events INFO:  eta: 0:38:03  iter: 1719  total_loss: 0.2248  loss_cls: 0.1044  loss_box_reg: 0.1188  time: 0.9123  last_time: 0.8892  data_time: 0.0614  last_data_time: 0.0703   lr: 0.01  max_mem: 21301M
[02/26 21:10:47] d2.utils.events INFO:  eta: 0:37:42  iter: 1739  total_loss: 0.2319  loss_cls: 0.1072  loss_box_reg: 0.1218  time: 0.9119  last_time: 0.8213  data_time: 0.0589  last_data_time: 0.0508   lr: 0.01  max_mem: 21301M
[02/26 21:11:05] d2.utils.events INFO:  eta: 0:37:22  iter: 1759  total_loss: 0.2353  loss_cls: 0.1089  loss_box_reg: 0.1253  time: 0.9115  last_time: 0.8743  data_time: 0.0636  last_data_time: 0.0557   lr: 0.01  max_mem: 21301M
[02/26 21:11:22] d2.utils.events INFO:  eta: 0:37:01  iter: 1779  total_loss: 0.2221  loss_cls: 0.1046  loss_box_reg: 0.1183  time: 0.9110  last_time: 0.8701  data_time: 0.0591  last_data_time: 0.0510   lr: 0.01  max_mem: 21301M
[02/26 21:11:39] d2.utils.events INFO:  eta: 0:36:41  iter: 1799  total_loss: 0.238  loss_cls: 0.1123  loss_box_reg: 0.1252  time: 0.9105  last_time: 0.8001  data_time: 0.0605  last_data_time: 0.0757   lr: 0.01  max_mem: 21301M
[02/26 21:11:57] d2.utils.events INFO:  eta: 0:36:21  iter: 1819  total_loss: 0.2329  loss_cls: 0.1089  loss_box_reg: 0.1233  time: 0.9102  last_time: 0.8921  data_time: 0.0616  last_data_time: 0.0740   lr: 0.01  max_mem: 21301M
[02/26 21:12:14] d2.utils.events INFO:  eta: 0:36:02  iter: 1839  total_loss: 0.2256  loss_cls: 0.1035  loss_box_reg: 0.1221  time: 0.9098  last_time: 0.8287  data_time: 0.0597  last_data_time: 0.0575   lr: 0.01  max_mem: 21301M
[02/26 21:12:32] d2.utils.events INFO:  eta: 0:35:44  iter: 1859  total_loss: 0.2319  loss_cls: 0.1044  loss_box_reg: 0.1246  time: 0.9094  last_time: 0.8741  data_time: 0.0583  last_data_time: 0.0563   lr: 0.01  max_mem: 21301M
[02/26 21:12:50] d2.utils.events INFO:  eta: 0:35:25  iter: 1879  total_loss: 0.2328  loss_cls: 0.1077  loss_box_reg: 0.1248  time: 0.9091  last_time: 0.8776  data_time: 0.0599  last_data_time: 0.0588   lr: 0.01  max_mem: 21301M
[02/26 21:13:07] d2.utils.events INFO:  eta: 0:35:07  iter: 1899  total_loss: 0.2224  loss_cls: 0.1036  loss_box_reg: 0.1195  time: 0.9087  last_time: 0.8739  data_time: 0.0574  last_data_time: 0.0552   lr: 0.01  max_mem: 21301M
[02/26 21:13:25] d2.utils.events INFO:  eta: 0:34:49  iter: 1919  total_loss: 0.2199  loss_cls: 0.09908  loss_box_reg: 0.1201  time: 0.9084  last_time: 0.9019  data_time: 0.0615  last_data_time: 0.0849   lr: 0.01  max_mem: 21301M
[02/26 21:13:42] d2.utils.events INFO:  eta: 0:34:31  iter: 1939  total_loss: 0.2226  loss_cls: 0.102  loss_box_reg: 0.1207  time: 0.9081  last_time: 0.8683  data_time: 0.0578  last_data_time: 0.0495   lr: 0.01  max_mem: 21301M
[02/26 21:14:00] d2.utils.events INFO:  eta: 0:34:13  iter: 1959  total_loss: 0.2298  loss_cls: 0.1067  loss_box_reg: 0.1226  time: 0.9077  last_time: 0.8705  data_time: 0.0606  last_data_time: 0.0511   lr: 0.01  max_mem: 21301M
[02/26 21:14:17] d2.utils.events INFO:  eta: 0:33:55  iter: 1979  total_loss: 0.2266  loss_cls: 0.1032  loss_box_reg: 0.1238  time: 0.9075  last_time: 0.8743  data_time: 0.0600  last_data_time: 0.0551   lr: 0.01  max_mem: 21301M
[02/26 21:14:35] d2.utils.events INFO:  eta: 0:33:36  iter: 1999  total_loss: 0.2233  loss_cls: 0.09997  loss_box_reg: 0.1218  time: 0.9071  last_time: 0.8709  data_time: 0.0608  last_data_time: 0.0527   lr: 0.01  max_mem: 21301M
[02/26 21:14:52] d2.utils.events INFO:  eta: 0:33:18  iter: 2019  total_loss: 0.2203  loss_cls: 0.1009  loss_box_reg: 0.1189  time: 0.9068  last_time: 0.8903  data_time: 0.0591  last_data_time: 0.0729   lr: 0.01  max_mem: 21301M
[02/26 21:15:10] d2.utils.events INFO:  eta: 0:33:00  iter: 2039  total_loss: 0.2221  loss_cls: 0.1006  loss_box_reg: 0.1212  time: 0.9065  last_time: 0.8755  data_time: 0.0572  last_data_time: 0.0563   lr: 0.01  max_mem: 21301M
[02/26 21:15:27] d2.utils.events INFO:  eta: 0:32:41  iter: 2059  total_loss: 0.2191  loss_cls: 0.1002  loss_box_reg: 0.1192  time: 0.9061  last_time: 0.8834  data_time: 0.0597  last_data_time: 0.0647   lr: 0.01  max_mem: 21301M
[02/26 21:15:45] d2.utils.events INFO:  eta: 0:32:23  iter: 2079  total_loss: 0.2144  loss_cls: 0.09526  loss_box_reg: 0.118  time: 0.9058  last_time: 0.8768  data_time: 0.0600  last_data_time: 0.0595   lr: 0.01  max_mem: 21301M
[02/26 21:16:02] d2.utils.events INFO:  eta: 0:32:05  iter: 2099  total_loss: 0.2223  loss_cls: 0.1018  loss_box_reg: 0.1205  time: 0.9055  last_time: 0.8766  data_time: 0.0591  last_data_time: 0.0587   lr: 0.01  max_mem: 21301M
[02/26 21:16:19] d2.utils.events INFO:  eta: 0:31:46  iter: 2119  total_loss: 0.2218  loss_cls: 0.09866  loss_box_reg: 0.1228  time: 0.9052  last_time: 0.8823  data_time: 0.0600  last_data_time: 0.0647   lr: 0.01  max_mem: 21301M
[02/26 21:16:37] d2.utils.events INFO:  eta: 0:31:29  iter: 2139  total_loss: 0.2153  loss_cls: 0.09646  loss_box_reg: 0.1201  time: 0.9049  last_time: 0.8939  data_time: 0.0610  last_data_time: 0.0756   lr: 0.01  max_mem: 21301M
[02/26 21:16:55] d2.utils.events INFO:  eta: 0:31:10  iter: 2159  total_loss: 0.2328  loss_cls: 0.1036  loss_box_reg: 0.1267  time: 0.9046  last_time: 0.8315  data_time: 0.0596  last_data_time: 0.0609   lr: 0.01  max_mem: 21301M
[02/26 21:17:12] d2.utils.events INFO:  eta: 0:30:51  iter: 2179  total_loss: 0.2179  loss_cls: 0.09868  loss_box_reg: 0.1209  time: 0.9043  last_time: 0.8852  data_time: 0.0596  last_data_time: 0.0655   lr: 0.01  max_mem: 21301M
[02/26 21:17:30] d2.utils.events INFO:  eta: 0:30:32  iter: 2199  total_loss: 0.217  loss_cls: 0.09802  loss_box_reg: 0.1215  time: 0.9041  last_time: 0.8844  data_time: 0.0593  last_data_time: 0.0657   lr: 0.01  max_mem: 21301M
[02/26 21:17:47] d2.utils.events INFO:  eta: 0:30:14  iter: 2219  total_loss: 0.2204  loss_cls: 0.1003  loss_box_reg: 0.1206  time: 0.9038  last_time: 0.8851  data_time: 0.0623  last_data_time: 0.0662   lr: 0.01  max_mem: 21301M
[02/26 21:18:05] d2.utils.events INFO:  eta: 0:29:56  iter: 2239  total_loss: 0.2137  loss_cls: 0.09225  loss_box_reg: 0.1196  time: 0.9036  last_time: 0.8859  data_time: 0.0617  last_data_time: 0.0660   lr: 0.01  max_mem: 21301M
[02/26 21:18:22] d2.utils.events INFO:  eta: 0:29:38  iter: 2259  total_loss: 0.2103  loss_cls: 0.09403  loss_box_reg: 0.1172  time: 0.9033  last_time: 0.8757  data_time: 0.0615  last_data_time: 0.0577   lr: 0.01  max_mem: 21301M
[02/26 21:18:40] d2.utils.events INFO:  eta: 0:29:20  iter: 2279  total_loss: 0.2144  loss_cls: 0.09781  loss_box_reg: 0.1175  time: 0.9031  last_time: 0.8702  data_time: 0.0612  last_data_time: 0.0523   lr: 0.01  max_mem: 21301M
[02/26 21:18:57] d2.utils.events INFO:  eta: 0:29:02  iter: 2299  total_loss: 0.2082  loss_cls: 0.09145  loss_box_reg: 0.1173  time: 0.9028  last_time: 0.8769  data_time: 0.0603  last_data_time: 0.0580   lr: 0.01  max_mem: 21301M
[02/26 21:19:15] d2.utils.events INFO:  eta: 0:28:44  iter: 2319  total_loss: 0.2135  loss_cls: 0.09368  loss_box_reg: 0.1174  time: 0.9026  last_time: 0.8689  data_time: 0.0611  last_data_time: 0.0514   lr: 0.01  max_mem: 21301M
[02/26 21:19:32] d2.utils.events INFO:  eta: 0:28:26  iter: 2339  total_loss: 0.2128  loss_cls: 0.09463  loss_box_reg: 0.1174  time: 0.9024  last_time: 0.8743  data_time: 0.0614  last_data_time: 0.0556   lr: 0.01  max_mem: 21301M
[02/26 21:19:50] d2.utils.events INFO:  eta: 0:28:08  iter: 2359  total_loss: 0.2179  loss_cls: 0.09612  loss_box_reg: 0.1192  time: 0.9022  last_time: 0.8748  data_time: 0.0593  last_data_time: 0.0559   lr: 0.01  max_mem: 21301M
[02/26 21:20:07] d2.utils.events INFO:  eta: 0:27:50  iter: 2379  total_loss: 0.2145  loss_cls: 0.09419  loss_box_reg: 0.1203  time: 0.9019  last_time: 0.8757  data_time: 0.0620  last_data_time: 0.0578   lr: 0.01  max_mem: 21301M
[02/26 21:20:25] d2.utils.events INFO:  eta: 0:27:33  iter: 2399  total_loss: 0.2132  loss_cls: 0.09105  loss_box_reg: 0.1181  time: 0.9017  last_time: 0.8841  data_time: 0.0617  last_data_time: 0.0650   lr: 0.01  max_mem: 21301M
[02/26 21:20:42] d2.utils.events INFO:  eta: 0:27:15  iter: 2419  total_loss: 0.2014  loss_cls: 0.08945  loss_box_reg: 0.112  time: 0.9015  last_time: 0.8372  data_time: 0.0631  last_data_time: 0.0658   lr: 0.01  max_mem: 21301M
[02/26 21:21:00] d2.utils.events INFO:  eta: 0:26:57  iter: 2439  total_loss: 0.2118  loss_cls: 0.09251  loss_box_reg: 0.1193  time: 0.9013  last_time: 0.8745  data_time: 0.0628  last_data_time: 0.0574   lr: 0.01  max_mem: 21301M
[02/26 21:21:17] d2.utils.events INFO:  eta: 0:26:40  iter: 2459  total_loss: 0.2041  loss_cls: 0.08543  loss_box_reg: 0.1187  time: 0.9011  last_time: 0.8877  data_time: 0.0580  last_data_time: 0.0696   lr: 0.01  max_mem: 21301M
[02/26 21:21:35] d2.utils.events INFO:  eta: 0:26:22  iter: 2479  total_loss: 0.2135  loss_cls: 0.09322  loss_box_reg: 0.1208  time: 0.9008  last_time: 0.8740  data_time: 0.0612  last_data_time: 0.0536   lr: 0.01  max_mem: 21301M
[02/26 21:21:52] d2.utils.events INFO:  eta: 0:26:04  iter: 2499  total_loss: 0.2179  loss_cls: 0.09729  loss_box_reg: 0.1228  time: 0.9006  last_time: 0.8724  data_time: 0.0607  last_data_time: 0.0526   lr: 0.01  max_mem: 21301M
[02/26 21:22:10] d2.utils.events INFO:  eta: 0:25:47  iter: 2519  total_loss: 0.2054  loss_cls: 0.08964  loss_box_reg: 0.1155  time: 0.9004  last_time: 0.8798  data_time: 0.0625  last_data_time: 0.0609   lr: 0.01  max_mem: 21301M
[02/26 21:22:27] d2.utils.events INFO:  eta: 0:25:29  iter: 2539  total_loss: 0.2151  loss_cls: 0.09547  loss_box_reg: 0.1202  time: 0.9002  last_time: 0.8705  data_time: 0.0591  last_data_time: 0.0512   lr: 0.01  max_mem: 21301M
[02/26 21:22:45] d2.utils.events INFO:  eta: 0:25:12  iter: 2559  total_loss: 0.2126  loss_cls: 0.09244  loss_box_reg: 0.119  time: 0.9000  last_time: 0.8875  data_time: 0.0614  last_data_time: 0.0694   lr: 0.01  max_mem: 21301M
[02/26 21:22:53] d2.engine.hooks INFO: Overall training speed: 2567 iterations in 0:38:30 (0.9000 s / it)
[02/26 21:22:53] d2.engine.hooks INFO: Total training time: 0:38:36 (0:00:06 on hooks)
[02/26 21:22:53] d2.utils.events INFO:  eta: 0:25:03  iter: 2569  total_loss: 0.2047  loss_cls: 0.0886  loss_box_reg: 0.1177  time: 0.8999  last_time: 0.8888  data_time: 0.0619  last_data_time: 0.0703   lr: 0.01  max_mem: 21301M
