[02/26 21:23:21] detectron2 INFO: Rank of current process: 0. World size: 2
[02/26 21:23:21] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/26 21:23:21] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/26 21:23:21] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/26 21:23:21] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/26 21:23:21] detectron2 INFO: Full config saved to ./output/config.yaml
[02/26 21:23:21] d2.utils.env INFO: Using a generated random seed 21999088
[02/26 21:23:22] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/26 21:23:24] d2.data.datasets.coco INFO: Loading /media/nahyun/HDD//data_100/instances_train.json takes 2.31 seconds.
[02/26 21:23:24] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 21:23:24] d2.data.datasets.coco INFO: Loaded 19191 images in COCO format from /media/nahyun/HDD//data_100/instances_train.json
[02/26 21:23:26] d2.data.build INFO: Removed 0 images with no usable annotations. 19191 images left.
[02/26 21:23:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/26 21:23:26] d2.data.build INFO: Using training sampler TrainingSampler
[02/26 21:23:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 21:23:26] d2.data.common INFO: Serializing 19191 elements to byte tensors and concatenating them all ...
[02/26 21:23:26] d2.data.common INFO: Serialized dataset takes 80.55 MiB
[02/26 21:23:26] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/26 21:23:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 21:23:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/nahyun/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 21:23:26] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/26 21:23:26] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[02/26 21:23:26] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[02/26 21:23:26] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[02/26 21:23:26] d2.engine.train_loop INFO: Starting training from iteration 0
[02/26 21:23:42] detectron2 INFO: Rank of current process: 0. World size: 2
[02/26 21:23:42] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/26 21:23:42] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/26 21:23:42] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/26 21:23:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/26 21:23:42] detectron2 INFO: Full config saved to ./output/config.yaml
[02/26 21:23:42] d2.utils.env INFO: Using a generated random seed 42483305
[02/26 21:23:42] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/26 21:23:45] d2.data.datasets.coco INFO: Loading /media/nahyun/HDD//data_100/instances_train.json takes 2.32 seconds.
[02/26 21:23:45] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 21:23:45] d2.data.datasets.coco INFO: Loaded 19191 images in COCO format from /media/nahyun/HDD//data_100/instances_train.json
[02/26 21:23:46] d2.data.build INFO: Removed 0 images with no usable annotations. 19191 images left.
[02/26 21:23:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/26 21:23:46] d2.data.build INFO: Using training sampler TrainingSampler
[02/26 21:23:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 21:23:46] d2.data.common INFO: Serializing 19191 elements to byte tensors and concatenating them all ...
[02/26 21:23:47] d2.data.common INFO: Serialized dataset takes 80.55 MiB
[02/26 21:23:47] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/26 21:23:47] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 21:23:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/nahyun/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 21:23:47] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/26 21:23:47] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[02/26 21:23:47] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[02/26 21:23:47] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[02/26 21:23:47] d2.engine.train_loop INFO: Starting training from iteration 0
[02/26 21:24:17] detectron2 INFO: Rank of current process: 0. World size: 1
[02/26 21:24:18] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/26 21:24:18] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/26 21:24:18] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/26 21:24:18] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/26 21:24:18] detectron2 INFO: Full config saved to ./output/config.yaml
[02/26 21:24:18] d2.utils.env INFO: Using a generated random seed 18197365
[02/26 21:24:19] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/26 21:24:21] d2.data.datasets.coco INFO: Loading /media/nahyun/HDD//data_100/instances_train.json takes 2.23 seconds.
[02/26 21:24:21] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 21:24:21] d2.data.datasets.coco INFO: Loaded 19191 images in COCO format from /media/nahyun/HDD//data_100/instances_train.json
[02/26 21:24:23] d2.data.build INFO: Removed 0 images with no usable annotations. 19191 images left.
[02/26 21:24:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/26 21:24:23] d2.data.build INFO: Using training sampler TrainingSampler
[02/26 21:24:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 21:24:23] d2.data.common INFO: Serializing 19191 elements to byte tensors and concatenating them all ...
[02/26 21:24:23] d2.data.common INFO: Serialized dataset takes 80.55 MiB
[02/26 21:24:23] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/26 21:24:23] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 21:24:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/nahyun/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 21:24:23] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/26 21:24:23] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[02/26 21:24:23] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[02/26 21:24:23] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[02/26 21:24:23] d2.engine.train_loop INFO: Starting training from iteration 0
[02/26 21:24:42] d2.utils.events INFO:  eta: 1:01:54  iter: 19  total_loss: 2.758  loss_cls: 1.722  loss_box_reg: 1.037  time: 0.9056  last_time: 0.8719  data_time: 0.0679  last_data_time: 0.0596   lr: 0.00019981  max_mem: 21296M
[02/26 21:25:00] d2.utils.events INFO:  eta: 1:01:39  iter: 39  total_loss: 1.917  loss_cls: 1.209  loss_box_reg: 0.71  time: 0.8940  last_time: 0.8773  data_time: 0.0595  last_data_time: 0.0621   lr: 0.00039961  max_mem: 21296M
[02/26 21:25:18] d2.utils.events INFO:  eta: 1:01:23  iter: 59  total_loss: 1.81  loss_cls: 1.149  loss_box_reg: 0.6615  time: 0.8857  last_time: 0.8733  data_time: 0.0599  last_data_time: 0.0587   lr: 0.00059941  max_mem: 21296M
[02/26 21:25:35] d2.utils.events INFO:  eta: 1:01:09  iter: 79  total_loss: 1.804  loss_cls: 1.151  loss_box_reg: 0.6508  time: 0.8819  last_time: 0.8779  data_time: 0.0626  last_data_time: 0.0636   lr: 0.00079921  max_mem: 21296M
[02/26 21:25:52] d2.utils.events INFO:  eta: 1:00:53  iter: 99  total_loss: 1.796  loss_cls: 1.156  loss_box_reg: 0.6347  time: 0.8803  last_time: 0.8687  data_time: 0.0617  last_data_time: 0.0535   lr: 0.00099901  max_mem: 21296M
[02/26 21:26:10] d2.utils.events INFO:  eta: 1:00:37  iter: 119  total_loss: 1.787  loss_cls: 1.154  loss_box_reg: 0.6275  time: 0.8793  last_time: 0.8693  data_time: 0.0604  last_data_time: 0.0495   lr: 0.0011988  max_mem: 21296M
[02/26 21:26:27] d2.utils.events INFO:  eta: 1:00:23  iter: 139  total_loss: 1.754  loss_cls: 1.145  loss_box_reg: 0.6105  time: 0.8789  last_time: 0.8827  data_time: 0.0606  last_data_time: 0.0641   lr: 0.0013986  max_mem: 21296M
[02/26 21:26:45] d2.utils.events INFO:  eta: 1:00:09  iter: 159  total_loss: 1.755  loss_cls: 1.153  loss_box_reg: 0.603  time: 0.8781  last_time: 0.8199  data_time: 0.0584  last_data_time: 0.0497   lr: 0.0015984  max_mem: 21296M
[02/26 21:27:02] d2.utils.events INFO:  eta: 0:59:51  iter: 179  total_loss: 1.718  loss_cls: 1.137  loss_box_reg: 0.5805  time: 0.8777  last_time: 0.8737  data_time: 0.0585  last_data_time: 0.0559   lr: 0.0017982  max_mem: 21296M
[02/26 21:27:20] d2.utils.events INFO:  eta: 0:59:34  iter: 199  total_loss: 1.719  loss_cls: 1.155  loss_box_reg: 0.5659  time: 0.8775  last_time: 0.8724  data_time: 0.0593  last_data_time: 0.0532   lr: 0.001998  max_mem: 21296M
[02/26 21:27:37] d2.utils.events INFO:  eta: 0:59:17  iter: 219  total_loss: 1.662  loss_cls: 1.152  loss_box_reg: 0.5155  time: 0.8774  last_time: 0.8761  data_time: 0.0600  last_data_time: 0.0582   lr: 0.0021978  max_mem: 21296M
[02/26 21:27:55] d2.utils.events INFO:  eta: 0:59:01  iter: 239  total_loss: 1.611  loss_cls: 1.142  loss_box_reg: 0.4649  time: 0.8776  last_time: 0.8901  data_time: 0.0608  last_data_time: 0.0709   lr: 0.0023976  max_mem: 21296M
[02/26 21:28:13] d2.utils.events INFO:  eta: 0:58:44  iter: 259  total_loss: 1.582  loss_cls: 1.143  loss_box_reg: 0.4344  time: 0.8776  last_time: 0.8733  data_time: 0.0614  last_data_time: 0.0539   lr: 0.0025974  max_mem: 21296M
[02/26 21:28:30] d2.utils.events INFO:  eta: 0:58:28  iter: 279  total_loss: 1.486  loss_cls: 1.073  loss_box_reg: 0.4021  time: 0.8777  last_time: 0.8716  data_time: 0.0592  last_data_time: 0.0523   lr: 0.0027972  max_mem: 21296M
[02/26 21:28:48] d2.utils.events INFO:  eta: 0:58:11  iter: 299  total_loss: 1.296  loss_cls: 0.9105  loss_box_reg: 0.3829  time: 0.8773  last_time: 0.8708  data_time: 0.0603  last_data_time: 0.0528   lr: 0.002997  max_mem: 21296M
[02/26 21:29:05] d2.utils.events INFO:  eta: 0:57:54  iter: 319  total_loss: 1.162  loss_cls: 0.7954  loss_box_reg: 0.358  time: 0.8774  last_time: 0.8759  data_time: 0.0626  last_data_time: 0.0570   lr: 0.0031968  max_mem: 21296M
[02/26 21:29:23] d2.utils.events INFO:  eta: 0:57:37  iter: 339  total_loss: 1.106  loss_cls: 0.7659  loss_box_reg: 0.3435  time: 0.8774  last_time: 0.8783  data_time: 0.0618  last_data_time: 0.0594   lr: 0.0033966  max_mem: 21296M
[02/26 21:29:40] d2.utils.events INFO:  eta: 0:57:20  iter: 359  total_loss: 1.049  loss_cls: 0.7188  loss_box_reg: 0.3311  time: 0.8773  last_time: 0.8760  data_time: 0.0611  last_data_time: 0.0569   lr: 0.0035964  max_mem: 21296M
[02/26 21:29:58] d2.utils.events INFO:  eta: 0:57:03  iter: 379  total_loss: 1.02  loss_cls: 0.7072  loss_box_reg: 0.3134  time: 0.8774  last_time: 0.8842  data_time: 0.0614  last_data_time: 0.0665   lr: 0.0037962  max_mem: 21296M
[02/26 21:30:15] d2.utils.events INFO:  eta: 0:56:45  iter: 399  total_loss: 0.9938  loss_cls: 0.6852  loss_box_reg: 0.302  time: 0.8769  last_time: 0.8770  data_time: 0.0581  last_data_time: 0.0582   lr: 0.003996  max_mem: 21296M
[02/26 21:30:33] d2.utils.events INFO:  eta: 0:56:27  iter: 419  total_loss: 1.003  loss_cls: 0.6965  loss_box_reg: 0.3094  time: 0.8768  last_time: 0.8276  data_time: 0.0583  last_data_time: 0.0567   lr: 0.0041958  max_mem: 21296M
[02/26 21:30:50] d2.utils.events INFO:  eta: 0:56:09  iter: 439  total_loss: 0.9571  loss_cls: 0.6746  loss_box_reg: 0.2879  time: 0.8767  last_time: 0.8697  data_time: 0.0589  last_data_time: 0.0500   lr: 0.0043956  max_mem: 21296M
[02/26 21:31:08] d2.utils.events INFO:  eta: 0:55:52  iter: 459  total_loss: 0.9821  loss_cls: 0.6818  loss_box_reg: 0.2966  time: 0.8765  last_time: 0.8753  data_time: 0.0590  last_data_time: 0.0580   lr: 0.0045954  max_mem: 21296M
[02/26 21:31:25] d2.utils.events INFO:  eta: 0:55:34  iter: 479  total_loss: 1.021  loss_cls: 0.7114  loss_box_reg: 0.2928  time: 0.8763  last_time: 0.8682  data_time: 0.0598  last_data_time: 0.0503   lr: 0.0047952  max_mem: 21296M
[02/26 21:31:43] d2.utils.events INFO:  eta: 0:55:16  iter: 499  total_loss: 0.9596  loss_cls: 0.6781  loss_box_reg: 0.2871  time: 0.8763  last_time: 0.8780  data_time: 0.0583  last_data_time: 0.0587   lr: 0.004995  max_mem: 21296M
[02/26 21:32:00] d2.utils.events INFO:  eta: 0:54:59  iter: 519  total_loss: 0.9276  loss_cls: 0.6469  loss_box_reg: 0.2773  time: 0.8763  last_time: 0.8757  data_time: 0.0577  last_data_time: 0.0564   lr: 0.0051948  max_mem: 21296M
[02/26 21:32:18] d2.utils.events INFO:  eta: 0:54:41  iter: 539  total_loss: 0.8866  loss_cls: 0.629  loss_box_reg: 0.2601  time: 0.8762  last_time: 0.8736  data_time: 0.0599  last_data_time: 0.0556   lr: 0.0053946  max_mem: 21296M
[02/26 21:32:35] d2.utils.events INFO:  eta: 0:54:24  iter: 559  total_loss: 0.8895  loss_cls: 0.6276  loss_box_reg: 0.2601  time: 0.8764  last_time: 0.8797  data_time: 0.0617  last_data_time: 0.0601   lr: 0.0055944  max_mem: 21296M
[02/26 21:32:53] d2.utils.events INFO:  eta: 0:54:06  iter: 579  total_loss: 0.8708  loss_cls: 0.6017  loss_box_reg: 0.2645  time: 0.8765  last_time: 0.8267  data_time: 0.0619  last_data_time: 0.0566   lr: 0.0057942  max_mem: 21296M
[02/26 21:33:10] d2.utils.events INFO:  eta: 0:53:49  iter: 599  total_loss: 0.8575  loss_cls: 0.6019  loss_box_reg: 0.253  time: 0.8764  last_time: 0.8696  data_time: 0.0620  last_data_time: 0.0497   lr: 0.005994  max_mem: 21296M
[02/26 21:33:28] d2.utils.events INFO:  eta: 0:53:32  iter: 619  total_loss: 0.8534  loss_cls: 0.5939  loss_box_reg: 0.2552  time: 0.8766  last_time: 0.8868  data_time: 0.0618  last_data_time: 0.0672   lr: 0.0061938  max_mem: 21296M
[02/26 21:33:46] d2.utils.events INFO:  eta: 0:53:15  iter: 639  total_loss: 0.8225  loss_cls: 0.5695  loss_box_reg: 0.2529  time: 0.8765  last_time: 0.8822  data_time: 0.0631  last_data_time: 0.0635   lr: 0.0063936  max_mem: 21296M
[02/26 21:34:03] d2.utils.events INFO:  eta: 0:52:57  iter: 659  total_loss: 0.8013  loss_cls: 0.5523  loss_box_reg: 0.2457  time: 0.8765  last_time: 0.8832  data_time: 0.0606  last_data_time: 0.0646   lr: 0.0065934  max_mem: 21296M
[02/26 21:34:21] d2.utils.events INFO:  eta: 0:52:40  iter: 679  total_loss: 0.8148  loss_cls: 0.559  loss_box_reg: 0.2522  time: 0.8767  last_time: 0.8773  data_time: 0.0632  last_data_time: 0.0582   lr: 0.0067932  max_mem: 21296M
[02/26 21:34:38] d2.utils.events INFO:  eta: 0:52:22  iter: 699  total_loss: 1.059  loss_cls: 0.7758  loss_box_reg: 0.2777  time: 0.8763  last_time: 0.8837  data_time: 0.0594  last_data_time: 0.0643   lr: 0.006993  max_mem: 21296M
[02/26 21:34:55] d2.utils.events INFO:  eta: 0:52:05  iter: 719  total_loss: 0.9364  loss_cls: 0.6559  loss_box_reg: 0.2767  time: 0.8761  last_time: 0.8834  data_time: 0.0614  last_data_time: 0.0644   lr: 0.0071928  max_mem: 21296M
[02/26 21:35:13] d2.utils.events INFO:  eta: 0:51:47  iter: 739  total_loss: 0.8025  loss_cls: 0.5606  loss_box_reg: 0.2395  time: 0.8761  last_time: 0.8798  data_time: 0.0591  last_data_time: 0.0601   lr: 0.0073926  max_mem: 21296M
[02/26 21:35:31] d2.utils.events INFO:  eta: 0:51:30  iter: 759  total_loss: 0.7716  loss_cls: 0.5345  loss_box_reg: 0.2367  time: 0.8762  last_time: 0.8855  data_time: 0.0619  last_data_time: 0.0664   lr: 0.0075924  max_mem: 21296M
[02/26 21:35:48] d2.utils.events INFO:  eta: 0:51:13  iter: 779  total_loss: 0.7395  loss_cls: 0.5015  loss_box_reg: 0.2357  time: 0.8762  last_time: 0.8773  data_time: 0.0627  last_data_time: 0.0568   lr: 0.0077922  max_mem: 21296M
[02/26 21:36:06] d2.utils.events INFO:  eta: 0:50:55  iter: 799  total_loss: 0.7154  loss_cls: 0.4749  loss_box_reg: 0.2369  time: 0.8761  last_time: 0.8707  data_time: 0.0576  last_data_time: 0.0535   lr: 0.007992  max_mem: 21296M
[02/26 21:36:23] d2.utils.events INFO:  eta: 0:50:38  iter: 819  total_loss: 0.6753  loss_cls: 0.445  loss_box_reg: 0.2252  time: 0.8761  last_time: 0.8773  data_time: 0.0593  last_data_time: 0.0599   lr: 0.0081918  max_mem: 21296M
[02/26 21:36:41] d2.utils.events INFO:  eta: 0:50:20  iter: 839  total_loss: 0.6743  loss_cls: 0.4378  loss_box_reg: 0.2363  time: 0.8762  last_time: 0.8845  data_time: 0.0616  last_data_time: 0.0662   lr: 0.0083916  max_mem: 21296M
[02/26 21:36:58] d2.utils.events INFO:  eta: 0:50:03  iter: 859  total_loss: 0.6159  loss_cls: 0.3969  loss_box_reg: 0.2171  time: 0.8762  last_time: 0.8850  data_time: 0.0611  last_data_time: 0.0661   lr: 0.0085914  max_mem: 21296M
[02/26 21:37:16] d2.utils.events INFO:  eta: 0:49:45  iter: 879  total_loss: 0.6221  loss_cls: 0.3892  loss_box_reg: 0.2319  time: 0.8762  last_time: 0.8830  data_time: 0.0613  last_data_time: 0.0639   lr: 0.0087912  max_mem: 21296M
[02/26 21:37:33] d2.utils.events INFO:  eta: 0:49:28  iter: 899  total_loss: 0.6116  loss_cls: 0.3822  loss_box_reg: 0.2317  time: 0.8763  last_time: 0.8376  data_time: 0.0620  last_data_time: 0.0669   lr: 0.008991  max_mem: 21296M
[02/26 21:37:51] d2.utils.events INFO:  eta: 0:49:10  iter: 919  total_loss: 0.5921  loss_cls: 0.3694  loss_box_reg: 0.2179  time: 0.8762  last_time: 0.8848  data_time: 0.0594  last_data_time: 0.0651   lr: 0.0091908  max_mem: 21296M
[02/26 21:38:08] d2.utils.events INFO:  eta: 0:48:52  iter: 939  total_loss: 0.5518  loss_cls: 0.3304  loss_box_reg: 0.2221  time: 0.8762  last_time: 0.8753  data_time: 0.0601  last_data_time: 0.0573   lr: 0.0093906  max_mem: 21296M
[02/26 21:38:26] d2.utils.events INFO:  eta: 0:48:35  iter: 959  total_loss: 0.5311  loss_cls: 0.3171  loss_box_reg: 0.2195  time: 0.8764  last_time: 0.8752  data_time: 0.0630  last_data_time: 0.0578   lr: 0.0095904  max_mem: 21296M
[02/26 21:38:44] d2.utils.events INFO:  eta: 0:48:18  iter: 979  total_loss: 0.508  loss_cls: 0.295  loss_box_reg: 0.2116  time: 0.8764  last_time: 0.8761  data_time: 0.0589  last_data_time: 0.0582   lr: 0.0097902  max_mem: 21296M
[02/26 21:39:01] d2.utils.events INFO:  eta: 0:48:00  iter: 999  total_loss: 0.5629  loss_cls: 0.3488  loss_box_reg: 0.2168  time: 0.8763  last_time: 0.8871  data_time: 0.0599  last_data_time: 0.0672   lr: 0.00999  max_mem: 21296M
[02/26 21:39:18] d2.utils.events INFO:  eta: 0:47:43  iter: 1019  total_loss: 0.5363  loss_cls: 0.3135  loss_box_reg: 0.2186  time: 0.8762  last_time: 0.8822  data_time: 0.0613  last_data_time: 0.0644   lr: 0.01  max_mem: 21296M
[02/26 21:39:36] d2.utils.events INFO:  eta: 0:47:26  iter: 1039  total_loss: 0.4991  loss_cls: 0.2814  loss_box_reg: 0.2161  time: 0.8762  last_time: 0.8794  data_time: 0.0622  last_data_time: 0.0616   lr: 0.01  max_mem: 21296M
[02/26 21:39:54] d2.utils.events INFO:  eta: 0:47:08  iter: 1059  total_loss: 0.4852  loss_cls: 0.2724  loss_box_reg: 0.219  time: 0.8763  last_time: 0.8869  data_time: 0.0613  last_data_time: 0.0675   lr: 0.01  max_mem: 21296M
[02/26 21:40:11] d2.utils.events INFO:  eta: 0:46:51  iter: 1079  total_loss: 0.4665  loss_cls: 0.2573  loss_box_reg: 0.2067  time: 0.8763  last_time: 0.8836  data_time: 0.0608  last_data_time: 0.0651   lr: 0.01  max_mem: 21296M
[02/26 21:40:29] d2.utils.events INFO:  eta: 0:46:33  iter: 1099  total_loss: 0.4508  loss_cls: 0.2482  loss_box_reg: 0.2016  time: 0.8763  last_time: 0.8772  data_time: 0.0602  last_data_time: 0.0583   lr: 0.01  max_mem: 21296M
[02/26 21:40:46] d2.utils.events INFO:  eta: 0:46:16  iter: 1119  total_loss: 0.4676  loss_cls: 0.2538  loss_box_reg: 0.2118  time: 0.8763  last_time: 0.8674  data_time: 0.0605  last_data_time: 0.0483   lr: 0.01  max_mem: 21296M
[02/26 21:41:04] d2.utils.events INFO:  eta: 0:45:59  iter: 1139  total_loss: 0.4448  loss_cls: 0.2398  loss_box_reg: 0.2062  time: 0.8763  last_time: 0.8836  data_time: 0.0615  last_data_time: 0.0648   lr: 0.01  max_mem: 21296M
[02/26 21:41:21] d2.utils.events INFO:  eta: 0:45:41  iter: 1159  total_loss: 0.4381  loss_cls: 0.2357  loss_box_reg: 0.2  time: 0.8763  last_time: 0.8836  data_time: 0.0630  last_data_time: 0.0658   lr: 0.01  max_mem: 21296M
[02/26 21:41:39] d2.utils.events INFO:  eta: 0:45:24  iter: 1179  total_loss: 0.4391  loss_cls: 0.2331  loss_box_reg: 0.2086  time: 0.8763  last_time: 0.8396  data_time: 0.0599  last_data_time: 0.0680   lr: 0.01  max_mem: 21296M
[02/26 21:41:56] d2.utils.events INFO:  eta: 0:45:06  iter: 1199  total_loss: 0.4363  loss_cls: 0.2314  loss_box_reg: 0.2041  time: 0.8762  last_time: 0.8277  data_time: 0.0594  last_data_time: 0.0561   lr: 0.01  max_mem: 21296M
[02/26 21:42:14] d2.utils.events INFO:  eta: 0:44:49  iter: 1219  total_loss: 0.4227  loss_cls: 0.2235  loss_box_reg: 0.1992  time: 0.8763  last_time: 0.8694  data_time: 0.0641  last_data_time: 0.0506   lr: 0.01  max_mem: 21296M
[02/26 21:42:31] d2.utils.events INFO:  eta: 0:44:31  iter: 1239  total_loss: 0.4013  loss_cls: 0.2104  loss_box_reg: 0.1897  time: 0.8762  last_time: 0.8742  data_time: 0.0614  last_data_time: 0.0537   lr: 0.01  max_mem: 21296M
[02/26 21:42:49] d2.utils.events INFO:  eta: 0:44:13  iter: 1259  total_loss: 0.4095  loss_cls: 0.2171  loss_box_reg: 0.193  time: 0.8762  last_time: 0.8762  data_time: 0.0589  last_data_time: 0.0573   lr: 0.01  max_mem: 21296M
[02/26 21:43:06] d2.utils.events INFO:  eta: 0:43:56  iter: 1279  total_loss: 0.4043  loss_cls: 0.212  loss_box_reg: 0.1943  time: 0.8762  last_time: 0.8825  data_time: 0.0617  last_data_time: 0.0637   lr: 0.01  max_mem: 21296M
[02/26 21:43:24] d2.utils.events INFO:  eta: 0:43:39  iter: 1299  total_loss: 0.3923  loss_cls: 0.2028  loss_box_reg: 0.1924  time: 0.8762  last_time: 0.8758  data_time: 0.0608  last_data_time: 0.0578   lr: 0.01  max_mem: 21296M
[02/26 21:43:41] d2.utils.events INFO:  eta: 0:43:21  iter: 1319  total_loss: 0.3952  loss_cls: 0.2013  loss_box_reg: 0.196  time: 0.8762  last_time: 0.8751  data_time: 0.0586  last_data_time: 0.0567   lr: 0.01  max_mem: 21296M
[02/26 21:43:59] d2.utils.events INFO:  eta: 0:43:03  iter: 1339  total_loss: 0.391  loss_cls: 0.1991  loss_box_reg: 0.1938  time: 0.8762  last_time: 0.8795  data_time: 0.0620  last_data_time: 0.0599   lr: 0.01  max_mem: 21296M
[02/26 21:44:16] d2.utils.events INFO:  eta: 0:42:45  iter: 1359  total_loss: 0.39  loss_cls: 0.1999  loss_box_reg: 0.1913  time: 0.8761  last_time: 0.8737  data_time: 0.0583  last_data_time: 0.0537   lr: 0.01  max_mem: 21296M
[02/26 21:44:34] d2.utils.events INFO:  eta: 0:42:27  iter: 1379  total_loss: 0.3895  loss_cls: 0.1965  loss_box_reg: 0.1914  time: 0.8762  last_time: 0.8703  data_time: 0.0591  last_data_time: 0.0522   lr: 0.01  max_mem: 21296M
[02/26 21:44:52] d2.utils.events INFO:  eta: 0:42:11  iter: 1399  total_loss: 0.3841  loss_cls: 0.1929  loss_box_reg: 0.1898  time: 0.8762  last_time: 0.8736  data_time: 0.0614  last_data_time: 0.0554   lr: 0.01  max_mem: 21296M
[02/26 21:45:09] d2.utils.events INFO:  eta: 0:41:53  iter: 1419  total_loss: 0.3858  loss_cls: 0.1954  loss_box_reg: 0.1902  time: 0.8762  last_time: 0.8323  data_time: 0.0623  last_data_time: 0.0598   lr: 0.01  max_mem: 21296M
[02/26 21:45:15] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0001426.pth
[02/26 21:45:16] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 21:45:16] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/26 21:45:16] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/26 21:45:16] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 21:45:16] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/26 21:45:16] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/26 21:45:16] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/26 21:45:17] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0003 s/iter. Inference: 0.0289 s/iter. Eval: 0.0002 s/iter. Total: 0.0294 s/iter. ETA=0:00:04
[02/26 21:45:21] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.643079 (0.029955 s / iter per device, on 1 devices)
[02/26 21:45:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.028878 s / iter per device, on 1 devices)
[02/26 21:45:21] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/26 21:45:21] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/26 21:45:21] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/26 21:45:21] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/26 21:45:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.20 seconds.
[02/26 21:45:22] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/26 21:45:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.11 seconds.
[02/26 21:45:22] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 11.295 | 19.551 | 11.602 | 5.435 | 18.760 | 24.186 |
[02/26 21:45:22] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 10.231 | 001_binder_clips_median      | 18.433 | 002_binder_clips_small       | 13.187 |
| 003_bombik_bucket          | 10.791 | 004_bonne_maman_blueberry    | 0.147  | 005_bonne_maman_raspberry    | 0.192  |
| 006_bonne_maman_strawberry | 0.034  | 007_costa_caramel            | 26.107 | 008_essential_oil_bergamot   | 15.667 |
| 009_garlic_toast_spread    | 4.004  | 010_handcream_avocado        | 0.557  | 011_hb_calcium               | 14.123 |
| 012_hb_grapeseed           | 8.306  | 013_hb_marine_collagen       | 5.621  | 014_hellmanns_mayonnaise     | 3.010  |
| 015_illy_blend             | 0.434  | 016_japanese_finger_cookies  | 2.462  | 017_john_west_canned_tuna    | 2.882  |
| 018_kerastase_shampoo      | 12.166 | 019_kiehls_facial_cream      | 24.003 | 020_kiihne_balsamic          | 0.116  |
| 021_kiihne_honey_mustard   | 4.564  | 022_lindor_matcha            | 23.455 | 023_lindor_salted_caramel    | 28.171 |
| 024_lush_mask              | 60.420 | 025_pasta_sauce_black_pepper | 1.021  | 026_pasta_sauce_tomato       | 6.550  |
| 027_pepsi                  | 30.961 | 028_portable_yogurt_machine  | 0.050  | 029_selfile_stick            | 0.813  |
| 030_sour_lemon_drops       | 6.308  | 031_sticky_notes             | 9.326  | 032_stridex_green            | 37.142 |
| 033_thermos_flask_cream    | 37.973 | 034_thermos_flask_muji       | 0.906  | 035_thermos_flask_sliver     | 0.330  |
| 036_tragata_olive_oil      | 1.566  | 037_tulip_luncheon_meat      | 2.818  | 038_unicharm_cotton_pad      | 32.544 |
| 039_vinda_tissue           | 32.708 | 040_wrigley_doublemint_gum   | 0.414  | 041_baseball_cap_black       | 6.367  |
| 042_baseball_cap_pink      | 19.625 | 043_bfe_facial_mask          | 26.020 | 044_corgi_doll               | 7.446  |
| 045_dinosaur_doll          | 35.390 | 046_geo_mocha                | 3.177  | 047_geo_roast_charcoal       | 0.938  |
| 048_instant_noodle_black   | 1.775  | 049_instant_noodle_red       | 19.002 | 050_nabati_cheese_wafer      | 37.693 |
| 051_truffettes             | 7.630  | 052_acnes_cream              | 0.897  | 053_aveda_conditioner        | 20.025 |
| 054_banana_milk_drink      | 3.559  | 055_candle_beast             | 14.239 | 056_china_persimmon          | 9.871  |
| 057_danisa_butter_cookies  | 4.617  | 058_effaclar_duo             | 4.906  | 059_evelom_cleanser          | 5.316  |
| 060_glasses_box_blone      | 10.889 | 061_handcream_iris           | 0.000  | 062_handcream_lavender       | 0.000  |
| 063_handcream_rosewater    | 0.298  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 0.363  |
| 066_japanese_chocolate     | 34.515 | 067_kerastase_hair_treatment | 6.060  | 068_kiehls_serum             | 16.386 |
| 069_korean_beef_marinade   | 11.963 | 070_korean_doenjang          | 13.289 | 071_korean_gochujang         | 0.080  |
| 072_korean_ssamjang        | 15.871 | 073_loccitane_soap           | 13.232 | 074_marvis_toothpaste_purple | 33.399 |
| 075_mouse_thinkpad         | 5.494  | 076_oatly_chocolate          | 9.426  | 077_oatly_original           | 14.421 |
| 078_ousa_grated_cheese     | 4.777  | 079_polaroid_film            | 1.694  | 080_skinceuticals_be         | 33.181 |
| 081_skinceuticals_cf       | 13.441 | 082_skinceuticals_phyto      | 16.403 | 083_stapler_black            | 8.056  |
| 084_stapler_blue           | 10.523 | 085_sunscreen_blue           | 0.084  | 086_tempo_pocket_tissue      | 1.417  |
| 087_thermos_flask_purple   | 34.691 | 088_uha_matcha               | 9.046  | 089_urban_decay_spray        | 7.737  |
| 090_vitaboost_multivitamin | 11.319 | 091_watercolor_penbox        | 0.016  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 9.336  | 094_kaneyo_kitchen_bleach    | 15.208 | 095_lays_chip_bag_blue       | 8.218  |
| 096_lays_chip_bag_green    | 5.146  | 097_lays_chip_tube_auburn    | 10.468 | 098_lays_chip_tube_green     | 24.005 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/26 21:45:22] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/26 21:45:22] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/26 21:45:22] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/26 21:45:22] d2.evaluation.testing INFO: copypaste: 11.2946,19.5514,11.6021,5.4346,18.7601,24.1863
[02/26 21:45:32] d2.utils.events INFO:  eta: 0:41:36  iter: 1439  total_loss: 0.3774  loss_cls: 0.1865  loss_box_reg: 0.188  time: 0.8762  last_time: 0.8749  data_time: 0.0583  last_data_time: 0.0573   lr: 0.01  max_mem: 21296M
[02/26 21:45:50] d2.utils.events INFO:  eta: 0:41:18  iter: 1459  total_loss: 0.3789  loss_cls: 0.1932  loss_box_reg: 0.1861  time: 0.8762  last_time: 0.8771  data_time: 0.0595  last_data_time: 0.0578   lr: 0.01  max_mem: 21296M
[02/26 21:46:07] d2.utils.events INFO:  eta: 0:41:01  iter: 1479  total_loss: 0.3728  loss_cls: 0.1864  loss_box_reg: 0.1861  time: 0.8762  last_time: 0.8831  data_time: 0.0630  last_data_time: 0.0651   lr: 0.01  max_mem: 21296M
[02/26 21:46:25] d2.utils.events INFO:  eta: 0:40:43  iter: 1499  total_loss: 0.3615  loss_cls: 0.1761  loss_box_reg: 0.1848  time: 0.8761  last_time: 0.8775  data_time: 0.0602  last_data_time: 0.0595   lr: 0.01  max_mem: 21296M
[02/26 21:46:42] d2.utils.events INFO:  eta: 0:40:26  iter: 1519  total_loss: 0.3577  loss_cls: 0.178  loss_box_reg: 0.1831  time: 0.8762  last_time: 0.8724  data_time: 0.0615  last_data_time: 0.0535   lr: 0.01  max_mem: 21296M
[02/26 21:47:00] d2.utils.events INFO:  eta: 0:40:09  iter: 1539  total_loss: 0.3521  loss_cls: 0.1726  loss_box_reg: 0.1822  time: 0.8762  last_time: 0.8790  data_time: 0.0611  last_data_time: 0.0596   lr: 0.01  max_mem: 21296M
[02/26 21:47:17] d2.utils.events INFO:  eta: 0:39:51  iter: 1559  total_loss: 0.3501  loss_cls: 0.1726  loss_box_reg: 0.1789  time: 0.8762  last_time: 0.8790  data_time: 0.0596  last_data_time: 0.0595   lr: 0.01  max_mem: 21296M
[02/26 21:47:35] d2.utils.events INFO:  eta: 0:39:33  iter: 1579  total_loss: 0.3557  loss_cls: 0.1713  loss_box_reg: 0.1841  time: 0.8762  last_time: 0.8814  data_time: 0.0617  last_data_time: 0.0614   lr: 0.01  max_mem: 21296M
[02/26 21:47:53] d2.utils.events INFO:  eta: 0:39:16  iter: 1599  total_loss: 0.3541  loss_cls: 0.176  loss_box_reg: 0.1797  time: 0.8762  last_time: 0.8780  data_time: 0.0596  last_data_time: 0.0591   lr: 0.01  max_mem: 21296M
[02/26 21:48:10] d2.utils.events INFO:  eta: 0:38:58  iter: 1619  total_loss: 0.3538  loss_cls: 0.1733  loss_box_reg: 0.181  time: 0.8763  last_time: 0.8860  data_time: 0.0640  last_data_time: 0.0676   lr: 0.01  max_mem: 21296M
[02/26 21:48:28] d2.utils.events INFO:  eta: 0:38:40  iter: 1639  total_loss: 0.3607  loss_cls: 0.1742  loss_box_reg: 0.1823  time: 0.8762  last_time: 0.8944  data_time: 0.0618  last_data_time: 0.0740   lr: 0.01  max_mem: 21296M
[02/26 21:48:45] d2.utils.events INFO:  eta: 0:38:23  iter: 1659  total_loss: 0.3368  loss_cls: 0.1642  loss_box_reg: 0.1768  time: 0.8763  last_time: 0.8756  data_time: 0.0644  last_data_time: 0.0581   lr: 0.01  max_mem: 21296M
[02/26 21:49:03] d2.utils.events INFO:  eta: 0:38:05  iter: 1679  total_loss: 0.3494  loss_cls: 0.1699  loss_box_reg: 0.1783  time: 0.8762  last_time: 0.8722  data_time: 0.0629  last_data_time: 0.0524   lr: 0.01  max_mem: 21296M
[02/26 21:49:20] d2.utils.events INFO:  eta: 0:37:48  iter: 1699  total_loss: 0.3501  loss_cls: 0.1671  loss_box_reg: 0.1805  time: 0.8763  last_time: 0.8786  data_time: 0.0608  last_data_time: 0.0592   lr: 0.01  max_mem: 21296M
[02/26 21:49:38] d2.utils.events INFO:  eta: 0:37:30  iter: 1719  total_loss: 0.3365  loss_cls: 0.1612  loss_box_reg: 0.1768  time: 0.8762  last_time: 0.8363  data_time: 0.0606  last_data_time: 0.0643   lr: 0.01  max_mem: 21296M
[02/26 21:49:55] d2.utils.events INFO:  eta: 0:37:13  iter: 1739  total_loss: 0.3388  loss_cls: 0.1599  loss_box_reg: 0.1777  time: 0.8762  last_time: 0.8759  data_time: 0.0611  last_data_time: 0.0581   lr: 0.01  max_mem: 21296M
[02/26 21:50:13] d2.utils.events INFO:  eta: 0:36:55  iter: 1759  total_loss: 0.3444  loss_cls: 0.1621  loss_box_reg: 0.1793  time: 0.8761  last_time: 0.8703  data_time: 0.0607  last_data_time: 0.0514   lr: 0.01  max_mem: 21296M
[02/26 21:50:30] d2.utils.events INFO:  eta: 0:36:37  iter: 1779  total_loss: 0.3349  loss_cls: 0.1584  loss_box_reg: 0.1751  time: 0.8761  last_time: 0.8753  data_time: 0.0606  last_data_time: 0.0560   lr: 0.01  max_mem: 21296M
[02/26 21:50:48] d2.utils.events INFO:  eta: 0:36:20  iter: 1799  total_loss: 0.3168  loss_cls: 0.1509  loss_box_reg: 0.1666  time: 0.8762  last_time: 0.8731  data_time: 0.0637  last_data_time: 0.0533   lr: 0.01  max_mem: 21296M
[02/26 21:51:05] d2.utils.events INFO:  eta: 0:36:03  iter: 1819  total_loss: 0.3317  loss_cls: 0.158  loss_box_reg: 0.1773  time: 0.8762  last_time: 0.8721  data_time: 0.0612  last_data_time: 0.0543   lr: 0.01  max_mem: 21296M
[02/26 21:51:23] d2.utils.events INFO:  eta: 0:35:45  iter: 1839  total_loss: 0.3398  loss_cls: 0.1636  loss_box_reg: 0.1753  time: 0.8762  last_time: 0.8685  data_time: 0.0615  last_data_time: 0.0506   lr: 0.01  max_mem: 21296M
[02/26 21:51:41] d2.utils.events INFO:  eta: 0:35:27  iter: 1859  total_loss: 0.3195  loss_cls: 0.1526  loss_box_reg: 0.1682  time: 0.8762  last_time: 0.8756  data_time: 0.0607  last_data_time: 0.0563   lr: 0.01  max_mem: 21296M
[02/26 21:51:58] d2.utils.events INFO:  eta: 0:35:10  iter: 1879  total_loss: 0.3214  loss_cls: 0.1503  loss_box_reg: 0.1718  time: 0.8762  last_time: 0.8784  data_time: 0.0580  last_data_time: 0.0587   lr: 0.01  max_mem: 21296M
[02/26 21:52:16] d2.utils.events INFO:  eta: 0:34:52  iter: 1899  total_loss: 0.3221  loss_cls: 0.1501  loss_box_reg: 0.1708  time: 0.8762  last_time: 0.8911  data_time: 0.0598  last_data_time: 0.0718   lr: 0.01  max_mem: 21296M
[02/26 21:52:33] d2.utils.events INFO:  eta: 0:34:34  iter: 1919  total_loss: 0.3251  loss_cls: 0.153  loss_box_reg: 0.1736  time: 0.8762  last_time: 0.8764  data_time: 0.0608  last_data_time: 0.0585   lr: 0.01  max_mem: 21296M
[02/26 21:52:50] d2.utils.events INFO:  eta: 0:34:17  iter: 1939  total_loss: 0.313  loss_cls: 0.147  loss_box_reg: 0.1641  time: 0.8761  last_time: 0.8752  data_time: 0.0560  last_data_time: 0.0560   lr: 0.01  max_mem: 21296M
[02/26 21:53:08] d2.utils.events INFO:  eta: 0:33:59  iter: 1959  total_loss: 0.3301  loss_cls: 0.156  loss_box_reg: 0.1773  time: 0.8761  last_time: 0.8707  data_time: 0.0568  last_data_time: 0.0509   lr: 0.01  max_mem: 21296M
[02/26 21:53:25] d2.utils.events INFO:  eta: 0:33:41  iter: 1979  total_loss: 0.3201  loss_cls: 0.1482  loss_box_reg: 0.1699  time: 0.8761  last_time: 0.8888  data_time: 0.0597  last_data_time: 0.0694   lr: 0.01  max_mem: 21296M
[02/26 21:53:43] d2.utils.events INFO:  eta: 0:33:23  iter: 1999  total_loss: 0.3245  loss_cls: 0.1471  loss_box_reg: 0.1746  time: 0.8761  last_time: 0.8821  data_time: 0.0597  last_data_time: 0.0613   lr: 0.01  max_mem: 21296M
[02/26 21:54:00] d2.utils.events INFO:  eta: 0:33:06  iter: 2019  total_loss: 0.3074  loss_cls: 0.1436  loss_box_reg: 0.1637  time: 0.8761  last_time: 0.8706  data_time: 0.0590  last_data_time: 0.0505   lr: 0.01  max_mem: 21296M
[02/26 21:54:18] d2.utils.events INFO:  eta: 0:32:48  iter: 2039  total_loss: 0.3076  loss_cls: 0.143  loss_box_reg: 0.1634  time: 0.8761  last_time: 0.8767  data_time: 0.0601  last_data_time: 0.0586   lr: 0.01  max_mem: 21296M
[02/26 21:54:36] d2.utils.events INFO:  eta: 0:32:31  iter: 2059  total_loss: 0.3175  loss_cls: 0.1486  loss_box_reg: 0.1683  time: 0.8761  last_time: 0.8692  data_time: 0.0599  last_data_time: 0.0493   lr: 0.01  max_mem: 21296M
[02/26 21:54:53] d2.utils.events INFO:  eta: 0:32:13  iter: 2079  total_loss: 0.311  loss_cls: 0.1452  loss_box_reg: 0.1657  time: 0.8761  last_time: 0.8702  data_time: 0.0616  last_data_time: 0.0516   lr: 0.01  max_mem: 21296M
[02/26 21:55:10] d2.utils.events INFO:  eta: 0:31:56  iter: 2099  total_loss: 0.3079  loss_cls: 0.1433  loss_box_reg: 0.1656  time: 0.8761  last_time: 0.8844  data_time: 0.0636  last_data_time: 0.0662   lr: 0.01  max_mem: 21296M
[02/26 21:55:28] d2.utils.events INFO:  eta: 0:31:38  iter: 2119  total_loss: 0.3064  loss_cls: 0.1408  loss_box_reg: 0.1651  time: 0.8760  last_time: 0.8770  data_time: 0.0601  last_data_time: 0.0586   lr: 0.01  max_mem: 21296M
[02/26 21:55:45] d2.utils.events INFO:  eta: 0:31:20  iter: 2139  total_loss: 0.3132  loss_cls: 0.1433  loss_box_reg: 0.169  time: 0.8760  last_time: 0.8859  data_time: 0.0595  last_data_time: 0.0665   lr: 0.01  max_mem: 21296M
[02/26 21:56:03] d2.utils.events INFO:  eta: 0:31:02  iter: 2159  total_loss: 0.3122  loss_cls: 0.1441  loss_box_reg: 0.1674  time: 0.8760  last_time: 0.8850  data_time: 0.0596  last_data_time: 0.0664   lr: 0.01  max_mem: 21296M
[02/26 21:56:20] d2.utils.events INFO:  eta: 0:30:45  iter: 2179  total_loss: 0.3092  loss_cls: 0.142  loss_box_reg: 0.1679  time: 0.8760  last_time: 0.8785  data_time: 0.0606  last_data_time: 0.0590   lr: 0.01  max_mem: 21296M
[02/26 21:56:38] d2.utils.events INFO:  eta: 0:30:28  iter: 2199  total_loss: 0.3066  loss_cls: 0.1368  loss_box_reg: 0.169  time: 0.8760  last_time: 0.8829  data_time: 0.0620  last_data_time: 0.0645   lr: 0.01  max_mem: 21296M
[02/26 21:56:56] d2.utils.events INFO:  eta: 0:30:10  iter: 2219  total_loss: 0.3071  loss_cls: 0.1433  loss_box_reg: 0.1644  time: 0.8760  last_time: 0.8807  data_time: 0.0626  last_data_time: 0.0625   lr: 0.01  max_mem: 21296M
[02/26 21:57:13] d2.utils.events INFO:  eta: 0:29:53  iter: 2239  total_loss: 0.3022  loss_cls: 0.1376  loss_box_reg: 0.1633  time: 0.8760  last_time: 0.8867  data_time: 0.0605  last_data_time: 0.0684   lr: 0.01  max_mem: 21296M
[02/26 21:57:31] d2.utils.events INFO:  eta: 0:29:35  iter: 2259  total_loss: 0.2939  loss_cls: 0.1325  loss_box_reg: 0.1625  time: 0.8761  last_time: 0.8702  data_time: 0.0632  last_data_time: 0.0518   lr: 0.01  max_mem: 21296M
[02/26 21:57:48] d2.utils.events INFO:  eta: 0:29:18  iter: 2279  total_loss: 0.2961  loss_cls: 0.1346  loss_box_reg: 0.1617  time: 0.8761  last_time: 0.8700  data_time: 0.0619  last_data_time: 0.0513   lr: 0.01  max_mem: 21296M
[02/26 21:58:06] d2.utils.events INFO:  eta: 0:29:01  iter: 2299  total_loss: 0.2893  loss_cls: 0.1276  loss_box_reg: 0.1592  time: 0.8761  last_time: 0.8775  data_time: 0.0601  last_data_time: 0.0580   lr: 0.01  max_mem: 21296M
[02/26 21:58:24] d2.utils.events INFO:  eta: 0:28:43  iter: 2319  total_loss: 0.2972  loss_cls: 0.1315  loss_box_reg: 0.1655  time: 0.8762  last_time: 0.8737  data_time: 0.0608  last_data_time: 0.0547   lr: 0.01  max_mem: 21296M
[02/26 21:58:41] d2.utils.events INFO:  eta: 0:28:25  iter: 2339  total_loss: 0.2849  loss_cls: 0.125  loss_box_reg: 0.1566  time: 0.8761  last_time: 0.8723  data_time: 0.0610  last_data_time: 0.0533   lr: 0.01  max_mem: 21296M
[02/26 21:58:59] d2.utils.events INFO:  eta: 0:28:08  iter: 2359  total_loss: 0.2862  loss_cls: 0.1276  loss_box_reg: 0.1588  time: 0.8762  last_time: 0.8942  data_time: 0.0637  last_data_time: 0.0754   lr: 0.01  max_mem: 21296M
[02/26 21:59:16] d2.utils.events INFO:  eta: 0:27:51  iter: 2379  total_loss: 0.2893  loss_cls: 0.1268  loss_box_reg: 0.1609  time: 0.8762  last_time: 0.8743  data_time: 0.0597  last_data_time: 0.0565   lr: 0.01  max_mem: 21296M
[02/26 21:59:34] d2.utils.events INFO:  eta: 0:27:33  iter: 2399  total_loss: 0.2876  loss_cls: 0.1309  loss_box_reg: 0.1575  time: 0.8762  last_time: 0.8709  data_time: 0.0602  last_data_time: 0.0522   lr: 0.01  max_mem: 21296M
[02/26 21:59:51] d2.utils.events INFO:  eta: 0:27:15  iter: 2419  total_loss: 0.2864  loss_cls: 0.1303  loss_box_reg: 0.1601  time: 0.8762  last_time: 0.8730  data_time: 0.0611  last_data_time: 0.0542   lr: 0.01  max_mem: 21296M
[02/26 22:00:09] d2.utils.events INFO:  eta: 0:26:58  iter: 2439  total_loss: 0.2852  loss_cls: 0.1254  loss_box_reg: 0.1589  time: 0.8762  last_time: 0.8861  data_time: 0.0596  last_data_time: 0.0663   lr: 0.01  max_mem: 21296M
[02/26 22:00:26] d2.utils.events INFO:  eta: 0:26:40  iter: 2459  total_loss: 0.29  loss_cls: 0.1291  loss_box_reg: 0.1602  time: 0.8762  last_time: 0.8835  data_time: 0.0592  last_data_time: 0.0656   lr: 0.01  max_mem: 21296M
[02/26 22:00:44] d2.utils.events INFO:  eta: 0:26:22  iter: 2479  total_loss: 0.2837  loss_cls: 0.1248  loss_box_reg: 0.1578  time: 0.8762  last_time: 0.8901  data_time: 0.0606  last_data_time: 0.0705   lr: 0.01  max_mem: 21296M
[02/26 22:01:01] d2.utils.events INFO:  eta: 0:26:05  iter: 2499  total_loss: 0.2882  loss_cls: 0.1315  loss_box_reg: 0.1573  time: 0.8762  last_time: 0.8848  data_time: 0.0587  last_data_time: 0.0663   lr: 0.01  max_mem: 21296M
[02/26 22:01:19] d2.utils.events INFO:  eta: 0:25:47  iter: 2519  total_loss: 0.2774  loss_cls: 0.1225  loss_box_reg: 0.1542  time: 0.8762  last_time: 0.8778  data_time: 0.0615  last_data_time: 0.0589   lr: 0.01  max_mem: 21296M
[02/26 22:01:37] d2.utils.events INFO:  eta: 0:25:30  iter: 2539  total_loss: 0.2791  loss_cls: 0.1266  loss_box_reg: 0.1544  time: 0.8762  last_time: 0.8835  data_time: 0.0623  last_data_time: 0.0656   lr: 0.01  max_mem: 21296M
[02/26 22:01:54] d2.utils.events INFO:  eta: 0:25:12  iter: 2559  total_loss: 0.2817  loss_cls: 0.1261  loss_box_reg: 0.1579  time: 0.8762  last_time: 0.8878  data_time: 0.0599  last_data_time: 0.0689   lr: 0.01  max_mem: 21296M
[02/26 22:02:12] d2.utils.events INFO:  eta: 0:24:55  iter: 2579  total_loss: 0.2811  loss_cls: 0.1274  loss_box_reg: 0.1558  time: 0.8763  last_time: 0.8881  data_time: 0.0626  last_data_time: 0.0678   lr: 0.01  max_mem: 21296M
[02/26 22:02:29] d2.utils.events INFO:  eta: 0:24:37  iter: 2599  total_loss: 0.2843  loss_cls: 0.1275  loss_box_reg: 0.1594  time: 0.8762  last_time: 0.8962  data_time: 0.0633  last_data_time: 0.0772   lr: 0.01  max_mem: 21296M
[02/26 22:02:47] d2.utils.events INFO:  eta: 0:24:20  iter: 2619  total_loss: 0.2855  loss_cls: 0.1218  loss_box_reg: 0.1595  time: 0.8763  last_time: 0.8795  data_time: 0.0633  last_data_time: 0.0594   lr: 0.01  max_mem: 21296M
[02/26 22:03:04] d2.utils.events INFO:  eta: 0:24:02  iter: 2639  total_loss: 0.2832  loss_cls: 0.1255  loss_box_reg: 0.1575  time: 0.8763  last_time: 0.8301  data_time: 0.0614  last_data_time: 0.0591   lr: 0.01  max_mem: 21296M
[02/26 22:03:22] d2.utils.events INFO:  eta: 0:23:44  iter: 2659  total_loss: 0.2734  loss_cls: 0.1204  loss_box_reg: 0.1557  time: 0.8762  last_time: 0.8766  data_time: 0.0583  last_data_time: 0.0580   lr: 0.01  max_mem: 21296M
[02/26 22:03:39] d2.utils.events INFO:  eta: 0:23:27  iter: 2679  total_loss: 0.2791  loss_cls: 0.1241  loss_box_reg: 0.1546  time: 0.8762  last_time: 0.8789  data_time: 0.0587  last_data_time: 0.0606   lr: 0.01  max_mem: 21296M
[02/26 22:03:57] d2.utils.events INFO:  eta: 0:23:09  iter: 2699  total_loss: 0.2755  loss_cls: 0.1207  loss_box_reg: 0.1537  time: 0.8762  last_time: 0.8737  data_time: 0.0583  last_data_time: 0.0551   lr: 0.01  max_mem: 21296M
[02/26 22:04:14] d2.utils.events INFO:  eta: 0:22:52  iter: 2719  total_loss: 0.2664  loss_cls: 0.1161  loss_box_reg: 0.1484  time: 0.8762  last_time: 0.8797  data_time: 0.0606  last_data_time: 0.0610   lr: 0.01  max_mem: 21296M
[02/26 22:04:32] d2.utils.events INFO:  eta: 0:22:34  iter: 2739  total_loss: 0.2789  loss_cls: 0.1211  loss_box_reg: 0.1599  time: 0.8762  last_time: 0.8833  data_time: 0.0625  last_data_time: 0.0648   lr: 0.01  max_mem: 21296M
[02/26 22:04:49] d2.utils.events INFO:  eta: 0:22:17  iter: 2759  total_loss: 0.2754  loss_cls: 0.1206  loss_box_reg: 0.1538  time: 0.8762  last_time: 0.8298  data_time: 0.0619  last_data_time: 0.0586   lr: 0.01  max_mem: 21296M
[02/26 22:05:07] d2.utils.events INFO:  eta: 0:21:59  iter: 2779  total_loss: 0.2718  loss_cls: 0.1201  loss_box_reg: 0.1524  time: 0.8763  last_time: 0.8820  data_time: 0.0622  last_data_time: 0.0641   lr: 0.01  max_mem: 21296M
[02/26 22:05:25] d2.utils.events INFO:  eta: 0:21:42  iter: 2799  total_loss: 0.2887  loss_cls: 0.1253  loss_box_reg: 0.1626  time: 0.8763  last_time: 0.8782  data_time: 0.0617  last_data_time: 0.0594   lr: 0.01  max_mem: 21296M
[02/26 22:05:42] d2.utils.events INFO:  eta: 0:21:24  iter: 2819  total_loss: 0.2639  loss_cls: 0.1134  loss_box_reg: 0.1523  time: 0.8764  last_time: 0.8688  data_time: 0.0649  last_data_time: 0.0505   lr: 0.01  max_mem: 21296M
[02/26 22:06:00] d2.utils.events INFO:  eta: 0:21:07  iter: 2839  total_loss: 0.2754  loss_cls: 0.1229  loss_box_reg: 0.1548  time: 0.8763  last_time: 0.8847  data_time: 0.0597  last_data_time: 0.0656   lr: 0.01  max_mem: 21296M
[02/26 22:06:12] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0002853.pth
[02/26 22:06:14] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 22:06:14] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/26 22:06:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/26 22:06:14] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 22:06:14] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/26 22:06:14] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/26 22:06:14] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/26 22:06:15] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0004 s/iter. Inference: 0.0291 s/iter. Eval: 0.0002 s/iter. Total: 0.0297 s/iter. ETA=0:00:04
[02/26 22:06:19] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.687002 (0.030239 s / iter per device, on 1 devices)
[02/26 22:06:19] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.029081 s / iter per device, on 1 devices)
[02/26 22:06:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/26 22:06:19] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/26 22:06:19] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/26 22:06:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/26 22:06:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.26 seconds.
[02/26 22:06:20] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/26 22:06:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.11 seconds.
[02/26 22:06:20] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.074 | 23.305 | 15.062 | 7.181 | 23.091 | 28.066 |
[02/26 22:06:20] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 12.316 | 001_binder_clips_median      | 28.559 | 002_binder_clips_small       | 13.194 |
| 003_bombik_bucket          | 12.038 | 004_bonne_maman_blueberry    | 0.139  | 005_bonne_maman_raspberry    | 0.678  |
| 006_bonne_maman_strawberry | 1.441  | 007_costa_caramel            | 27.248 | 008_essential_oil_bergamot   | 21.017 |
| 009_garlic_toast_spread    | 4.805  | 010_handcream_avocado        | 0.507  | 011_hb_calcium               | 16.513 |
| 012_hb_grapeseed           | 10.216 | 013_hb_marine_collagen       | 8.374  | 014_hellmanns_mayonnaise     | 7.269  |
| 015_illy_blend             | 0.231  | 016_japanese_finger_cookies  | 1.546  | 017_john_west_canned_tuna    | 4.289  |
| 018_kerastase_shampoo      | 11.268 | 019_kiehls_facial_cream      | 28.568 | 020_kiihne_balsamic          | 0.192  |
| 021_kiihne_honey_mustard   | 13.327 | 022_lindor_matcha            | 20.679 | 023_lindor_salted_caramel    | 33.500 |
| 024_lush_mask              | 71.440 | 025_pasta_sauce_black_pepper | 2.206  | 026_pasta_sauce_tomato       | 8.194  |
| 027_pepsi                  | 42.100 | 028_portable_yogurt_machine  | 3.590  | 029_selfile_stick            | 1.423  |
| 030_sour_lemon_drops       | 8.975  | 031_sticky_notes             | 9.032  | 032_stridex_green            | 44.840 |
| 033_thermos_flask_cream    | 36.448 | 034_thermos_flask_muji       | 0.243  | 035_thermos_flask_sliver     | 0.062  |
| 036_tragata_olive_oil      | 3.758  | 037_tulip_luncheon_meat      | 5.653  | 038_unicharm_cotton_pad      | 43.416 |
| 039_vinda_tissue           | 34.565 | 040_wrigley_doublemint_gum   | 0.149  | 041_baseball_cap_black       | 13.223 |
| 042_baseball_cap_pink      | 14.081 | 043_bfe_facial_mask          | 25.275 | 044_corgi_doll               | 7.120  |
| 045_dinosaur_doll          | 30.570 | 046_geo_mocha                | 6.289  | 047_geo_roast_charcoal       | 1.055  |
| 048_instant_noodle_black   | 6.942  | 049_instant_noodle_red       | 27.714 | 050_nabati_cheese_wafer      | 33.715 |
| 051_truffettes             | 6.109  | 052_acnes_cream              | 18.419 | 053_aveda_conditioner        | 22.700 |
| 054_banana_milk_drink      | 5.209  | 055_candle_beast             | 17.220 | 056_china_persimmon          | 17.237 |
| 057_danisa_butter_cookies  | 3.029  | 058_effaclar_duo             | 9.613  | 059_evelom_cleanser          | 28.063 |
| 060_glasses_box_blone      | 18.124 | 061_handcream_iris           | 0.096  | 062_handcream_lavender       | 0.000  |
| 063_handcream_rosewater    | 1.658  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 3.397  |
| 066_japanese_chocolate     | 35.739 | 067_kerastase_hair_treatment | 12.040 | 068_kiehls_serum             | 26.567 |
| 069_korean_beef_marinade   | 18.893 | 070_korean_doenjang          | 20.617 | 071_korean_gochujang         | 0.225  |
| 072_korean_ssamjang        | 26.301 | 073_loccitane_soap           | 13.600 | 074_marvis_toothpaste_purple | 33.366 |
| 075_mouse_thinkpad         | 1.234  | 076_oatly_chocolate          | 7.411  | 077_oatly_original           | 16.881 |
| 078_ousa_grated_cheese     | 2.120  | 079_polaroid_film            | 0.297  | 080_skinceuticals_be         | 45.101 |
| 081_skinceuticals_cf       | 26.008 | 082_skinceuticals_phyto      | 16.105 | 083_stapler_black            | 9.122  |
| 084_stapler_blue           | 14.097 | 085_sunscreen_blue           | 3.101  | 086_tempo_pocket_tissue      | 2.012  |
| 087_thermos_flask_purple   | 34.867 | 088_uha_matcha               | 10.377 | 089_urban_decay_spray        | 9.899  |
| 090_vitaboost_multivitamin | 9.851  | 091_watercolor_penbox        | 0.063  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 15.088 | 094_kaneyo_kitchen_bleach    | 24.162 | 095_lays_chip_bag_blue       | 16.345 |
| 096_lays_chip_bag_green    | 12.118 | 097_lays_chip_tube_auburn    | 11.599 | 098_lays_chip_tube_green     | 21.304 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/26 22:06:20] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/26 22:06:20] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/26 22:06:20] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/26 22:06:20] d2.evaluation.testing INFO: copypaste: 14.0737,23.3053,15.0619,7.1807,23.0912,28.0658
[02/26 22:06:23] d2.utils.events INFO:  eta: 0:20:49  iter: 2859  total_loss: 0.2673  loss_cls: 0.1143  loss_box_reg: 0.1529  time: 0.8763  last_time: 0.8788  data_time: 0.0611  last_data_time: 0.0602   lr: 0.01  max_mem: 21296M
[02/26 22:06:41] d2.utils.events INFO:  eta: 0:20:32  iter: 2879  total_loss: 0.2753  loss_cls: 0.117  loss_box_reg: 0.1571  time: 0.8764  last_time: 0.8842  data_time: 0.0599  last_data_time: 0.0656   lr: 0.01  max_mem: 21296M
[02/26 22:06:58] d2.utils.events INFO:  eta: 0:20:14  iter: 2899  total_loss: 0.2681  loss_cls: 0.1159  loss_box_reg: 0.1517  time: 0.8764  last_time: 0.8953  data_time: 0.0605  last_data_time: 0.0761   lr: 0.01  max_mem: 21296M
[02/26 22:07:16] d2.utils.events INFO:  eta: 0:19:57  iter: 2919  total_loss: 0.2682  loss_cls: 0.1139  loss_box_reg: 0.1537  time: 0.8764  last_time: 0.8759  data_time: 0.0623  last_data_time: 0.0574   lr: 0.01  max_mem: 21296M
[02/26 22:07:33] d2.utils.events INFO:  eta: 0:19:39  iter: 2939  total_loss: 0.272  loss_cls: 0.1173  loss_box_reg: 0.154  time: 0.8764  last_time: 0.8737  data_time: 0.0631  last_data_time: 0.0552   lr: 0.01  max_mem: 21296M
[02/26 22:07:51] d2.utils.events INFO:  eta: 0:19:22  iter: 2959  total_loss: 0.2664  loss_cls: 0.1133  loss_box_reg: 0.1531  time: 0.8763  last_time: 0.8790  data_time: 0.0598  last_data_time: 0.0607   lr: 0.01  max_mem: 21296M
[02/26 22:08:08] d2.utils.events INFO:  eta: 0:19:04  iter: 2979  total_loss: 0.2651  loss_cls: 0.1151  loss_box_reg: 0.1482  time: 0.8763  last_time: 0.8848  data_time: 0.0594  last_data_time: 0.0659   lr: 0.01  max_mem: 21296M
[02/26 22:08:26] d2.utils.events INFO:  eta: 0:18:47  iter: 2999  total_loss: 0.2664  loss_cls: 0.1153  loss_box_reg: 0.1541  time: 0.8763  last_time: 0.8365  data_time: 0.0627  last_data_time: 0.0655   lr: 0.01  max_mem: 21296M
[02/26 22:08:43] d2.utils.events INFO:  eta: 0:18:29  iter: 3019  total_loss: 0.2643  loss_cls: 0.1113  loss_box_reg: 0.1508  time: 0.8763  last_time: 0.8868  data_time: 0.0625  last_data_time: 0.0678   lr: 0.01  max_mem: 21296M
[02/26 22:09:01] d2.utils.events INFO:  eta: 0:18:12  iter: 3039  total_loss: 0.2603  loss_cls: 0.113  loss_box_reg: 0.1535  time: 0.8763  last_time: 0.8766  data_time: 0.0616  last_data_time: 0.0576   lr: 0.01  max_mem: 21296M
[02/26 22:09:18] d2.utils.events INFO:  eta: 0:17:54  iter: 3059  total_loss: 0.2581  loss_cls: 0.1097  loss_box_reg: 0.1471  time: 0.8762  last_time: 0.8857  data_time: 0.0620  last_data_time: 0.0670   lr: 0.01  max_mem: 21296M
[02/26 22:09:36] d2.utils.events INFO:  eta: 0:17:37  iter: 3079  total_loss: 0.2703  loss_cls: 0.1154  loss_box_reg: 0.1555  time: 0.8762  last_time: 0.8816  data_time: 0.0632  last_data_time: 0.0632   lr: 0.01  max_mem: 21296M
[02/26 22:09:53] d2.utils.events INFO:  eta: 0:17:19  iter: 3099  total_loss: 0.2787  loss_cls: 0.1216  loss_box_reg: 0.1545  time: 0.8762  last_time: 0.8722  data_time: 0.0622  last_data_time: 0.0533   lr: 0.01  max_mem: 21296M
[02/26 22:10:11] d2.utils.events INFO:  eta: 0:17:02  iter: 3119  total_loss: 0.2601  loss_cls: 0.1112  loss_box_reg: 0.1493  time: 0.8762  last_time: 0.8820  data_time: 0.0603  last_data_time: 0.0625   lr: 0.01  max_mem: 21296M
[02/26 22:10:28] d2.utils.events INFO:  eta: 0:16:44  iter: 3139  total_loss: 0.2602  loss_cls: 0.1138  loss_box_reg: 0.1489  time: 0.8762  last_time: 0.8863  data_time: 0.0631  last_data_time: 0.0682   lr: 0.01  max_mem: 21296M
[02/26 22:10:46] d2.utils.events INFO:  eta: 0:16:27  iter: 3159  total_loss: 0.2629  loss_cls: 0.1135  loss_box_reg: 0.1505  time: 0.8762  last_time: 0.8789  data_time: 0.0589  last_data_time: 0.0601   lr: 0.01  max_mem: 21296M
[02/26 22:11:03] d2.utils.events INFO:  eta: 0:16:09  iter: 3179  total_loss: 0.2657  loss_cls: 0.115  loss_box_reg: 0.147  time: 0.8762  last_time: 0.8817  data_time: 0.0593  last_data_time: 0.0638   lr: 0.01  max_mem: 21296M
[02/26 22:11:21] d2.utils.events INFO:  eta: 0:15:51  iter: 3199  total_loss: 0.249  loss_cls: 0.1036  loss_box_reg: 0.1448  time: 0.8762  last_time: 0.8808  data_time: 0.0614  last_data_time: 0.0637   lr: 0.01  max_mem: 21296M
[02/26 22:11:38] d2.utils.events INFO:  eta: 0:15:34  iter: 3219  total_loss: 0.2675  loss_cls: 0.1157  loss_box_reg: 0.1506  time: 0.8762  last_time: 0.8877  data_time: 0.0634  last_data_time: 0.0676   lr: 0.01  max_mem: 21296M
[02/26 22:11:56] d2.utils.events INFO:  eta: 0:15:16  iter: 3239  total_loss: 0.2573  loss_cls: 0.1114  loss_box_reg: 0.1455  time: 0.8762  last_time: 0.8706  data_time: 0.0594  last_data_time: 0.0513   lr: 0.01  max_mem: 21296M
[02/26 22:12:14] d2.utils.events INFO:  eta: 0:14:59  iter: 3259  total_loss: 0.2545  loss_cls: 0.1092  loss_box_reg: 0.144  time: 0.8763  last_time: 0.8879  data_time: 0.0616  last_data_time: 0.0692   lr: 0.01  max_mem: 21296M
[02/26 22:12:31] d2.utils.events INFO:  eta: 0:14:41  iter: 3279  total_loss: 0.2595  loss_cls: 0.1139  loss_box_reg: 0.1472  time: 0.8763  last_time: 0.8816  data_time: 0.0630  last_data_time: 0.0641   lr: 0.01  max_mem: 21296M
[02/26 22:12:49] d2.utils.events INFO:  eta: 0:14:24  iter: 3299  total_loss: 0.2598  loss_cls: 0.1112  loss_box_reg: 0.1497  time: 0.8763  last_time: 0.8783  data_time: 0.0601  last_data_time: 0.0596   lr: 0.01  max_mem: 21296M
[02/26 22:13:06] d2.utils.events INFO:  eta: 0:14:06  iter: 3319  total_loss: 0.2571  loss_cls: 0.1093  loss_box_reg: 0.1477  time: 0.8763  last_time: 0.8868  data_time: 0.0604  last_data_time: 0.0681   lr: 0.01  max_mem: 21296M
[02/26 22:13:24] d2.utils.events INFO:  eta: 0:13:48  iter: 3339  total_loss: 0.2657  loss_cls: 0.1133  loss_box_reg: 0.1508  time: 0.8763  last_time: 0.8737  data_time: 0.0601  last_data_time: 0.0546   lr: 0.01  max_mem: 21296M
[02/26 22:13:41] d2.utils.events INFO:  eta: 0:13:31  iter: 3359  total_loss: 0.2549  loss_cls: 0.1068  loss_box_reg: 0.1482  time: 0.8763  last_time: 0.8718  data_time: 0.0610  last_data_time: 0.0524   lr: 0.01  max_mem: 21296M
[02/26 22:13:59] d2.utils.events INFO:  eta: 0:13:13  iter: 3379  total_loss: 0.2616  loss_cls: 0.1091  loss_box_reg: 0.1524  time: 0.8763  last_time: 0.8795  data_time: 0.0607  last_data_time: 0.0590   lr: 0.01  max_mem: 21296M
[02/26 22:14:16] d2.utils.events INFO:  eta: 0:12:56  iter: 3399  total_loss: 0.2503  loss_cls: 0.1069  loss_box_reg: 0.1465  time: 0.8763  last_time: 0.8843  data_time: 0.0620  last_data_time: 0.0658   lr: 0.01  max_mem: 21296M
[02/26 22:14:34] d2.utils.events INFO:  eta: 0:12:38  iter: 3419  total_loss: 0.2623  loss_cls: 0.1124  loss_box_reg: 0.1508  time: 0.8762  last_time: 0.8694  data_time: 0.0605  last_data_time: 0.0498   lr: 0.01  max_mem: 21296M
[02/26 22:14:51] d2.utils.events INFO:  eta: 0:12:20  iter: 3439  total_loss: 0.2432  loss_cls: 0.1041  loss_box_reg: 0.1402  time: 0.8762  last_time: 0.8907  data_time: 0.0618  last_data_time: 0.0722   lr: 0.01  max_mem: 21296M
[02/26 22:15:09] d2.utils.events INFO:  eta: 0:12:03  iter: 3459  total_loss: 0.2436  loss_cls: 0.1016  loss_box_reg: 0.1394  time: 0.8762  last_time: 0.8867  data_time: 0.0613  last_data_time: 0.0678   lr: 0.01  max_mem: 21296M
[02/26 22:15:26] d2.utils.events INFO:  eta: 0:11:45  iter: 3479  total_loss: 0.2525  loss_cls: 0.1066  loss_box_reg: 0.1485  time: 0.8762  last_time: 0.8389  data_time: 0.0605  last_data_time: 0.0686   lr: 0.01  max_mem: 21296M
[02/26 22:15:44] d2.utils.events INFO:  eta: 0:11:28  iter: 3499  total_loss: 0.2578  loss_cls: 0.1096  loss_box_reg: 0.1441  time: 0.8762  last_time: 0.8844  data_time: 0.0612  last_data_time: 0.0660   lr: 0.01  max_mem: 21296M
[02/26 22:16:01] d2.utils.events INFO:  eta: 0:11:10  iter: 3519  total_loss: 0.2471  loss_cls: 0.1062  loss_box_reg: 0.1423  time: 0.8762  last_time: 0.8739  data_time: 0.0585  last_data_time: 0.0559   lr: 0.01  max_mem: 21296M
[02/26 22:16:19] d2.utils.events INFO:  eta: 0:10:53  iter: 3539  total_loss: 0.2693  loss_cls: 0.1153  loss_box_reg: 0.1515  time: 0.8761  last_time: 0.8827  data_time: 0.0608  last_data_time: 0.0643   lr: 0.01  max_mem: 21296M
[02/26 22:16:36] d2.utils.events INFO:  eta: 0:10:35  iter: 3559  total_loss: 0.2457  loss_cls: 0.1043  loss_box_reg: 0.1424  time: 0.8761  last_time: 0.8836  data_time: 0.0601  last_data_time: 0.0652   lr: 0.01  max_mem: 21296M
[02/26 22:16:54] d2.utils.events INFO:  eta: 0:10:17  iter: 3579  total_loss: 0.2421  loss_cls: 0.1001  loss_box_reg: 0.1416  time: 0.8761  last_time: 0.8824  data_time: 0.0592  last_data_time: 0.0644   lr: 0.01  max_mem: 21296M
[02/26 22:17:11] d2.utils.events INFO:  eta: 0:10:00  iter: 3599  total_loss: 0.2466  loss_cls: 0.1032  loss_box_reg: 0.143  time: 0.8762  last_time: 0.8827  data_time: 0.0614  last_data_time: 0.0657   lr: 0.01  max_mem: 21296M
[02/26 22:17:29] d2.utils.events INFO:  eta: 0:09:42  iter: 3619  total_loss: 0.2413  loss_cls: 0.1023  loss_box_reg: 0.1406  time: 0.8762  last_time: 0.8860  data_time: 0.0606  last_data_time: 0.0681   lr: 0.01  max_mem: 21296M
[02/26 22:17:46] d2.utils.events INFO:  eta: 0:09:25  iter: 3639  total_loss: 0.2449  loss_cls: 0.1013  loss_box_reg: 0.1431  time: 0.8761  last_time: 0.8847  data_time: 0.0611  last_data_time: 0.0650   lr: 0.01  max_mem: 21296M
[02/26 22:18:04] d2.utils.events INFO:  eta: 0:09:07  iter: 3659  total_loss: 0.2483  loss_cls: 0.105  loss_box_reg: 0.1455  time: 0.8762  last_time: 0.8962  data_time: 0.0630  last_data_time: 0.0774   lr: 0.01  max_mem: 21296M
[02/26 22:18:21] d2.utils.events INFO:  eta: 0:08:50  iter: 3679  total_loss: 0.2398  loss_cls: 0.1042  loss_box_reg: 0.1425  time: 0.8762  last_time: 0.8790  data_time: 0.0614  last_data_time: 0.0613   lr: 0.01  max_mem: 21296M
[02/26 22:18:39] d2.utils.events INFO:  eta: 0:08:32  iter: 3699  total_loss: 0.2484  loss_cls: 0.1014  loss_box_reg: 0.1439  time: 0.8762  last_time: 0.8690  data_time: 0.0620  last_data_time: 0.0515   lr: 0.01  max_mem: 21296M
[02/26 22:18:57] d2.utils.events INFO:  eta: 0:08:14  iter: 3719  total_loss: 0.2476  loss_cls: 0.1044  loss_box_reg: 0.1446  time: 0.8762  last_time: 0.8688  data_time: 0.0599  last_data_time: 0.0506   lr: 0.01  max_mem: 21296M
[02/26 22:19:14] d2.utils.events INFO:  eta: 0:07:57  iter: 3739  total_loss: 0.2445  loss_cls: 0.1041  loss_box_reg: 0.1416  time: 0.8762  last_time: 0.8879  data_time: 0.0636  last_data_time: 0.0685   lr: 0.01  max_mem: 21296M
[02/26 22:19:32] d2.utils.events INFO:  eta: 0:07:39  iter: 3759  total_loss: 0.2471  loss_cls: 0.1043  loss_box_reg: 0.1421  time: 0.8762  last_time: 0.8766  data_time: 0.0611  last_data_time: 0.0580   lr: 0.01  max_mem: 21296M
[02/26 22:19:49] d2.utils.events INFO:  eta: 0:07:22  iter: 3779  total_loss: 0.2527  loss_cls: 0.1033  loss_box_reg: 0.1451  time: 0.8762  last_time: 0.8759  data_time: 0.0623  last_data_time: 0.0568   lr: 0.01  max_mem: 21296M
[02/26 22:20:07] d2.utils.events INFO:  eta: 0:07:04  iter: 3799  total_loss: 0.2519  loss_cls: 0.1037  loss_box_reg: 0.1428  time: 0.8762  last_time: 0.8761  data_time: 0.0597  last_data_time: 0.0572   lr: 0.01  max_mem: 21296M
[02/26 22:20:24] d2.utils.events INFO:  eta: 0:06:46  iter: 3819  total_loss: 0.2489  loss_cls: 0.1005  loss_box_reg: 0.1466  time: 0.8762  last_time: 0.8773  data_time: 0.0605  last_data_time: 0.0583   lr: 0.01  max_mem: 21296M
[02/26 22:20:42] d2.utils.events INFO:  eta: 0:06:29  iter: 3839  total_loss: 0.2472  loss_cls: 0.1014  loss_box_reg: 0.1446  time: 0.8762  last_time: 0.8696  data_time: 0.0578  last_data_time: 0.0505   lr: 0.01  max_mem: 21296M
[02/26 22:20:59] d2.utils.events INFO:  eta: 0:06:11  iter: 3859  total_loss: 0.2451  loss_cls: 0.1004  loss_box_reg: 0.1439  time: 0.8762  last_time: 0.8799  data_time: 0.0619  last_data_time: 0.0608   lr: 0.01  max_mem: 21296M
[02/26 22:21:17] d2.utils.events INFO:  eta: 0:05:54  iter: 3879  total_loss: 0.2439  loss_cls: 0.1027  loss_box_reg: 0.1426  time: 0.8762  last_time: 0.8802  data_time: 0.0614  last_data_time: 0.0603   lr: 0.01  max_mem: 21296M
[02/26 22:21:35] d2.utils.events INFO:  eta: 0:05:36  iter: 3899  total_loss: 0.2395  loss_cls: 0.09974  loss_box_reg: 0.1399  time: 0.8762  last_time: 0.8755  data_time: 0.0610  last_data_time: 0.0556   lr: 0.01  max_mem: 21296M
[02/26 22:21:52] d2.utils.events INFO:  eta: 0:05:19  iter: 3919  total_loss: 0.2486  loss_cls: 0.1053  loss_box_reg: 0.1452  time: 0.8762  last_time: 0.8327  data_time: 0.0606  last_data_time: 0.0610   lr: 0.01  max_mem: 21296M
[02/26 22:22:09] d2.utils.events INFO:  eta: 0:05:01  iter: 3939  total_loss: 0.2391  loss_cls: 0.09899  loss_box_reg: 0.1406  time: 0.8762  last_time: 0.8778  data_time: 0.0593  last_data_time: 0.0586   lr: 0.01  max_mem: 21296M
[02/26 22:22:27] d2.utils.events INFO:  eta: 0:04:43  iter: 3959  total_loss: 0.2386  loss_cls: 0.09907  loss_box_reg: 0.1384  time: 0.8762  last_time: 0.8698  data_time: 0.0624  last_data_time: 0.0508   lr: 0.01  max_mem: 21296M
[02/26 22:22:45] d2.utils.events INFO:  eta: 0:04:26  iter: 3979  total_loss: 0.2472  loss_cls: 0.1064  loss_box_reg: 0.1427  time: 0.8762  last_time: 0.8781  data_time: 0.0618  last_data_time: 0.0590   lr: 0.01  max_mem: 21296M
[02/26 22:23:02] d2.utils.events INFO:  eta: 0:04:08  iter: 3999  total_loss: 0.2437  loss_cls: 0.1004  loss_box_reg: 0.1419  time: 0.8762  last_time: 0.8785  data_time: 0.0583  last_data_time: 0.0598   lr: 0.01  max_mem: 21296M
[02/26 22:23:20] d2.utils.events INFO:  eta: 0:03:51  iter: 4019  total_loss: 0.2395  loss_cls: 0.09867  loss_box_reg: 0.1416  time: 0.8762  last_time: 0.8882  data_time: 0.0592  last_data_time: 0.0691   lr: 0.01  max_mem: 21296M
[02/26 22:23:37] d2.utils.events INFO:  eta: 0:03:33  iter: 4039  total_loss: 0.2453  loss_cls: 0.1022  loss_box_reg: 0.1429  time: 0.8762  last_time: 0.8776  data_time: 0.0580  last_data_time: 0.0579   lr: 0.01  max_mem: 21296M
[02/26 22:23:55] d2.utils.events INFO:  eta: 0:03:15  iter: 4059  total_loss: 0.2411  loss_cls: 0.09844  loss_box_reg: 0.1434  time: 0.8762  last_time: 0.8800  data_time: 0.0589  last_data_time: 0.0603   lr: 0.01  max_mem: 21296M
[02/26 22:24:12] d2.utils.events INFO:  eta: 0:02:58  iter: 4079  total_loss: 0.2328  loss_cls: 0.09665  loss_box_reg: 0.1388  time: 0.8762  last_time: 0.8802  data_time: 0.0585  last_data_time: 0.0598   lr: 0.01  max_mem: 21296M
[02/26 22:24:30] d2.utils.events INFO:  eta: 0:02:40  iter: 4099  total_loss: 0.2423  loss_cls: 0.09986  loss_box_reg: 0.1415  time: 0.8762  last_time: 0.8730  data_time: 0.0623  last_data_time: 0.0534   lr: 0.01  max_mem: 21296M
[02/26 22:24:47] d2.utils.events INFO:  eta: 0:02:23  iter: 4119  total_loss: 0.2373  loss_cls: 0.09729  loss_box_reg: 0.1403  time: 0.8762  last_time: 0.8296  data_time: 0.0584  last_data_time: 0.0592   lr: 0.01  max_mem: 21296M
[02/26 22:25:05] d2.utils.events INFO:  eta: 0:02:05  iter: 4139  total_loss: 0.2344  loss_cls: 0.09535  loss_box_reg: 0.1379  time: 0.8761  last_time: 0.8950  data_time: 0.0611  last_data_time: 0.0765   lr: 0.01  max_mem: 21296M
[02/26 22:25:22] d2.utils.events INFO:  eta: 0:01:48  iter: 4159  total_loss: 0.2305  loss_cls: 0.09566  loss_box_reg: 0.1347  time: 0.8761  last_time: 0.8958  data_time: 0.0627  last_data_time: 0.0768   lr: 0.01  max_mem: 21296M
[02/26 22:25:40] d2.utils.events INFO:  eta: 0:01:30  iter: 4179  total_loss: 0.239  loss_cls: 0.09868  loss_box_reg: 0.1421  time: 0.8761  last_time: 0.8816  data_time: 0.0599  last_data_time: 0.0634   lr: 0.01  max_mem: 21296M
[02/26 22:25:57] d2.utils.events INFO:  eta: 0:01:12  iter: 4199  total_loss: 0.2286  loss_cls: 0.09439  loss_box_reg: 0.1354  time: 0.8762  last_time: 0.8824  data_time: 0.0621  last_data_time: 0.0650   lr: 0.01  max_mem: 21296M
[02/26 22:26:15] d2.utils.events INFO:  eta: 0:00:55  iter: 4219  total_loss: 0.2342  loss_cls: 0.09545  loss_box_reg: 0.1399  time: 0.8762  last_time: 0.8832  data_time: 0.0637  last_data_time: 0.0649   lr: 0.01  max_mem: 21296M
[02/26 22:26:32] d2.utils.events INFO:  eta: 0:00:37  iter: 4239  total_loss: 0.2308  loss_cls: 0.09033  loss_box_reg: 0.1379  time: 0.8762  last_time: 0.8953  data_time: 0.0632  last_data_time: 0.0773   lr: 0.01  max_mem: 21296M
[02/26 22:26:50] d2.utils.events INFO:  eta: 0:00:20  iter: 4259  total_loss: 0.2371  loss_cls: 0.09751  loss_box_reg: 0.1385  time: 0.8762  last_time: 0.8800  data_time: 0.0584  last_data_time: 0.0617   lr: 0.01  max_mem: 21296M
[02/26 22:27:07] d2.utils.events INFO:  eta: 0:00:02  iter: 4279  total_loss: 0.2365  loss_cls: 0.09637  loss_box_reg: 0.1404  time: 0.8762  last_time: 0.8688  data_time: 0.0583  last_data_time: 0.0509   lr: 0.01  max_mem: 21296M
[02/26 22:27:08] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0004280.pth
[02/26 22:27:10] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_final.pth
[02/26 22:27:10] d2.utils.events INFO:  eta: 0:00:00  iter: 4282  total_loss: 0.2331  loss_cls: 0.09487  loss_box_reg: 0.1397  time: 0.8762  last_time: 0.8700  data_time: 0.0588  last_data_time: 0.0519   lr: 0.01  max_mem: 21296M
[02/26 22:27:10] d2.engine.hooks INFO: Overall training speed: 4281 iterations in 1:02:30 (0.8762 s / it)
[02/26 22:27:10] d2.engine.hooks INFO: Total training time: 1:02:44 (0:00:13 on hooks)
[02/26 22:27:10] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 22:27:10] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/26 22:27:10] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/26 22:27:10] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 22:27:10] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/26 22:27:10] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/26 22:27:10] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/26 22:27:11] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0004 s/iter. Inference: 0.0290 s/iter. Eval: 0.0003 s/iter. Total: 0.0297 s/iter. ETA=0:00:04
[02/26 22:27:15] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.726440 (0.030493 s / iter per device, on 1 devices)
[02/26 22:27:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.029359 s / iter per device, on 1 devices)
[02/26 22:27:15] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/26 22:27:16] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/26 22:27:16] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/26 22:27:16] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/26 22:27:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.24 seconds.
[02/26 22:27:16] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/26 22:27:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.12 seconds.
[02/26 22:27:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.162 | 22.704 | 15.328 | 7.253 | 23.046 | 28.423 |
[02/26 22:27:16] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 15.127 | 001_binder_clips_median      | 29.271 | 002_binder_clips_small       | 12.610 |
| 003_bombik_bucket          | 13.324 | 004_bonne_maman_blueberry    | 0.171  | 005_bonne_maman_raspberry    | 1.681  |
| 006_bonne_maman_strawberry | 0.334  | 007_costa_caramel            | 20.823 | 008_essential_oil_bergamot   | 24.974 |
| 009_garlic_toast_spread    | 6.139  | 010_handcream_avocado        | 0.539  | 011_hb_calcium               | 15.774 |
| 012_hb_grapeseed           | 9.899  | 013_hb_marine_collagen       | 8.703  | 014_hellmanns_mayonnaise     | 7.217  |
| 015_illy_blend             | 1.201  | 016_japanese_finger_cookies  | 2.594  | 017_john_west_canned_tuna    | 3.799  |
| 018_kerastase_shampoo      | 7.634  | 019_kiehls_facial_cream      | 28.416 | 020_kiihne_balsamic          | 0.057  |
| 021_kiihne_honey_mustard   | 14.870 | 022_lindor_matcha            | 26.354 | 023_lindor_salted_caramel    | 30.348 |
| 024_lush_mask              | 72.614 | 025_pasta_sauce_black_pepper | 0.090  | 026_pasta_sauce_tomato       | 7.448  |
| 027_pepsi                  | 45.530 | 028_portable_yogurt_machine  | 0.637  | 029_selfile_stick            | 1.480  |
| 030_sour_lemon_drops       | 8.397  | 031_sticky_notes             | 11.113 | 032_stridex_green            | 42.470 |
| 033_thermos_flask_cream    | 40.768 | 034_thermos_flask_muji       | 0.000  | 035_thermos_flask_sliver     | 0.000  |
| 036_tragata_olive_oil      | 4.607  | 037_tulip_luncheon_meat      | 6.270  | 038_unicharm_cotton_pad      | 42.846 |
| 039_vinda_tissue           | 34.041 | 040_wrigley_doublemint_gum   | 0.583  | 041_baseball_cap_black       | 14.800 |
| 042_baseball_cap_pink      | 13.338 | 043_bfe_facial_mask          | 26.407 | 044_corgi_doll               | 5.251  |
| 045_dinosaur_doll          | 29.722 | 046_geo_mocha                | 6.499  | 047_geo_roast_charcoal       | 1.270  |
| 048_instant_noodle_black   | 10.073 | 049_instant_noodle_red       | 27.574 | 050_nabati_cheese_wafer      | 34.279 |
| 051_truffettes             | 9.444  | 052_acnes_cream              | 24.001 | 053_aveda_conditioner        | 17.371 |
| 054_banana_milk_drink      | 7.620  | 055_candle_beast             | 29.266 | 056_china_persimmon          | 16.094 |
| 057_danisa_butter_cookies  | 4.054  | 058_effaclar_duo             | 5.545  | 059_evelom_cleanser          | 26.677 |
| 060_glasses_box_blone      | 14.579 | 061_handcream_iris           | 0.124  | 062_handcream_lavender       | 0.000  |
| 063_handcream_rosewater    | 1.622  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 5.482  |
| 066_japanese_chocolate     | 32.889 | 067_kerastase_hair_treatment | 13.296 | 068_kiehls_serum             | 26.923 |
| 069_korean_beef_marinade   | 16.025 | 070_korean_doenjang          | 14.122 | 071_korean_gochujang         | 0.124  |
| 072_korean_ssamjang        | 26.402 | 073_loccitane_soap           | 16.458 | 074_marvis_toothpaste_purple | 42.393 |
| 075_mouse_thinkpad         | 1.712  | 076_oatly_chocolate          | 6.008  | 077_oatly_original           | 18.771 |
| 078_ousa_grated_cheese     | 2.491  | 079_polaroid_film            | 0.290  | 080_skinceuticals_be         | 50.413 |
| 081_skinceuticals_cf       | 20.715 | 082_skinceuticals_phyto      | 14.703 | 083_stapler_black            | 10.450 |
| 084_stapler_blue           | 14.273 | 085_sunscreen_blue           | 3.119  | 086_tempo_pocket_tissue      | 2.126  |
| 087_thermos_flask_purple   | 28.711 | 088_uha_matcha               | 7.276  | 089_urban_decay_spray        | 10.634 |
| 090_vitaboost_multivitamin | 2.497  | 091_watercolor_penbox        | 0.066  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 15.306 | 094_kaneyo_kitchen_bleach    | 18.003 | 095_lays_chip_bag_blue       | 14.149 |
| 096_lays_chip_bag_green    | 14.748 | 097_lays_chip_tube_auburn    | 11.404 | 098_lays_chip_tube_green     | 27.849 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/26 22:27:16] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/26 22:27:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/26 22:27:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/26 22:27:16] d2.evaluation.testing INFO: copypaste: 14.1619,22.7036,15.3280,7.2535,23.0455,28.4229
