[02/26 22:38:40] detectron2 INFO: Rank of current process: 0. World size: 2
[02/26 22:38:41] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/26 22:38:41] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/26 22:38:41] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/26 22:38:41] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/26 22:38:41] detectron2 INFO: Full config saved to ./output/config.yaml
[02/26 22:38:41] d2.utils.env INFO: Using a generated random seed 41325654
[02/26 22:38:41] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/26 22:38:43] d2.data.datasets.coco INFO: Loading /media/nahyun/HDD//data_100/instances_train.json takes 2.30 seconds.
[02/26 22:38:43] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 22:38:43] d2.data.datasets.coco INFO: Loaded 19191 images in COCO format from /media/nahyun/HDD//data_100/instances_train.json
[02/26 22:38:45] d2.data.build INFO: Removed 0 images with no usable annotations. 19191 images left.
[02/26 22:38:45] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/26 22:38:45] d2.data.build INFO: Using training sampler TrainingSampler
[02/26 22:38:45] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 22:38:45] d2.data.common INFO: Serializing 19191 elements to byte tensors and concatenating them all ...
[02/26 22:38:45] d2.data.common INFO: Serialized dataset takes 80.55 MiB
[02/26 22:38:46] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/26 22:38:46] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 22:38:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/nahyun/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 22:38:46] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/26 22:38:46] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[02/26 22:38:46] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[02/26 22:38:46] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[02/26 22:38:46] d2.engine.train_loop INFO: Starting training from iteration 0
[02/26 22:44:01] detectron2 INFO: Rank of current process: 0. World size: 2
[02/26 22:44:01] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/26 22:44:01] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/26 22:44:01] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/26 22:44:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/26 22:44:01] detectron2 INFO: Full config saved to ./output/config.yaml
[02/26 22:44:01] d2.utils.env INFO: Using a generated random seed 1919935
[02/26 22:44:02] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/26 22:44:06] detectron2 INFO: Rank of current process: 0. World size: 1
[02/26 22:44:06] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/26 22:44:06] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/26 22:44:06] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/26 22:44:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/26 22:44:06] detectron2 INFO: Full config saved to ./output/config.yaml
[02/26 22:44:06] d2.utils.env INFO: Using a generated random seed 7233434
[02/26 22:44:08] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/26 22:44:10] d2.data.datasets.coco INFO: Loading /media/nahyun/HDD//data_100/instances_train.json takes 2.23 seconds.
[02/26 22:44:10] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 22:44:10] d2.data.datasets.coco INFO: Loaded 19191 images in COCO format from /media/nahyun/HDD//data_100/instances_train.json
[02/26 22:44:11] d2.data.build INFO: Removed 0 images with no usable annotations. 19191 images left.
[02/26 22:44:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/26 22:44:11] d2.data.build INFO: Using training sampler TrainingSampler
[02/26 22:44:11] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 22:44:11] d2.data.common INFO: Serializing 19191 elements to byte tensors and concatenating them all ...
[02/26 22:44:12] d2.data.common INFO: Serialized dataset takes 80.55 MiB
[02/26 22:44:12] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/26 22:44:12] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 22:44:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/nahyun/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[02/26 22:44:12] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/26 22:44:12] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[02/26 22:44:12] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[02/26 22:44:12] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[02/26 22:44:12] d2.engine.train_loop INFO: Starting training from iteration 0
[02/26 22:44:31] d2.utils.events INFO:  eta: 1:01:11  iter: 19  total_loss: 2.771  loss_cls: 1.734  loss_box_reg: 1.037  time: 0.9051  last_time: 0.8733  data_time: 0.0637  last_data_time: 0.0661   lr: 0.00019981  max_mem: 21305M
[02/26 22:44:48] d2.utils.events INFO:  eta: 1:00:59  iter: 39  total_loss: 1.913  loss_cls: 1.198  loss_box_reg: 0.7231  time: 0.8808  last_time: 0.8767  data_time: 0.0605  last_data_time: 0.0658   lr: 0.00039961  max_mem: 21305M
[02/26 22:45:06] d2.utils.events INFO:  eta: 1:01:02  iter: 59  total_loss: 1.842  loss_cls: 1.157  loss_box_reg: 0.6778  time: 0.8762  last_time: 0.8825  data_time: 0.0608  last_data_time: 0.0678   lr: 0.00059941  max_mem: 21305M
[02/26 22:45:23] d2.utils.events INFO:  eta: 1:00:55  iter: 79  total_loss: 1.847  loss_cls: 1.167  loss_box_reg: 0.6736  time: 0.8756  last_time: 0.8834  data_time: 0.0613  last_data_time: 0.0694   lr: 0.00079921  max_mem: 21305M
[02/26 22:45:41] d2.utils.events INFO:  eta: 1:00:48  iter: 99  total_loss: 1.797  loss_cls: 1.149  loss_box_reg: 0.649  time: 0.8748  last_time: 0.8792  data_time: 0.0636  last_data_time: 0.0652   lr: 0.00099901  max_mem: 21305M
[02/26 22:45:58] d2.utils.events INFO:  eta: 1:00:32  iter: 119  total_loss: 1.765  loss_cls: 1.138  loss_box_reg: 0.6311  time: 0.8741  last_time: 0.8791  data_time: 0.0599  last_data_time: 0.0640   lr: 0.0011988  max_mem: 21305M
[02/26 22:46:16] d2.utils.events INFO:  eta: 1:00:17  iter: 139  total_loss: 1.757  loss_cls: 1.145  loss_box_reg: 0.6126  time: 0.8740  last_time: 0.8815  data_time: 0.0606  last_data_time: 0.0662   lr: 0.0013986  max_mem: 21305M
[02/26 22:46:33] d2.utils.events INFO:  eta: 1:00:00  iter: 159  total_loss: 1.74  loss_cls: 1.135  loss_box_reg: 0.5995  time: 0.8741  last_time: 0.8824  data_time: 0.0608  last_data_time: 0.0650   lr: 0.0015984  max_mem: 21305M
[02/26 22:46:51] d2.utils.events INFO:  eta: 0:59:42  iter: 179  total_loss: 1.764  loss_cls: 1.169  loss_box_reg: 0.596  time: 0.8734  last_time: 0.8832  data_time: 0.0571  last_data_time: 0.0656   lr: 0.0017982  max_mem: 21305M
[02/26 22:47:08] d2.utils.events INFO:  eta: 0:59:26  iter: 199  total_loss: 1.718  loss_cls: 1.15  loss_box_reg: 0.5646  time: 0.8736  last_time: 0.8817  data_time: 0.0604  last_data_time: 0.0639   lr: 0.001998  max_mem: 21305M
[02/26 22:47:26] d2.utils.events INFO:  eta: 0:59:11  iter: 219  total_loss: 1.647  loss_cls: 1.129  loss_box_reg: 0.5247  time: 0.8736  last_time: 0.8672  data_time: 0.0590  last_data_time: 0.0501   lr: 0.0021978  max_mem: 21305M
[02/26 22:47:43] d2.utils.events INFO:  eta: 0:58:56  iter: 239  total_loss: 1.635  loss_cls: 1.147  loss_box_reg: 0.4905  time: 0.8741  last_time: 0.8787  data_time: 0.0614  last_data_time: 0.0608   lr: 0.0023976  max_mem: 21305M
[02/26 22:48:01] d2.utils.events INFO:  eta: 0:58:41  iter: 259  total_loss: 1.533  loss_cls: 1.096  loss_box_reg: 0.4374  time: 0.8744  last_time: 0.8847  data_time: 0.0611  last_data_time: 0.0671   lr: 0.0025974  max_mem: 21305M
[02/26 22:48:18] d2.utils.events INFO:  eta: 0:58:23  iter: 279  total_loss: 1.365  loss_cls: 0.9624  loss_box_reg: 0.4059  time: 0.8746  last_time: 0.8814  data_time: 0.0609  last_data_time: 0.0632   lr: 0.0027972  max_mem: 21305M
[02/26 22:48:36] d2.utils.events INFO:  eta: 0:58:06  iter: 299  total_loss: 1.219  loss_cls: 0.8328  loss_box_reg: 0.3859  time: 0.8748  last_time: 0.8855  data_time: 0.0601  last_data_time: 0.0665   lr: 0.002997  max_mem: 21305M
[02/26 22:48:53] d2.utils.events INFO:  eta: 0:57:48  iter: 319  total_loss: 1.135  loss_cls: 0.7726  loss_box_reg: 0.3605  time: 0.8747  last_time: 0.8788  data_time: 0.0586  last_data_time: 0.0613   lr: 0.0031968  max_mem: 21305M
[02/26 22:49:11] d2.utils.events INFO:  eta: 0:57:30  iter: 339  total_loss: 1.105  loss_cls: 0.7525  loss_box_reg: 0.3514  time: 0.8747  last_time: 0.8737  data_time: 0.0573  last_data_time: 0.0566   lr: 0.0033966  max_mem: 21305M
[02/26 22:49:28] d2.utils.events INFO:  eta: 0:57:13  iter: 359  total_loss: 1.041  loss_cls: 0.7201  loss_box_reg: 0.3255  time: 0.8746  last_time: 0.8191  data_time: 0.0598  last_data_time: 0.0498   lr: 0.0035964  max_mem: 21305M
[02/26 22:49:46] d2.utils.events INFO:  eta: 0:56:55  iter: 379  total_loss: 1.033  loss_cls: 0.7172  loss_box_reg: 0.3238  time: 0.8742  last_time: 0.8762  data_time: 0.0590  last_data_time: 0.0593   lr: 0.0037962  max_mem: 21305M
[02/26 22:50:03] d2.utils.events INFO:  eta: 0:56:38  iter: 399  total_loss: 1.021  loss_cls: 0.7075  loss_box_reg: 0.3071  time: 0.8740  last_time: 0.8770  data_time: 0.0579  last_data_time: 0.0582   lr: 0.003996  max_mem: 21305M
[02/26 22:50:20] d2.utils.events INFO:  eta: 0:56:21  iter: 419  total_loss: 1.123  loss_cls: 0.785  loss_box_reg: 0.338  time: 0.8739  last_time: 0.8696  data_time: 0.0588  last_data_time: 0.0526   lr: 0.0041958  max_mem: 21305M
[02/26 22:50:38] d2.utils.events INFO:  eta: 0:56:03  iter: 439  total_loss: 1.002  loss_cls: 0.7017  loss_box_reg: 0.3048  time: 0.8741  last_time: 0.8683  data_time: 0.0596  last_data_time: 0.0502   lr: 0.0043956  max_mem: 21305M
[02/26 22:50:55] d2.utils.events INFO:  eta: 0:55:45  iter: 459  total_loss: 0.9655  loss_cls: 0.6832  loss_box_reg: 0.2885  time: 0.8740  last_time: 0.8860  data_time: 0.0580  last_data_time: 0.0677   lr: 0.0045954  max_mem: 21305M
[02/26 22:51:13] d2.utils.events INFO:  eta: 0:55:28  iter: 479  total_loss: 0.9489  loss_cls: 0.669  loss_box_reg: 0.2795  time: 0.8741  last_time: 0.8753  data_time: 0.0588  last_data_time: 0.0570   lr: 0.0047952  max_mem: 21305M
[02/26 22:51:30] d2.utils.events INFO:  eta: 0:55:10  iter: 499  total_loss: 0.9378  loss_cls: 0.6606  loss_box_reg: 0.2771  time: 0.8741  last_time: 0.8796  data_time: 0.0574  last_data_time: 0.0602   lr: 0.004995  max_mem: 21305M
[02/26 22:51:48] d2.utils.events INFO:  eta: 0:54:52  iter: 519  total_loss: 0.9189  loss_cls: 0.6475  loss_box_reg: 0.2756  time: 0.8741  last_time: 0.8666  data_time: 0.0568  last_data_time: 0.0486   lr: 0.0051948  max_mem: 21305M
[02/26 22:52:05] d2.utils.events INFO:  eta: 0:54:34  iter: 539  total_loss: 0.8964  loss_cls: 0.6258  loss_box_reg: 0.2709  time: 0.8740  last_time: 0.8820  data_time: 0.0580  last_data_time: 0.0647   lr: 0.0053946  max_mem: 21305M
[02/26 22:52:23] d2.utils.events INFO:  eta: 0:54:17  iter: 559  total_loss: 0.8969  loss_cls: 0.6375  loss_box_reg: 0.2603  time: 0.8742  last_time: 0.8775  data_time: 0.0596  last_data_time: 0.0606   lr: 0.0055944  max_mem: 21305M
[02/26 22:52:41] d2.utils.events INFO:  eta: 0:54:00  iter: 579  total_loss: 0.8883  loss_cls: 0.6265  loss_box_reg: 0.2615  time: 0.8743  last_time: 0.8782  data_time: 0.0619  last_data_time: 0.0600   lr: 0.0057942  max_mem: 21305M
[02/26 22:52:58] d2.utils.events INFO:  eta: 0:53:43  iter: 599  total_loss: 0.8618  loss_cls: 0.5998  loss_box_reg: 0.2627  time: 0.8744  last_time: 0.8739  data_time: 0.0605  last_data_time: 0.0568   lr: 0.005994  max_mem: 21305M
[02/26 22:53:16] d2.utils.events INFO:  eta: 0:53:25  iter: 619  total_loss: 0.8376  loss_cls: 0.5907  loss_box_reg: 0.2491  time: 0.8745  last_time: 0.8855  data_time: 0.0619  last_data_time: 0.0677   lr: 0.0061938  max_mem: 21305M
[02/26 22:53:33] d2.utils.events INFO:  eta: 0:53:08  iter: 639  total_loss: 0.8351  loss_cls: 0.5859  loss_box_reg: 0.2506  time: 0.8743  last_time: 0.8807  data_time: 0.0605  last_data_time: 0.0631   lr: 0.0063936  max_mem: 21305M
[02/26 22:53:51] d2.utils.events INFO:  eta: 0:52:51  iter: 659  total_loss: 0.8348  loss_cls: 0.5754  loss_box_reg: 0.2585  time: 0.8744  last_time: 0.8747  data_time: 0.0609  last_data_time: 0.0573   lr: 0.0065934  max_mem: 21305M
[02/26 22:54:08] d2.utils.events INFO:  eta: 0:52:33  iter: 679  total_loss: 0.9081  loss_cls: 0.6533  loss_box_reg: 0.2629  time: 0.8741  last_time: 0.8829  data_time: 0.0600  last_data_time: 0.0658   lr: 0.0067932  max_mem: 21305M
[02/26 22:54:25] d2.utils.events INFO:  eta: 0:52:16  iter: 699  total_loss: 1.024  loss_cls: 0.7559  loss_box_reg: 0.2611  time: 0.8739  last_time: 0.8801  data_time: 0.0585  last_data_time: 0.0625   lr: 0.006993  max_mem: 21305M
[02/26 22:54:43] d2.utils.events INFO:  eta: 0:51:58  iter: 719  total_loss: 0.8252  loss_cls: 0.5907  loss_box_reg: 0.2409  time: 0.8740  last_time: 0.8833  data_time: 0.0614  last_data_time: 0.0646   lr: 0.0071928  max_mem: 21305M
[02/26 22:55:00] d2.utils.events INFO:  eta: 0:51:41  iter: 739  total_loss: 0.7762  loss_cls: 0.5346  loss_box_reg: 0.2431  time: 0.8740  last_time: 0.8721  data_time: 0.0621  last_data_time: 0.0553   lr: 0.0073926  max_mem: 21305M
[02/26 22:55:18] d2.utils.events INFO:  eta: 0:51:24  iter: 759  total_loss: 0.7522  loss_cls: 0.5199  loss_box_reg: 0.2336  time: 0.8741  last_time: 0.8687  data_time: 0.0615  last_data_time: 0.0514   lr: 0.0075924  max_mem: 21305M
[02/26 22:55:35] d2.utils.events INFO:  eta: 0:51:06  iter: 779  total_loss: 0.732  loss_cls: 0.4962  loss_box_reg: 0.2373  time: 0.8741  last_time: 0.8785  data_time: 0.0592  last_data_time: 0.0602   lr: 0.0077922  max_mem: 21305M
[02/26 22:55:53] d2.utils.events INFO:  eta: 0:50:49  iter: 799  total_loss: 0.7016  loss_cls: 0.4712  loss_box_reg: 0.2331  time: 0.8740  last_time: 0.8819  data_time: 0.0608  last_data_time: 0.0638   lr: 0.007992  max_mem: 21305M
[02/26 22:56:10] d2.utils.events INFO:  eta: 0:50:31  iter: 819  total_loss: 0.6879  loss_cls: 0.4493  loss_box_reg: 0.2358  time: 0.8739  last_time: 0.8263  data_time: 0.0593  last_data_time: 0.0569   lr: 0.0081918  max_mem: 21305M
[02/26 22:56:28] d2.utils.events INFO:  eta: 0:50:13  iter: 839  total_loss: 0.6694  loss_cls: 0.439  loss_box_reg: 0.2358  time: 0.8740  last_time: 0.8812  data_time: 0.0580  last_data_time: 0.0634   lr: 0.0083916  max_mem: 21305M
[02/26 22:56:45] d2.utils.events INFO:  eta: 0:49:56  iter: 859  total_loss: 0.6502  loss_cls: 0.4223  loss_box_reg: 0.2321  time: 0.8739  last_time: 0.8785  data_time: 0.0576  last_data_time: 0.0602   lr: 0.0085914  max_mem: 21305M
[02/26 22:57:03] d2.utils.events INFO:  eta: 0:49:38  iter: 879  total_loss: 0.6199  loss_cls: 0.3961  loss_box_reg: 0.2277  time: 0.8740  last_time: 0.8675  data_time: 0.0606  last_data_time: 0.0512   lr: 0.0087912  max_mem: 21305M
[02/26 22:57:20] d2.utils.events INFO:  eta: 0:49:21  iter: 899  total_loss: 0.6087  loss_cls: 0.3775  loss_box_reg: 0.2308  time: 0.8741  last_time: 0.8845  data_time: 0.0593  last_data_time: 0.0667   lr: 0.008991  max_mem: 21305M
[02/26 22:57:38] d2.utils.events INFO:  eta: 0:49:03  iter: 919  total_loss: 0.5906  loss_cls: 0.3598  loss_box_reg: 0.2265  time: 0.8739  last_time: 0.8852  data_time: 0.0586  last_data_time: 0.0677   lr: 0.0091908  max_mem: 21305M
[02/26 22:57:55] d2.utils.events INFO:  eta: 0:48:46  iter: 939  total_loss: 0.5917  loss_cls: 0.362  loss_box_reg: 0.2289  time: 0.8737  last_time: 0.8717  data_time: 0.0586  last_data_time: 0.0532   lr: 0.0093906  max_mem: 21305M
[02/26 22:58:12] d2.utils.events INFO:  eta: 0:48:28  iter: 959  total_loss: 0.656  loss_cls: 0.4197  loss_box_reg: 0.2363  time: 0.8737  last_time: 0.8668  data_time: 0.0600  last_data_time: 0.0504   lr: 0.0095904  max_mem: 21305M
[02/26 22:58:30] d2.utils.events INFO:  eta: 0:48:11  iter: 979  total_loss: 0.5568  loss_cls: 0.3366  loss_box_reg: 0.2211  time: 0.8737  last_time: 0.8842  data_time: 0.0591  last_data_time: 0.0662   lr: 0.0097902  max_mem: 21305M
[02/26 22:58:47] d2.utils.events INFO:  eta: 0:47:53  iter: 999  total_loss: 0.5308  loss_cls: 0.3072  loss_box_reg: 0.2224  time: 0.8737  last_time: 0.8843  data_time: 0.0594  last_data_time: 0.0670   lr: 0.00999  max_mem: 21305M
[02/26 22:59:05] d2.utils.events INFO:  eta: 0:47:37  iter: 1019  total_loss: 0.5029  loss_cls: 0.2874  loss_box_reg: 0.2176  time: 0.8738  last_time: 0.8797  data_time: 0.0606  last_data_time: 0.0622   lr: 0.01  max_mem: 21305M
[02/26 22:59:22] d2.utils.events INFO:  eta: 0:47:19  iter: 1039  total_loss: 0.4958  loss_cls: 0.2854  loss_box_reg: 0.2154  time: 0.8738  last_time: 0.8891  data_time: 0.0610  last_data_time: 0.0721   lr: 0.01  max_mem: 21305M
[02/26 22:59:40] d2.utils.events INFO:  eta: 0:47:02  iter: 1059  total_loss: 0.4769  loss_cls: 0.2698  loss_box_reg: 0.2099  time: 0.8737  last_time: 0.8781  data_time: 0.0571  last_data_time: 0.0597   lr: 0.01  max_mem: 21305M
[02/26 22:59:57] d2.utils.events INFO:  eta: 0:46:44  iter: 1079  total_loss: 0.4697  loss_cls: 0.2573  loss_box_reg: 0.2103  time: 0.8737  last_time: 0.8835  data_time: 0.0633  last_data_time: 0.0658   lr: 0.01  max_mem: 21305M
[02/26 23:00:15] d2.utils.events INFO:  eta: 0:46:27  iter: 1099  total_loss: 0.4703  loss_cls: 0.2592  loss_box_reg: 0.2113  time: 0.8737  last_time: 0.8788  data_time: 0.0587  last_data_time: 0.0612   lr: 0.01  max_mem: 21305M
[02/26 23:00:32] d2.utils.events INFO:  eta: 0:46:09  iter: 1119  total_loss: 0.4534  loss_cls: 0.245  loss_box_reg: 0.2081  time: 0.8737  last_time: 0.8782  data_time: 0.0586  last_data_time: 0.0597   lr: 0.01  max_mem: 21305M
[02/26 23:00:50] d2.utils.events INFO:  eta: 0:45:52  iter: 1139  total_loss: 0.4409  loss_cls: 0.2395  loss_box_reg: 0.2007  time: 0.8737  last_time: 0.8817  data_time: 0.0619  last_data_time: 0.0648   lr: 0.01  max_mem: 21305M
[02/26 23:01:07] d2.utils.events INFO:  eta: 0:45:35  iter: 1159  total_loss: 0.4454  loss_cls: 0.2393  loss_box_reg: 0.207  time: 0.8738  last_time: 0.8739  data_time: 0.0613  last_data_time: 0.0570   lr: 0.01  max_mem: 21305M
[02/26 23:01:25] d2.utils.events INFO:  eta: 0:45:17  iter: 1179  total_loss: 0.4487  loss_cls: 0.2398  loss_box_reg: 0.2104  time: 0.8738  last_time: 0.8788  data_time: 0.0577  last_data_time: 0.0611   lr: 0.01  max_mem: 21305M
[02/26 23:01:42] d2.utils.events INFO:  eta: 0:45:00  iter: 1199  total_loss: 0.4287  loss_cls: 0.2321  loss_box_reg: 0.2013  time: 0.8736  last_time: 0.8702  data_time: 0.0592  last_data_time: 0.0527   lr: 0.01  max_mem: 21305M
[02/26 23:02:00] d2.utils.events INFO:  eta: 0:44:43  iter: 1219  total_loss: 0.4149  loss_cls: 0.2208  loss_box_reg: 0.1958  time: 0.8737  last_time: 0.8765  data_time: 0.0615  last_data_time: 0.0585   lr: 0.01  max_mem: 21305M
[02/26 23:02:17] d2.utils.events INFO:  eta: 0:44:25  iter: 1239  total_loss: 0.4088  loss_cls: 0.2123  loss_box_reg: 0.197  time: 0.8737  last_time: 0.8831  data_time: 0.0611  last_data_time: 0.0659   lr: 0.01  max_mem: 21305M
[02/26 23:02:35] d2.utils.events INFO:  eta: 0:44:07  iter: 1259  total_loss: 0.4197  loss_cls: 0.2193  loss_box_reg: 0.1999  time: 0.8737  last_time: 0.8804  data_time: 0.0598  last_data_time: 0.0624   lr: 0.01  max_mem: 21305M
[02/26 23:02:52] d2.utils.events INFO:  eta: 0:43:50  iter: 1279  total_loss: 0.4168  loss_cls: 0.2124  loss_box_reg: 0.2036  time: 0.8737  last_time: 0.8817  data_time: 0.0602  last_data_time: 0.0634   lr: 0.01  max_mem: 21305M
[02/26 23:03:10] d2.utils.events INFO:  eta: 0:43:32  iter: 1299  total_loss: 0.3945  loss_cls: 0.2004  loss_box_reg: 0.1936  time: 0.8738  last_time: 0.8824  data_time: 0.0584  last_data_time: 0.0648   lr: 0.01  max_mem: 21305M
[02/26 23:03:27] d2.utils.events INFO:  eta: 0:43:15  iter: 1319  total_loss: 0.4061  loss_cls: 0.2065  loss_box_reg: 0.1968  time: 0.8737  last_time: 0.8798  data_time: 0.0606  last_data_time: 0.0625   lr: 0.01  max_mem: 21305M
[02/26 23:03:44] d2.utils.events INFO:  eta: 0:42:57  iter: 1339  total_loss: 0.3869  loss_cls: 0.196  loss_box_reg: 0.1927  time: 0.8737  last_time: 0.8846  data_time: 0.0578  last_data_time: 0.0680   lr: 0.01  max_mem: 21305M
[02/26 23:04:02] d2.utils.events INFO:  eta: 0:42:40  iter: 1359  total_loss: 0.3939  loss_cls: 0.1979  loss_box_reg: 0.1988  time: 0.8735  last_time: 0.8876  data_time: 0.0582  last_data_time: 0.0686   lr: 0.01  max_mem: 21305M
[02/26 23:04:19] d2.utils.events INFO:  eta: 0:42:22  iter: 1379  total_loss: 0.3726  loss_cls: 0.1869  loss_box_reg: 0.1822  time: 0.8736  last_time: 0.8818  data_time: 0.0613  last_data_time: 0.0646   lr: 0.01  max_mem: 21305M
[02/26 23:04:37] d2.utils.events INFO:  eta: 0:42:05  iter: 1399  total_loss: 0.3672  loss_cls: 0.1801  loss_box_reg: 0.1861  time: 0.8735  last_time: 0.8944  data_time: 0.0576  last_data_time: 0.0767   lr: 0.01  max_mem: 21305M
[02/26 23:04:54] d2.utils.events INFO:  eta: 0:41:47  iter: 1419  total_loss: 0.3668  loss_cls: 0.1849  loss_box_reg: 0.1843  time: 0.8736  last_time: 0.8770  data_time: 0.0600  last_data_time: 0.0592   lr: 0.01  max_mem: 21305M
[02/26 23:05:00] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0001426.pth
[02/26 23:05:02] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 23:05:02] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/26 23:05:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/26 23:05:02] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 23:05:02] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/26 23:05:02] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/26 23:05:02] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/26 23:05:02] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0004 s/iter. Inference: 0.0290 s/iter. Eval: 0.0002 s/iter. Total: 0.0296 s/iter. ETA=0:00:04
[02/26 23:05:06] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.636706 (0.029914 s / iter per device, on 1 devices)
[02/26 23:05:06] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.028883 s / iter per device, on 1 devices)
[02/26 23:05:06] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/26 23:05:06] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/26 23:05:06] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/26 23:05:07] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/26 23:05:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.20 seconds.
[02/26 23:05:07] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/26 23:05:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.11 seconds.
[02/26 23:05:07] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 12.264 | 21.564 | 12.212 | 4.566 | 21.512 | 21.977 |
[02/26 23:05:07] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 12.255 | 001_binder_clips_median      | 24.176 | 002_binder_clips_small       | 14.436 |
| 003_bombik_bucket          | 8.954  | 004_bonne_maman_blueberry    | 0.169  | 005_bonne_maman_raspberry    | 0.710  |
| 006_bonne_maman_strawberry | 0.046  | 007_costa_caramel            | 28.273 | 008_essential_oil_bergamot   | 10.452 |
| 009_garlic_toast_spread    | 2.706  | 010_handcream_avocado        | 0.947  | 011_hb_calcium               | 10.853 |
| 012_hb_grapeseed           | 8.029  | 013_hb_marine_collagen       | 7.367  | 014_hellmanns_mayonnaise     | 4.196  |
| 015_illy_blend             | 0.936  | 016_japanese_finger_cookies  | 1.070  | 017_john_west_canned_tuna    | 5.323  |
| 018_kerastase_shampoo      | 9.843  | 019_kiehls_facial_cream      | 19.838 | 020_kiihne_balsamic          | 0.057  |
| 021_kiihne_honey_mustard   | 9.353  | 022_lindor_matcha            | 23.153 | 023_lindor_salted_caramel    | 31.871 |
| 024_lush_mask              | 71.709 | 025_pasta_sauce_black_pepper | 4.620  | 026_pasta_sauce_tomato       | 3.036  |
| 027_pepsi                  | 39.750 | 028_portable_yogurt_machine  | 0.638  | 029_selfile_stick            | 0.997  |
| 030_sour_lemon_drops       | 4.356  | 031_sticky_notes             | 14.010 | 032_stridex_green            | 36.221 |
| 033_thermos_flask_cream    | 36.896 | 034_thermos_flask_muji       | 1.612  | 035_thermos_flask_sliver     | 2.673  |
| 036_tragata_olive_oil      | 5.340  | 037_tulip_luncheon_meat      | 5.499  | 038_unicharm_cotton_pad      | 40.668 |
| 039_vinda_tissue           | 33.424 | 040_wrigley_doublemint_gum   | 0.000  | 041_baseball_cap_black       | 11.462 |
| 042_baseball_cap_pink      | 21.674 | 043_bfe_facial_mask          | 28.347 | 044_corgi_doll               | 13.030 |
| 045_dinosaur_doll          | 32.888 | 046_geo_mocha                | 4.463  | 047_geo_roast_charcoal       | 2.908  |
| 048_instant_noodle_black   | 5.787  | 049_instant_noodle_red       | 17.282 | 050_nabati_cheese_wafer      | 32.309 |
| 051_truffettes             | 6.524  | 052_acnes_cream              | 11.134 | 053_aveda_conditioner        | 28.170 |
| 054_banana_milk_drink      | 5.319  | 055_candle_beast             | 23.815 | 056_china_persimmon          | 10.473 |
| 057_danisa_butter_cookies  | 1.143  | 058_effaclar_duo             | 6.832  | 059_evelom_cleanser          | 20.829 |
| 060_glasses_box_blone      | 25.235 | 061_handcream_iris           | 0.074  | 062_handcream_lavender       | 0.099  |
| 063_handcream_rosewater    | 0.076  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 1.750  |
| 066_japanese_chocolate     | 23.187 | 067_kerastase_hair_treatment | 8.537  | 068_kiehls_serum             | 9.592  |
| 069_korean_beef_marinade   | 14.839 | 070_korean_doenjang          | 9.442  | 071_korean_gochujang         | 0.000  |
| 072_korean_ssamjang        | 9.895  | 073_loccitane_soap           | 18.232 | 074_marvis_toothpaste_purple | 23.044 |
| 075_mouse_thinkpad         | 2.959  | 076_oatly_chocolate          | 7.766  | 077_oatly_original           | 19.212 |
| 078_ousa_grated_cheese     | 7.002  | 079_polaroid_film            | 2.326  | 080_skinceuticals_be         | 29.057 |
| 081_skinceuticals_cf       | 11.656 | 082_skinceuticals_phyto      | 18.761 | 083_stapler_black            | 11.390 |
| 084_stapler_blue           | 12.742 | 085_sunscreen_blue           | 0.225  | 086_tempo_pocket_tissue      | 0.096  |
| 087_thermos_flask_purple   | 33.916 | 088_uha_matcha               | 11.421 | 089_urban_decay_spray        | 5.970  |
| 090_vitaboost_multivitamin | 6.471  | 091_watercolor_penbox        | 0.057  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 12.647 | 094_kaneyo_kitchen_bleach    | 15.718 | 095_lays_chip_bag_blue       | 11.938 |
| 096_lays_chip_bag_green    | 10.054 | 097_lays_chip_tube_auburn    | 10.627 | 098_lays_chip_tube_green     | 19.534 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/26 23:05:07] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/26 23:05:07] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/26 23:05:07] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/26 23:05:07] d2.evaluation.testing INFO: copypaste: 12.2639,21.5637,12.2116,4.5658,21.5118,21.9767
[02/26 23:05:17] d2.utils.events INFO:  eta: 0:41:30  iter: 1439  total_loss: 0.3708  loss_cls: 0.1831  loss_box_reg: 0.1879  time: 0.8736  last_time: 0.8803  data_time: 0.0576  last_data_time: 0.0613   lr: 0.01  max_mem: 21305M
[02/26 23:05:35] d2.utils.events INFO:  eta: 0:41:12  iter: 1459  total_loss: 0.3829  loss_cls: 0.1937  loss_box_reg: 0.1902  time: 0.8735  last_time: 0.8807  data_time: 0.0597  last_data_time: 0.0635   lr: 0.01  max_mem: 21305M
[02/26 23:05:52] d2.utils.events INFO:  eta: 0:40:55  iter: 1479  total_loss: 0.3603  loss_cls: 0.178  loss_box_reg: 0.1823  time: 0.8735  last_time: 0.8801  data_time: 0.0606  last_data_time: 0.0611   lr: 0.01  max_mem: 21305M
[02/26 23:06:10] d2.utils.events INFO:  eta: 0:40:38  iter: 1499  total_loss: 0.3625  loss_cls: 0.179  loss_box_reg: 0.1839  time: 0.8736  last_time: 0.8848  data_time: 0.0603  last_data_time: 0.0677   lr: 0.01  max_mem: 21305M
[02/26 23:06:27] d2.utils.events INFO:  eta: 0:40:20  iter: 1519  total_loss: 0.3619  loss_cls: 0.1752  loss_box_reg: 0.1837  time: 0.8736  last_time: 0.8758  data_time: 0.0607  last_data_time: 0.0580   lr: 0.01  max_mem: 21305M
[02/26 23:06:45] d2.utils.events INFO:  eta: 0:40:03  iter: 1539  total_loss: 0.3595  loss_cls: 0.1746  loss_box_reg: 0.1814  time: 0.8737  last_time: 0.8756  data_time: 0.0613  last_data_time: 0.0567   lr: 0.01  max_mem: 21305M
[02/26 23:07:02] d2.utils.events INFO:  eta: 0:39:46  iter: 1559  total_loss: 0.3519  loss_cls: 0.1703  loss_box_reg: 0.1823  time: 0.8737  last_time: 0.8822  data_time: 0.0605  last_data_time: 0.0639   lr: 0.01  max_mem: 21305M
[02/26 23:07:20] d2.utils.events INFO:  eta: 0:39:28  iter: 1579  total_loss: 0.3677  loss_cls: 0.1819  loss_box_reg: 0.1852  time: 0.8737  last_time: 0.8762  data_time: 0.0629  last_data_time: 0.0580   lr: 0.01  max_mem: 21305M
[02/26 23:07:37] d2.utils.events INFO:  eta: 0:39:11  iter: 1599  total_loss: 0.344  loss_cls: 0.1708  loss_box_reg: 0.1778  time: 0.8737  last_time: 0.8742  data_time: 0.0610  last_data_time: 0.0583   lr: 0.01  max_mem: 21305M
[02/26 23:07:55] d2.utils.events INFO:  eta: 0:38:53  iter: 1619  total_loss: 0.3566  loss_cls: 0.1683  loss_box_reg: 0.1855  time: 0.8737  last_time: 0.8903  data_time: 0.0604  last_data_time: 0.0735   lr: 0.01  max_mem: 21305M
[02/26 23:08:12] d2.utils.events INFO:  eta: 0:38:36  iter: 1639  total_loss: 0.3493  loss_cls: 0.1686  loss_box_reg: 0.1807  time: 0.8737  last_time: 0.8829  data_time: 0.0602  last_data_time: 0.0653   lr: 0.01  max_mem: 21305M
[02/26 23:08:30] d2.utils.events INFO:  eta: 0:38:18  iter: 1659  total_loss: 0.3466  loss_cls: 0.165  loss_box_reg: 0.1808  time: 0.8737  last_time: 0.8776  data_time: 0.0601  last_data_time: 0.0591   lr: 0.01  max_mem: 21305M
[02/26 23:08:47] d2.utils.events INFO:  eta: 0:38:01  iter: 1679  total_loss: 0.347  loss_cls: 0.1692  loss_box_reg: 0.1773  time: 0.8737  last_time: 0.8867  data_time: 0.0635  last_data_time: 0.0691   lr: 0.01  max_mem: 21305M
[02/26 23:09:05] d2.utils.events INFO:  eta: 0:37:44  iter: 1699  total_loss: 0.3351  loss_cls: 0.1594  loss_box_reg: 0.1765  time: 0.8737  last_time: 0.8655  data_time: 0.0601  last_data_time: 0.0492   lr: 0.01  max_mem: 21305M
[02/26 23:09:22] d2.utils.events INFO:  eta: 0:37:26  iter: 1719  total_loss: 0.3404  loss_cls: 0.1605  loss_box_reg: 0.1774  time: 0.8737  last_time: 0.8823  data_time: 0.0630  last_data_time: 0.0650   lr: 0.01  max_mem: 21305M
[02/26 23:09:40] d2.utils.events INFO:  eta: 0:37:09  iter: 1739  total_loss: 0.3295  loss_cls: 0.1563  loss_box_reg: 0.1731  time: 0.8737  last_time: 0.8752  data_time: 0.0608  last_data_time: 0.0574   lr: 0.01  max_mem: 21305M
[02/26 23:09:57] d2.utils.events INFO:  eta: 0:36:51  iter: 1759  total_loss: 0.3326  loss_cls: 0.1564  loss_box_reg: 0.1762  time: 0.8738  last_time: 0.8840  data_time: 0.0615  last_data_time: 0.0660   lr: 0.01  max_mem: 21305M
[02/26 23:10:15] d2.utils.events INFO:  eta: 0:36:34  iter: 1779  total_loss: 0.3382  loss_cls: 0.1638  loss_box_reg: 0.1781  time: 0.8738  last_time: 0.8860  data_time: 0.0611  last_data_time: 0.0671   lr: 0.01  max_mem: 21305M
[02/26 23:10:32] d2.utils.events INFO:  eta: 0:36:17  iter: 1799  total_loss: 0.3338  loss_cls: 0.1553  loss_box_reg: 0.1811  time: 0.8738  last_time: 0.8835  data_time: 0.0599  last_data_time: 0.0658   lr: 0.01  max_mem: 21305M
[02/26 23:10:50] d2.utils.events INFO:  eta: 0:36:00  iter: 1819  total_loss: 0.3232  loss_cls: 0.1557  loss_box_reg: 0.1713  time: 0.8738  last_time: 0.8843  data_time: 0.0609  last_data_time: 0.0661   lr: 0.01  max_mem: 21305M
[02/26 23:11:07] d2.utils.events INFO:  eta: 0:35:43  iter: 1839  total_loss: 0.3253  loss_cls: 0.1546  loss_box_reg: 0.1738  time: 0.8739  last_time: 0.8825  data_time: 0.0623  last_data_time: 0.0646   lr: 0.01  max_mem: 21305M
[02/26 23:11:25] d2.utils.events INFO:  eta: 0:35:25  iter: 1859  total_loss: 0.3353  loss_cls: 0.1535  loss_box_reg: 0.1794  time: 0.8739  last_time: 0.8823  data_time: 0.0581  last_data_time: 0.0639   lr: 0.01  max_mem: 21305M
[02/26 23:11:42] d2.utils.events INFO:  eta: 0:35:08  iter: 1879  total_loss: 0.31  loss_cls: 0.1458  loss_box_reg: 0.1655  time: 0.8739  last_time: 0.8345  data_time: 0.0605  last_data_time: 0.0664   lr: 0.01  max_mem: 21305M
[02/26 23:12:00] d2.utils.events INFO:  eta: 0:34:50  iter: 1899  total_loss: 0.33  loss_cls: 0.1581  loss_box_reg: 0.1743  time: 0.8739  last_time: 0.8736  data_time: 0.0614  last_data_time: 0.0544   lr: 0.01  max_mem: 21305M
[02/26 23:12:17] d2.utils.events INFO:  eta: 0:34:33  iter: 1919  total_loss: 0.3244  loss_cls: 0.1523  loss_box_reg: 0.1727  time: 0.8738  last_time: 0.8669  data_time: 0.0582  last_data_time: 0.0486   lr: 0.01  max_mem: 21305M
[02/26 23:12:35] d2.utils.events INFO:  eta: 0:34:15  iter: 1939  total_loss: 0.31  loss_cls: 0.1458  loss_box_reg: 0.1641  time: 0.8737  last_time: 0.8675  data_time: 0.0592  last_data_time: 0.0504   lr: 0.01  max_mem: 21305M
[02/26 23:12:52] d2.utils.events INFO:  eta: 0:33:57  iter: 1959  total_loss: 0.3278  loss_cls: 0.1533  loss_box_reg: 0.1722  time: 0.8737  last_time: 0.8844  data_time: 0.0585  last_data_time: 0.0659   lr: 0.01  max_mem: 21305M
[02/26 23:13:09] d2.utils.events INFO:  eta: 0:33:39  iter: 1979  total_loss: 0.311  loss_cls: 0.145  loss_box_reg: 0.1661  time: 0.8737  last_time: 0.8761  data_time: 0.0604  last_data_time: 0.0583   lr: 0.01  max_mem: 21305M
[02/26 23:13:27] d2.utils.events INFO:  eta: 0:33:21  iter: 1999  total_loss: 0.3265  loss_cls: 0.1513  loss_box_reg: 0.1739  time: 0.8736  last_time: 0.8834  data_time: 0.0585  last_data_time: 0.0668   lr: 0.01  max_mem: 21305M
[02/26 23:13:44] d2.utils.events INFO:  eta: 0:33:03  iter: 2019  total_loss: 0.3204  loss_cls: 0.1475  loss_box_reg: 0.1694  time: 0.8736  last_time: 0.8824  data_time: 0.0566  last_data_time: 0.0662   lr: 0.01  max_mem: 21305M
[02/26 23:14:02] d2.utils.events INFO:  eta: 0:32:45  iter: 2039  total_loss: 0.3171  loss_cls: 0.1441  loss_box_reg: 0.1676  time: 0.8735  last_time: 0.8718  data_time: 0.0564  last_data_time: 0.0546   lr: 0.01  max_mem: 21305M
[02/26 23:14:19] d2.utils.events INFO:  eta: 0:32:28  iter: 2059  total_loss: 0.3193  loss_cls: 0.1454  loss_box_reg: 0.1734  time: 0.8736  last_time: 0.8711  data_time: 0.0596  last_data_time: 0.0532   lr: 0.01  max_mem: 21305M
[02/26 23:14:37] d2.utils.events INFO:  eta: 0:32:10  iter: 2079  total_loss: 0.3177  loss_cls: 0.1473  loss_box_reg: 0.1705  time: 0.8736  last_time: 0.8168  data_time: 0.0597  last_data_time: 0.0469   lr: 0.01  max_mem: 21305M
[02/26 23:14:54] d2.utils.events INFO:  eta: 0:31:53  iter: 2099  total_loss: 0.3061  loss_cls: 0.1366  loss_box_reg: 0.1644  time: 0.8736  last_time: 0.8768  data_time: 0.0580  last_data_time: 0.0585   lr: 0.01  max_mem: 21305M
[02/26 23:15:12] d2.utils.events INFO:  eta: 0:31:35  iter: 2119  total_loss: 0.3091  loss_cls: 0.1414  loss_box_reg: 0.1686  time: 0.8736  last_time: 0.8879  data_time: 0.0622  last_data_time: 0.0696   lr: 0.01  max_mem: 21305M
[02/26 23:15:29] d2.utils.events INFO:  eta: 0:31:17  iter: 2139  total_loss: 0.3032  loss_cls: 0.1395  loss_box_reg: 0.1643  time: 0.8736  last_time: 0.8816  data_time: 0.0597  last_data_time: 0.0642   lr: 0.01  max_mem: 21305M
[02/26 23:15:47] d2.utils.events INFO:  eta: 0:31:00  iter: 2159  total_loss: 0.3097  loss_cls: 0.1392  loss_box_reg: 0.1681  time: 0.8737  last_time: 0.8833  data_time: 0.0617  last_data_time: 0.0660   lr: 0.01  max_mem: 21305M
[02/26 23:16:04] d2.utils.events INFO:  eta: 0:30:42  iter: 2179  total_loss: 0.3072  loss_cls: 0.1406  loss_box_reg: 0.1685  time: 0.8737  last_time: 0.8866  data_time: 0.0585  last_data_time: 0.0683   lr: 0.01  max_mem: 21305M
[02/26 23:16:22] d2.utils.events INFO:  eta: 0:30:25  iter: 2199  total_loss: 0.2965  loss_cls: 0.1342  loss_box_reg: 0.163  time: 0.8736  last_time: 0.8703  data_time: 0.0602  last_data_time: 0.0528   lr: 0.01  max_mem: 21305M
[02/26 23:16:39] d2.utils.events INFO:  eta: 0:30:07  iter: 2219  total_loss: 0.3098  loss_cls: 0.1413  loss_box_reg: 0.1671  time: 0.8737  last_time: 0.8839  data_time: 0.0627  last_data_time: 0.0653   lr: 0.01  max_mem: 21305M
[02/26 23:16:57] d2.utils.events INFO:  eta: 0:29:50  iter: 2239  total_loss: 0.3025  loss_cls: 0.1342  loss_box_reg: 0.1671  time: 0.8737  last_time: 0.8672  data_time: 0.0608  last_data_time: 0.0495   lr: 0.01  max_mem: 21305M
[02/26 23:17:14] d2.utils.events INFO:  eta: 0:29:32  iter: 2259  total_loss: 0.3033  loss_cls: 0.1349  loss_box_reg: 0.1661  time: 0.8737  last_time: 0.8339  data_time: 0.0603  last_data_time: 0.0647   lr: 0.01  max_mem: 21305M
[02/26 23:17:32] d2.utils.events INFO:  eta: 0:29:15  iter: 2279  total_loss: 0.3008  loss_cls: 0.1327  loss_box_reg: 0.1681  time: 0.8737  last_time: 0.8599  data_time: 0.0593  last_data_time: 0.0415   lr: 0.01  max_mem: 21305M
[02/26 23:17:49] d2.utils.events INFO:  eta: 0:28:57  iter: 2299  total_loss: 0.3054  loss_cls: 0.1353  loss_box_reg: 0.1662  time: 0.8737  last_time: 0.8674  data_time: 0.0572  last_data_time: 0.0495   lr: 0.01  max_mem: 21305M
[02/26 23:18:07] d2.utils.events INFO:  eta: 0:28:39  iter: 2319  total_loss: 0.2931  loss_cls: 0.132  loss_box_reg: 0.1618  time: 0.8737  last_time: 0.8613  data_time: 0.0588  last_data_time: 0.0442   lr: 0.01  max_mem: 21305M
[02/26 23:18:24] d2.utils.events INFO:  eta: 0:28:21  iter: 2339  total_loss: 0.2928  loss_cls: 0.1315  loss_box_reg: 0.1611  time: 0.8737  last_time: 0.8733  data_time: 0.0577  last_data_time: 0.0561   lr: 0.01  max_mem: 21305M
[02/26 23:18:42] d2.utils.events INFO:  eta: 0:28:04  iter: 2359  total_loss: 0.2858  loss_cls: 0.1319  loss_box_reg: 0.1545  time: 0.8737  last_time: 0.8690  data_time: 0.0618  last_data_time: 0.0510   lr: 0.01  max_mem: 21305M
[02/26 23:18:59] d2.utils.events INFO:  eta: 0:27:46  iter: 2379  total_loss: 0.2941  loss_cls: 0.1314  loss_box_reg: 0.166  time: 0.8737  last_time: 0.8307  data_time: 0.0572  last_data_time: 0.0614   lr: 0.01  max_mem: 21305M
[02/26 23:19:16] d2.utils.events INFO:  eta: 0:27:29  iter: 2399  total_loss: 0.2927  loss_cls: 0.1284  loss_box_reg: 0.1609  time: 0.8736  last_time: 0.8950  data_time: 0.0595  last_data_time: 0.0771   lr: 0.01  max_mem: 21305M
[02/26 23:19:34] d2.utils.events INFO:  eta: 0:27:11  iter: 2419  total_loss: 0.2962  loss_cls: 0.1287  loss_box_reg: 0.1653  time: 0.8736  last_time: 0.8869  data_time: 0.0585  last_data_time: 0.0693   lr: 0.01  max_mem: 21305M
[02/26 23:19:51] d2.utils.events INFO:  eta: 0:26:54  iter: 2439  total_loss: 0.2808  loss_cls: 0.1233  loss_box_reg: 0.1569  time: 0.8736  last_time: 0.8741  data_time: 0.0610  last_data_time: 0.0578   lr: 0.01  max_mem: 21305M
[02/26 23:20:09] d2.utils.events INFO:  eta: 0:26:36  iter: 2459  total_loss: 0.2853  loss_cls: 0.1262  loss_box_reg: 0.1582  time: 0.8736  last_time: 0.8259  data_time: 0.0609  last_data_time: 0.0578   lr: 0.01  max_mem: 21305M
[02/26 23:20:26] d2.utils.events INFO:  eta: 0:26:19  iter: 2479  total_loss: 0.2889  loss_cls: 0.1263  loss_box_reg: 0.1642  time: 0.8736  last_time: 0.8653  data_time: 0.0587  last_data_time: 0.0479   lr: 0.01  max_mem: 21305M
[02/26 23:20:44] d2.utils.events INFO:  eta: 0:26:01  iter: 2499  total_loss: 0.29  loss_cls: 0.1299  loss_box_reg: 0.1633  time: 0.8736  last_time: 0.8682  data_time: 0.0605  last_data_time: 0.0501   lr: 0.01  max_mem: 21305M
[02/26 23:21:01] d2.utils.events INFO:  eta: 0:25:43  iter: 2519  total_loss: 0.2882  loss_cls: 0.1298  loss_box_reg: 0.1571  time: 0.8736  last_time: 0.8216  data_time: 0.0589  last_data_time: 0.0532   lr: 0.01  max_mem: 21305M
[02/26 23:21:19] d2.utils.events INFO:  eta: 0:25:26  iter: 2539  total_loss: 0.2889  loss_cls: 0.1282  loss_box_reg: 0.1587  time: 0.8736  last_time: 0.8734  data_time: 0.0594  last_data_time: 0.0569   lr: 0.01  max_mem: 21305M
[02/26 23:21:36] d2.utils.events INFO:  eta: 0:25:08  iter: 2559  total_loss: 0.2823  loss_cls: 0.1268  loss_box_reg: 0.1578  time: 0.8736  last_time: 0.8788  data_time: 0.0599  last_data_time: 0.0617   lr: 0.01  max_mem: 21305M
[02/26 23:21:54] d2.utils.events INFO:  eta: 0:24:51  iter: 2579  total_loss: 0.2804  loss_cls: 0.1239  loss_box_reg: 0.1606  time: 0.8736  last_time: 0.8827  data_time: 0.0577  last_data_time: 0.0650   lr: 0.01  max_mem: 21305M
[02/26 23:22:11] d2.utils.events INFO:  eta: 0:24:33  iter: 2599  total_loss: 0.278  loss_cls: 0.1216  loss_box_reg: 0.1573  time: 0.8736  last_time: 0.8885  data_time: 0.0604  last_data_time: 0.0710   lr: 0.01  max_mem: 21305M
[02/26 23:22:29] d2.utils.events INFO:  eta: 0:24:16  iter: 2619  total_loss: 0.2818  loss_cls: 0.1218  loss_box_reg: 0.1596  time: 0.8736  last_time: 0.8684  data_time: 0.0607  last_data_time: 0.0508   lr: 0.01  max_mem: 21305M
[02/26 23:22:46] d2.utils.events INFO:  eta: 0:23:58  iter: 2639  total_loss: 0.2714  loss_cls: 0.12  loss_box_reg: 0.1527  time: 0.8736  last_time: 0.8860  data_time: 0.0599  last_data_time: 0.0666   lr: 0.01  max_mem: 21305M
[02/26 23:23:03] d2.utils.events INFO:  eta: 0:23:40  iter: 2659  total_loss: 0.291  loss_cls: 0.1316  loss_box_reg: 0.1614  time: 0.8735  last_time: 0.8685  data_time: 0.0591  last_data_time: 0.0509   lr: 0.01  max_mem: 21305M
[02/26 23:23:21] d2.utils.events INFO:  eta: 0:23:23  iter: 2679  total_loss: 0.2786  loss_cls: 0.123  loss_box_reg: 0.1577  time: 0.8735  last_time: 0.8668  data_time: 0.0614  last_data_time: 0.0498   lr: 0.01  max_mem: 21305M
[02/26 23:23:38] d2.utils.events INFO:  eta: 0:23:05  iter: 2699  total_loss: 0.2752  loss_cls: 0.1189  loss_box_reg: 0.1534  time: 0.8735  last_time: 0.8323  data_time: 0.0625  last_data_time: 0.0643   lr: 0.01  max_mem: 21305M
[02/26 23:23:56] d2.utils.events INFO:  eta: 0:22:48  iter: 2719  total_loss: 0.2862  loss_cls: 0.1247  loss_box_reg: 0.1596  time: 0.8735  last_time: 0.8729  data_time: 0.0604  last_data_time: 0.0565   lr: 0.01  max_mem: 21305M
[02/26 23:24:13] d2.utils.events INFO:  eta: 0:22:30  iter: 2739  total_loss: 0.2785  loss_cls: 0.1236  loss_box_reg: 0.1591  time: 0.8735  last_time: 0.8716  data_time: 0.0602  last_data_time: 0.0544   lr: 0.01  max_mem: 21305M
[02/26 23:24:31] d2.utils.events INFO:  eta: 0:22:13  iter: 2759  total_loss: 0.2808  loss_cls: 0.124  loss_box_reg: 0.1573  time: 0.8735  last_time: 0.8834  data_time: 0.0604  last_data_time: 0.0651   lr: 0.01  max_mem: 21305M
[02/26 23:24:48] d2.utils.events INFO:  eta: 0:21:55  iter: 2779  total_loss: 0.2679  loss_cls: 0.1164  loss_box_reg: 0.1512  time: 0.8735  last_time: 0.8678  data_time: 0.0605  last_data_time: 0.0510   lr: 0.01  max_mem: 21305M
[02/26 23:25:06] d2.utils.events INFO:  eta: 0:21:38  iter: 2799  total_loss: 0.2817  loss_cls: 0.1219  loss_box_reg: 0.1578  time: 0.8735  last_time: 0.8665  data_time: 0.0589  last_data_time: 0.0495   lr: 0.01  max_mem: 21305M
[02/26 23:25:23] d2.utils.events INFO:  eta: 0:21:20  iter: 2819  total_loss: 0.2714  loss_cls: 0.1195  loss_box_reg: 0.1508  time: 0.8735  last_time: 0.8868  data_time: 0.0592  last_data_time: 0.0693   lr: 0.01  max_mem: 21305M
[02/26 23:25:41] d2.utils.events INFO:  eta: 0:21:02  iter: 2839  total_loss: 0.2629  loss_cls: 0.1149  loss_box_reg: 0.1484  time: 0.8735  last_time: 0.8939  data_time: 0.0616  last_data_time: 0.0763   lr: 0.01  max_mem: 21305M
[02/26 23:25:53] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0002853.pth
[02/26 23:25:55] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 23:25:55] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/26 23:25:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/26 23:25:55] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 23:25:55] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/26 23:25:55] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/26 23:25:55] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/26 23:25:55] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0004 s/iter. Inference: 0.0289 s/iter. Eval: 0.0002 s/iter. Total: 0.0294 s/iter. ETA=0:00:04
[02/26 23:26:00] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.659722 (0.030063 s / iter per device, on 1 devices)
[02/26 23:26:00] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.028943 s / iter per device, on 1 devices)
[02/26 23:26:00] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/26 23:26:00] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/26 23:26:00] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/26 23:26:00] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/26 23:26:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.25 seconds.
[02/26 23:26:00] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/26 23:26:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.11 seconds.
[02/26 23:26:00] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.697 | 24.003 | 15.692 | 7.103 | 23.970 | 28.563 |
[02/26 23:26:00] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 16.825 | 001_binder_clips_median      | 27.713 | 002_binder_clips_small       | 19.936 |
| 003_bombik_bucket          | 10.698 | 004_bonne_maman_blueberry    | 0.142  | 005_bonne_maman_raspberry    | 0.323  |
| 006_bonne_maman_strawberry | 0.186  | 007_costa_caramel            | 26.404 | 008_essential_oil_bergamot   | 19.594 |
| 009_garlic_toast_spread    | 2.579  | 010_handcream_avocado        | 0.844  | 011_hb_calcium               | 13.334 |
| 012_hb_grapeseed           | 9.406  | 013_hb_marine_collagen       | 10.139 | 014_hellmanns_mayonnaise     | 4.277  |
| 015_illy_blend             | 2.107  | 016_japanese_finger_cookies  | 3.798  | 017_john_west_canned_tuna    | 6.837  |
| 018_kerastase_shampoo      | 8.276  | 019_kiehls_facial_cream      | 28.077 | 020_kiihne_balsamic          | 0.099  |
| 021_kiihne_honey_mustard   | 16.107 | 022_lindor_matcha            | 27.695 | 023_lindor_salted_caramel    | 38.562 |
| 024_lush_mask              | 69.900 | 025_pasta_sauce_black_pepper | 1.423  | 026_pasta_sauce_tomato       | 8.678  |
| 027_pepsi                  | 46.730 | 028_portable_yogurt_machine  | 1.584  | 029_selfile_stick            | 1.516  |
| 030_sour_lemon_drops       | 4.664  | 031_sticky_notes             | 10.085 | 032_stridex_green            | 43.340 |
| 033_thermos_flask_cream    | 39.166 | 034_thermos_flask_muji       | 0.198  | 035_thermos_flask_sliver     | 0.084  |
| 036_tragata_olive_oil      | 5.083  | 037_tulip_luncheon_meat      | 10.871 | 038_unicharm_cotton_pad      | 44.128 |
| 039_vinda_tissue           | 37.518 | 040_wrigley_doublemint_gum   | 0.099  | 041_baseball_cap_black       | 14.008 |
| 042_baseball_cap_pink      | 17.652 | 043_bfe_facial_mask          | 27.142 | 044_corgi_doll               | 9.717  |
| 045_dinosaur_doll          | 30.536 | 046_geo_mocha                | 4.878  | 047_geo_roast_charcoal       | 3.354  |
| 048_instant_noodle_black   | 7.330  | 049_instant_noodle_red       | 22.639 | 050_nabati_cheese_wafer      | 42.024 |
| 051_truffettes             | 8.596  | 052_acnes_cream              | 22.754 | 053_aveda_conditioner        | 26.621 |
| 054_banana_milk_drink      | 4.097  | 055_candle_beast             | 18.498 | 056_china_persimmon          | 14.805 |
| 057_danisa_butter_cookies  | 1.941  | 058_effaclar_duo             | 7.525  | 059_evelom_cleanser          | 16.768 |
| 060_glasses_box_blone      | 27.510 | 061_handcream_iris           | 0.030  | 062_handcream_lavender       | 0.052  |
| 063_handcream_rosewater    | 0.694  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 3.313  |
| 066_japanese_chocolate     | 35.685 | 067_kerastase_hair_treatment | 11.837 | 068_kiehls_serum             | 20.004 |
| 069_korean_beef_marinade   | 20.318 | 070_korean_doenjang          | 20.505 | 071_korean_gochujang         | 0.059  |
| 072_korean_ssamjang        | 12.066 | 073_loccitane_soap           | 18.010 | 074_marvis_toothpaste_purple | 48.270 |
| 075_mouse_thinkpad         | 4.413  | 076_oatly_chocolate          | 7.361  | 077_oatly_original           | 17.671 |
| 078_ousa_grated_cheese     | 4.403  | 079_polaroid_film            | 0.938  | 080_skinceuticals_be         | 50.776 |
| 081_skinceuticals_cf       | 26.900 | 082_skinceuticals_phyto      | 17.457 | 083_stapler_black            | 9.172  |
| 084_stapler_blue           | 13.781 | 085_sunscreen_blue           | 0.119  | 086_tempo_pocket_tissue      | 0.234  |
| 087_thermos_flask_purple   | 39.433 | 088_uha_matcha               | 9.732  | 089_urban_decay_spray        | 11.432 |
| 090_vitaboost_multivitamin | 4.378  | 091_watercolor_penbox        | 0.073  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 16.383 | 094_kaneyo_kitchen_bleach    | 18.601 | 095_lays_chip_bag_blue       | 16.566 |
| 096_lays_chip_bag_green    | 19.667 | 097_lays_chip_tube_auburn    | 11.322 | 098_lays_chip_tube_green     | 30.578 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/26 23:26:00] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/26 23:26:00] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/26 23:26:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/26 23:26:00] d2.evaluation.testing INFO: copypaste: 14.6965,24.0032,15.6924,7.1033,23.9699,28.5632
[02/26 23:26:04] d2.utils.events INFO:  eta: 0:20:45  iter: 2859  total_loss: 0.2758  loss_cls: 0.1181  loss_box_reg: 0.1579  time: 0.8735  last_time: 0.8893  data_time: 0.0634  last_data_time: 0.0710   lr: 0.01  max_mem: 21305M
[02/26 23:26:21] d2.utils.events INFO:  eta: 0:20:27  iter: 2879  total_loss: 0.2717  loss_cls: 0.1184  loss_box_reg: 0.1529  time: 0.8735  last_time: 0.8732  data_time: 0.0599  last_data_time: 0.0553   lr: 0.01  max_mem: 21305M
[02/26 23:26:39] d2.utils.events INFO:  eta: 0:20:10  iter: 2899  total_loss: 0.279  loss_cls: 0.1234  loss_box_reg: 0.1575  time: 0.8735  last_time: 0.8965  data_time: 0.0586  last_data_time: 0.0785   lr: 0.01  max_mem: 21305M
[02/26 23:26:56] d2.utils.events INFO:  eta: 0:19:52  iter: 2919  total_loss: 0.2693  loss_cls: 0.1175  loss_box_reg: 0.1564  time: 0.8735  last_time: 0.8849  data_time: 0.0586  last_data_time: 0.0680   lr: 0.01  max_mem: 21305M
[02/26 23:27:14] d2.utils.events INFO:  eta: 0:19:35  iter: 2939  total_loss: 0.2714  loss_cls: 0.1168  loss_box_reg: 0.1504  time: 0.8735  last_time: 0.8748  data_time: 0.0595  last_data_time: 0.0549   lr: 0.01  max_mem: 21305M
[02/26 23:27:31] d2.utils.events INFO:  eta: 0:19:17  iter: 2959  total_loss: 0.2675  loss_cls: 0.1128  loss_box_reg: 0.1515  time: 0.8736  last_time: 0.8797  data_time: 0.0585  last_data_time: 0.0570   lr: 0.01  max_mem: 21305M
[02/26 23:27:49] d2.utils.events INFO:  eta: 0:19:00  iter: 2979  total_loss: 0.2651  loss_cls: 0.1152  loss_box_reg: 0.1523  time: 0.8736  last_time: 0.8930  data_time: 0.0630  last_data_time: 0.0751   lr: 0.01  max_mem: 21305M
[02/26 23:28:06] d2.utils.events INFO:  eta: 0:18:43  iter: 2999  total_loss: 0.2672  loss_cls: 0.1148  loss_box_reg: 0.1524  time: 0.8736  last_time: 0.8845  data_time: 0.0607  last_data_time: 0.0673   lr: 0.01  max_mem: 21305M
[02/26 23:28:24] d2.utils.events INFO:  eta: 0:18:25  iter: 3019  total_loss: 0.2552  loss_cls: 0.1067  loss_box_reg: 0.1469  time: 0.8736  last_time: 0.8853  data_time: 0.0602  last_data_time: 0.0681   lr: 0.01  max_mem: 21305M
[02/26 23:28:41] d2.utils.events INFO:  eta: 0:18:08  iter: 3039  total_loss: 0.2723  loss_cls: 0.115  loss_box_reg: 0.1552  time: 0.8736  last_time: 0.8948  data_time: 0.0614  last_data_time: 0.0780   lr: 0.01  max_mem: 21305M
[02/26 23:28:59] d2.utils.events INFO:  eta: 0:17:50  iter: 3059  total_loss: 0.2691  loss_cls: 0.1159  loss_box_reg: 0.1524  time: 0.8736  last_time: 0.8845  data_time: 0.0608  last_data_time: 0.0672   lr: 0.01  max_mem: 21305M
[02/26 23:29:16] d2.utils.events INFO:  eta: 0:17:33  iter: 3079  total_loss: 0.2696  loss_cls: 0.118  loss_box_reg: 0.1538  time: 0.8736  last_time: 0.8831  data_time: 0.0608  last_data_time: 0.0663   lr: 0.01  max_mem: 21305M
[02/26 23:29:34] d2.utils.events INFO:  eta: 0:17:15  iter: 3099  total_loss: 0.2663  loss_cls: 0.1137  loss_box_reg: 0.1497  time: 0.8736  last_time: 0.8988  data_time: 0.0650  last_data_time: 0.0808   lr: 0.01  max_mem: 21305M
[02/26 23:29:51] d2.utils.events INFO:  eta: 0:16:58  iter: 3119  total_loss: 0.263  loss_cls: 0.1124  loss_box_reg: 0.1524  time: 0.8736  last_time: 0.8655  data_time: 0.0591  last_data_time: 0.0487   lr: 0.01  max_mem: 21305M
[02/26 23:30:09] d2.utils.events INFO:  eta: 0:16:41  iter: 3139  total_loss: 0.2641  loss_cls: 0.1131  loss_box_reg: 0.1497  time: 0.8736  last_time: 0.8947  data_time: 0.0611  last_data_time: 0.0781   lr: 0.01  max_mem: 21305M
[02/26 23:30:26] d2.utils.events INFO:  eta: 0:16:23  iter: 3159  total_loss: 0.2615  loss_cls: 0.115  loss_box_reg: 0.147  time: 0.8736  last_time: 0.8917  data_time: 0.0621  last_data_time: 0.0732   lr: 0.01  max_mem: 21305M
[02/26 23:30:44] d2.utils.events INFO:  eta: 0:16:06  iter: 3179  total_loss: 0.2515  loss_cls: 0.1059  loss_box_reg: 0.1452  time: 0.8736  last_time: 0.8843  data_time: 0.0583  last_data_time: 0.0669   lr: 0.01  max_mem: 21305M
[02/26 23:31:01] d2.utils.events INFO:  eta: 0:15:48  iter: 3199  total_loss: 0.2721  loss_cls: 0.1201  loss_box_reg: 0.1547  time: 0.8736  last_time: 0.8749  data_time: 0.0636  last_data_time: 0.0573   lr: 0.01  max_mem: 21305M
[02/26 23:31:19] d2.utils.events INFO:  eta: 0:15:31  iter: 3219  total_loss: 0.2584  loss_cls: 0.1106  loss_box_reg: 0.1472  time: 0.8736  last_time: 0.8853  data_time: 0.0652  last_data_time: 0.0670   lr: 0.01  max_mem: 21305M
[02/26 23:31:36] d2.utils.events INFO:  eta: 0:15:13  iter: 3239  total_loss: 0.2537  loss_cls: 0.1068  loss_box_reg: 0.1467  time: 0.8736  last_time: 0.8863  data_time: 0.0600  last_data_time: 0.0679   lr: 0.01  max_mem: 21305M
[02/26 23:31:54] d2.utils.events INFO:  eta: 0:14:56  iter: 3259  total_loss: 0.2593  loss_cls: 0.1101  loss_box_reg: 0.1474  time: 0.8737  last_time: 0.8854  data_time: 0.0628  last_data_time: 0.0668   lr: 0.01  max_mem: 21305M
[02/26 23:32:12] d2.utils.events INFO:  eta: 0:14:38  iter: 3279  total_loss: 0.246  loss_cls: 0.1008  loss_box_reg: 0.1452  time: 0.8737  last_time: 0.8972  data_time: 0.0610  last_data_time: 0.0797   lr: 0.01  max_mem: 21305M
[02/26 23:32:29] d2.utils.events INFO:  eta: 0:14:21  iter: 3299  total_loss: 0.2554  loss_cls: 0.1108  loss_box_reg: 0.1473  time: 0.8737  last_time: 0.8759  data_time: 0.0608  last_data_time: 0.0588   lr: 0.01  max_mem: 21305M
[02/26 23:32:47] d2.utils.events INFO:  eta: 0:14:03  iter: 3319  total_loss: 0.2616  loss_cls: 0.1095  loss_box_reg: 0.1517  time: 0.8737  last_time: 0.8871  data_time: 0.0644  last_data_time: 0.0691   lr: 0.01  max_mem: 21305M
[02/26 23:33:04] d2.utils.events INFO:  eta: 0:13:46  iter: 3339  total_loss: 0.2625  loss_cls: 0.1129  loss_box_reg: 0.1497  time: 0.8737  last_time: 0.8956  data_time: 0.0623  last_data_time: 0.0773   lr: 0.01  max_mem: 21305M
[02/26 23:33:22] d2.utils.events INFO:  eta: 0:13:28  iter: 3359  total_loss: 0.264  loss_cls: 0.1115  loss_box_reg: 0.148  time: 0.8738  last_time: 0.8894  data_time: 0.0617  last_data_time: 0.0712   lr: 0.01  max_mem: 21305M
[02/26 23:33:39] d2.utils.events INFO:  eta: 0:13:11  iter: 3379  total_loss: 0.2449  loss_cls: 0.1041  loss_box_reg: 0.1423  time: 0.8738  last_time: 0.8263  data_time: 0.0622  last_data_time: 0.0561   lr: 0.01  max_mem: 21305M
[02/26 23:33:56] d2.utils.events INFO:  eta: 0:12:53  iter: 3399  total_loss: 0.2596  loss_cls: 0.113  loss_box_reg: 0.1484  time: 0.8737  last_time: 0.8309  data_time: 0.0598  last_data_time: 0.0595   lr: 0.01  max_mem: 21305M
[02/26 23:34:14] d2.utils.events INFO:  eta: 0:12:36  iter: 3419  total_loss: 0.2544  loss_cls: 0.1082  loss_box_reg: 0.1488  time: 0.8736  last_time: 0.8758  data_time: 0.0570  last_data_time: 0.0582   lr: 0.01  max_mem: 21305M
[02/26 23:34:31] d2.utils.events INFO:  eta: 0:12:18  iter: 3439  total_loss: 0.2462  loss_cls: 0.1077  loss_box_reg: 0.1443  time: 0.8736  last_time: 0.8721  data_time: 0.0584  last_data_time: 0.0542   lr: 0.01  max_mem: 21305M
[02/26 23:34:49] d2.utils.events INFO:  eta: 0:12:01  iter: 3459  total_loss: 0.2637  loss_cls: 0.1098  loss_box_reg: 0.1538  time: 0.8736  last_time: 0.8773  data_time: 0.0576  last_data_time: 0.0594   lr: 0.01  max_mem: 21305M
[02/26 23:35:06] d2.utils.events INFO:  eta: 0:11:43  iter: 3479  total_loss: 0.2597  loss_cls: 0.1081  loss_box_reg: 0.1489  time: 0.8736  last_time: 0.8802  data_time: 0.0579  last_data_time: 0.0613   lr: 0.01  max_mem: 21305M
[02/26 23:35:24] d2.utils.events INFO:  eta: 0:11:26  iter: 3499  total_loss: 0.2471  loss_cls: 0.1034  loss_box_reg: 0.1441  time: 0.8736  last_time: 0.8733  data_time: 0.0576  last_data_time: 0.0546   lr: 0.01  max_mem: 21305M
[02/26 23:35:41] d2.utils.events INFO:  eta: 0:11:08  iter: 3519  total_loss: 0.2437  loss_cls: 0.1027  loss_box_reg: 0.1413  time: 0.8736  last_time: 0.8723  data_time: 0.0561  last_data_time: 0.0544   lr: 0.01  max_mem: 21305M
[02/26 23:35:59] d2.utils.events INFO:  eta: 0:10:51  iter: 3539  total_loss: 0.2508  loss_cls: 0.1035  loss_box_reg: 0.1472  time: 0.8737  last_time: 0.8858  data_time: 0.0628  last_data_time: 0.0677   lr: 0.01  max_mem: 21305M
[02/26 23:36:16] d2.utils.events INFO:  eta: 0:10:33  iter: 3559  total_loss: 0.2578  loss_cls: 0.1069  loss_box_reg: 0.149  time: 0.8736  last_time: 0.8812  data_time: 0.0592  last_data_time: 0.0634   lr: 0.01  max_mem: 21305M
[02/26 23:36:34] d2.utils.events INFO:  eta: 0:10:16  iter: 3579  total_loss: 0.2541  loss_cls: 0.1072  loss_box_reg: 0.1456  time: 0.8737  last_time: 0.8907  data_time: 0.0627  last_data_time: 0.0726   lr: 0.01  max_mem: 21305M
[02/26 23:36:51] d2.utils.events INFO:  eta: 0:09:58  iter: 3599  total_loss: 0.2553  loss_cls: 0.1032  loss_box_reg: 0.1484  time: 0.8737  last_time: 0.8967  data_time: 0.0621  last_data_time: 0.0788   lr: 0.01  max_mem: 21305M
[02/26 23:37:09] d2.utils.events INFO:  eta: 0:09:41  iter: 3619  total_loss: 0.255  loss_cls: 0.11  loss_box_reg: 0.147  time: 0.8737  last_time: 0.8697  data_time: 0.0604  last_data_time: 0.0524   lr: 0.01  max_mem: 21305M
[02/26 23:37:26] d2.utils.events INFO:  eta: 0:09:23  iter: 3639  total_loss: 0.2479  loss_cls: 0.103  loss_box_reg: 0.1448  time: 0.8737  last_time: 0.8658  data_time: 0.0615  last_data_time: 0.0474   lr: 0.01  max_mem: 21305M
[02/26 23:37:44] d2.utils.events INFO:  eta: 0:09:06  iter: 3659  total_loss: 0.2396  loss_cls: 0.1006  loss_box_reg: 0.1415  time: 0.8737  last_time: 0.8952  data_time: 0.0637  last_data_time: 0.0786   lr: 0.01  max_mem: 21305M
[02/26 23:38:01] d2.utils.events INFO:  eta: 0:08:48  iter: 3679  total_loss: 0.2581  loss_cls: 0.1098  loss_box_reg: 0.15  time: 0.8738  last_time: 0.8814  data_time: 0.0620  last_data_time: 0.0636   lr: 0.01  max_mem: 21305M
[02/26 23:38:19] d2.utils.events INFO:  eta: 0:08:31  iter: 3699  total_loss: 0.2463  loss_cls: 0.1051  loss_box_reg: 0.145  time: 0.8738  last_time: 0.8942  data_time: 0.0646  last_data_time: 0.0768   lr: 0.01  max_mem: 21305M
[02/26 23:38:37] d2.utils.events INFO:  eta: 0:08:13  iter: 3719  total_loss: 0.2483  loss_cls: 0.1017  loss_box_reg: 0.1459  time: 0.8738  last_time: 0.8795  data_time: 0.0610  last_data_time: 0.0616   lr: 0.01  max_mem: 21305M
[02/26 23:38:54] d2.utils.events INFO:  eta: 0:07:56  iter: 3739  total_loss: 0.2411  loss_cls: 0.09838  loss_box_reg: 0.1451  time: 0.8738  last_time: 0.8841  data_time: 0.0624  last_data_time: 0.0663   lr: 0.01  max_mem: 21305M
[02/26 23:39:11] d2.utils.events INFO:  eta: 0:07:38  iter: 3759  total_loss: 0.2488  loss_cls: 0.1026  loss_box_reg: 0.1448  time: 0.8738  last_time: 0.8852  data_time: 0.0605  last_data_time: 0.0677   lr: 0.01  max_mem: 21305M
[02/26 23:39:29] d2.utils.events INFO:  eta: 0:07:20  iter: 3779  total_loss: 0.2469  loss_cls: 0.1043  loss_box_reg: 0.146  time: 0.8738  last_time: 0.8854  data_time: 0.0600  last_data_time: 0.0675   lr: 0.01  max_mem: 21305M
[02/26 23:39:47] d2.utils.events INFO:  eta: 0:07:03  iter: 3799  total_loss: 0.2402  loss_cls: 0.09874  loss_box_reg: 0.1393  time: 0.8738  last_time: 0.8955  data_time: 0.0606  last_data_time: 0.0776   lr: 0.01  max_mem: 21305M
[02/26 23:40:04] d2.utils.events INFO:  eta: 0:06:45  iter: 3819  total_loss: 0.2465  loss_cls: 0.1064  loss_box_reg: 0.142  time: 0.8738  last_time: 0.8191  data_time: 0.0615  last_data_time: 0.0488   lr: 0.01  max_mem: 21305M
[02/26 23:40:22] d2.utils.events INFO:  eta: 0:06:28  iter: 3839  total_loss: 0.2474  loss_cls: 0.1029  loss_box_reg: 0.1455  time: 0.8739  last_time: 0.8726  data_time: 0.0628  last_data_time: 0.0544   lr: 0.01  max_mem: 21305M
[02/26 23:40:39] d2.utils.events INFO:  eta: 0:06:10  iter: 3859  total_loss: 0.2436  loss_cls: 0.1021  loss_box_reg: 0.1455  time: 0.8739  last_time: 0.8742  data_time: 0.0596  last_data_time: 0.0566   lr: 0.01  max_mem: 21305M
[02/26 23:40:57] d2.utils.events INFO:  eta: 0:05:53  iter: 3879  total_loss: 0.2434  loss_cls: 0.09856  loss_box_reg: 0.1445  time: 0.8738  last_time: 0.8731  data_time: 0.0593  last_data_time: 0.0549   lr: 0.01  max_mem: 21305M
[02/26 23:41:14] d2.utils.events INFO:  eta: 0:05:35  iter: 3899  total_loss: 0.2497  loss_cls: 0.1055  loss_box_reg: 0.1454  time: 0.8739  last_time: 0.8913  data_time: 0.0633  last_data_time: 0.0740   lr: 0.01  max_mem: 21305M
[02/26 23:41:31] d2.utils.events INFO:  eta: 0:05:18  iter: 3919  total_loss: 0.2317  loss_cls: 0.09475  loss_box_reg: 0.1387  time: 0.8738  last_time: 0.8709  data_time: 0.0585  last_data_time: 0.0534   lr: 0.01  max_mem: 21305M
[02/26 23:41:49] d2.utils.events INFO:  eta: 0:05:00  iter: 3939  total_loss: 0.2479  loss_cls: 0.1017  loss_box_reg: 0.1473  time: 0.8739  last_time: 0.8664  data_time: 0.0630  last_data_time: 0.0486   lr: 0.01  max_mem: 21305M
[02/26 23:42:07] d2.utils.events INFO:  eta: 0:04:43  iter: 3959  total_loss: 0.2453  loss_cls: 0.09904  loss_box_reg: 0.1445  time: 0.8739  last_time: 0.8876  data_time: 0.0617  last_data_time: 0.0696   lr: 0.01  max_mem: 21305M
[02/26 23:42:24] d2.utils.events INFO:  eta: 0:04:25  iter: 3979  total_loss: 0.2391  loss_cls: 0.09769  loss_box_reg: 0.1407  time: 0.8739  last_time: 0.8720  data_time: 0.0584  last_data_time: 0.0545   lr: 0.01  max_mem: 21305M
[02/26 23:42:41] d2.utils.events INFO:  eta: 0:04:08  iter: 3999  total_loss: 0.2343  loss_cls: 0.0937  loss_box_reg: 0.1395  time: 0.8739  last_time: 0.8736  data_time: 0.0580  last_data_time: 0.0551   lr: 0.01  max_mem: 21305M
[02/26 23:42:59] d2.utils.events INFO:  eta: 0:03:50  iter: 4019  total_loss: 0.2454  loss_cls: 0.1013  loss_box_reg: 0.1404  time: 0.8738  last_time: 0.8820  data_time: 0.0612  last_data_time: 0.0639   lr: 0.01  max_mem: 21305M
[02/26 23:43:17] d2.utils.events INFO:  eta: 0:03:33  iter: 4039  total_loss: 0.2396  loss_cls: 0.09772  loss_box_reg: 0.1412  time: 0.8739  last_time: 0.8742  data_time: 0.0632  last_data_time: 0.0555   lr: 0.01  max_mem: 21305M
[02/26 23:43:34] d2.utils.events INFO:  eta: 0:03:15  iter: 4059  total_loss: 0.2399  loss_cls: 0.09877  loss_box_reg: 0.141  time: 0.8739  last_time: 0.8673  data_time: 0.0594  last_data_time: 0.0484   lr: 0.01  max_mem: 21305M
[02/26 23:43:51] d2.utils.events INFO:  eta: 0:02:57  iter: 4079  total_loss: 0.2355  loss_cls: 0.09794  loss_box_reg: 0.1372  time: 0.8739  last_time: 0.8770  data_time: 0.0592  last_data_time: 0.0589   lr: 0.01  max_mem: 21305M
[02/26 23:44:09] d2.utils.events INFO:  eta: 0:02:40  iter: 4099  total_loss: 0.2354  loss_cls: 0.09762  loss_box_reg: 0.1398  time: 0.8739  last_time: 0.8665  data_time: 0.0615  last_data_time: 0.0494   lr: 0.01  max_mem: 21305M
[02/26 23:44:26] d2.utils.events INFO:  eta: 0:02:22  iter: 4119  total_loss: 0.2398  loss_cls: 0.09763  loss_box_reg: 0.1382  time: 0.8739  last_time: 0.8737  data_time: 0.0591  last_data_time: 0.0555   lr: 0.01  max_mem: 21305M
[02/26 23:44:44] d2.utils.events INFO:  eta: 0:02:05  iter: 4139  total_loss: 0.2361  loss_cls: 0.09622  loss_box_reg: 0.1381  time: 0.8739  last_time: 0.8672  data_time: 0.0591  last_data_time: 0.0496   lr: 0.01  max_mem: 21305M
[02/26 23:45:01] d2.utils.events INFO:  eta: 0:01:47  iter: 4159  total_loss: 0.2394  loss_cls: 0.09995  loss_box_reg: 0.142  time: 0.8739  last_time: 0.8839  data_time: 0.0610  last_data_time: 0.0661   lr: 0.01  max_mem: 21305M
[02/26 23:45:19] d2.utils.events INFO:  eta: 0:01:30  iter: 4179  total_loss: 0.2252  loss_cls: 0.09086  loss_box_reg: 0.131  time: 0.8739  last_time: 0.8911  data_time: 0.0598  last_data_time: 0.0735   lr: 0.01  max_mem: 21305M
[02/26 23:45:36] d2.utils.events INFO:  eta: 0:01:12  iter: 4199  total_loss: 0.2394  loss_cls: 0.0998  loss_box_reg: 0.1429  time: 0.8739  last_time: 0.8727  data_time: 0.0618  last_data_time: 0.0557   lr: 0.01  max_mem: 21305M
[02/26 23:45:54] d2.utils.events INFO:  eta: 0:00:55  iter: 4219  total_loss: 0.2394  loss_cls: 0.097  loss_box_reg: 0.1443  time: 0.8739  last_time: 0.8720  data_time: 0.0590  last_data_time: 0.0557   lr: 0.01  max_mem: 21305M
[02/26 23:46:11] d2.utils.events INFO:  eta: 0:00:37  iter: 4239  total_loss: 0.2348  loss_cls: 0.0946  loss_box_reg: 0.1395  time: 0.8739  last_time: 0.8680  data_time: 0.0583  last_data_time: 0.0508   lr: 0.01  max_mem: 21305M
[02/26 23:46:29] d2.utils.events INFO:  eta: 0:00:20  iter: 4259  total_loss: 0.2279  loss_cls: 0.09263  loss_box_reg: 0.1377  time: 0.8739  last_time: 0.8827  data_time: 0.0613  last_data_time: 0.0645   lr: 0.01  max_mem: 21305M
[02/26 23:46:47] d2.utils.events INFO:  eta: 0:00:02  iter: 4279  total_loss: 0.2345  loss_cls: 0.09497  loss_box_reg: 0.1391  time: 0.8739  last_time: 0.8853  data_time: 0.0627  last_data_time: 0.0673   lr: 0.01  max_mem: 21305M
[02/26 23:46:47] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0004280.pth
[02/26 23:46:50] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_final.pth
[02/26 23:46:50] d2.utils.events INFO:  eta: 0:00:00  iter: 4282  total_loss: 0.2356  loss_cls: 0.0954  loss_box_reg: 0.1395  time: 0.8739  last_time: 0.8800  data_time: 0.0616  last_data_time: 0.0622   lr: 0.01  max_mem: 21305M
[02/26 23:46:50] d2.engine.hooks INFO: Overall training speed: 4281 iterations in 1:02:21 (0.8739 s / it)
[02/26 23:46:50] d2.engine.hooks INFO: Total training time: 1:02:34 (0:00:13 on hooks)
[02/26 23:46:50] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/26 23:46:50] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/26 23:46:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/26 23:46:50] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/26 23:46:50] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/26 23:46:50] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/26 23:46:50] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/26 23:46:50] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0005 s/iter. Inference: 0.0291 s/iter. Eval: 0.0002 s/iter. Total: 0.0298 s/iter. ETA=0:00:04
[02/26 23:46:55] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.676430 (0.030171 s / iter per device, on 1 devices)
[02/26 23:46:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.029040 s / iter per device, on 1 devices)
[02/26 23:46:55] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/26 23:46:55] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/26 23:46:55] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/26 23:46:55] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/26 23:46:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.23 seconds.
[02/26 23:46:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/26 23:46:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.11 seconds.
[02/26 23:46:55] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 13.280 | 22.072 | 14.080 | 6.445 | 22.173 | 20.190 |
[02/26 23:46:55] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 16.825 | 001_binder_clips_median      | 29.462 | 002_binder_clips_small       | 20.302 |
| 003_bombik_bucket          | 13.035 | 004_bonne_maman_blueberry    | 0.191  | 005_bonne_maman_raspberry    | 0.390  |
| 006_bonne_maman_strawberry | 0.010  | 007_costa_caramel            | 20.611 | 008_essential_oil_bergamot   | 22.272 |
| 009_garlic_toast_spread    | 4.682  | 010_handcream_avocado        | 0.538  | 011_hb_calcium               | 13.676 |
| 012_hb_grapeseed           | 10.962 | 013_hb_marine_collagen       | 8.092  | 014_hellmanns_mayonnaise     | 5.343  |
| 015_illy_blend             | 1.708  | 016_japanese_finger_cookies  | 7.282  | 017_john_west_canned_tuna    | 7.036  |
| 018_kerastase_shampoo      | 2.142  | 019_kiehls_facial_cream      | 25.039 | 020_kiihne_balsamic          | 0.050  |
| 021_kiihne_honey_mustard   | 13.672 | 022_lindor_matcha            | 25.022 | 023_lindor_salted_caramel    | 31.429 |
| 024_lush_mask              | 64.604 | 025_pasta_sauce_black_pepper | 0.063  | 026_pasta_sauce_tomato       | 7.099  |
| 027_pepsi                  | 41.883 | 028_portable_yogurt_machine  | 0.057  | 029_selfile_stick            | 0.903  |
| 030_sour_lemon_drops       | 4.334  | 031_sticky_notes             | 14.790 | 032_stridex_green            | 42.666 |
| 033_thermos_flask_cream    | 40.477 | 034_thermos_flask_muji       | 0.000  | 035_thermos_flask_sliver     | 0.064  |
| 036_tragata_olive_oil      | 4.919  | 037_tulip_luncheon_meat      | 9.408  | 038_unicharm_cotton_pad      | 39.481 |
| 039_vinda_tissue           | 26.447 | 040_wrigley_doublemint_gum   | 0.199  | 041_baseball_cap_black       | 8.058  |
| 042_baseball_cap_pink      | 7.820  | 043_bfe_facial_mask          | 26.013 | 044_corgi_doll               | 4.624  |
| 045_dinosaur_doll          | 23.665 | 046_geo_mocha                | 2.960  | 047_geo_roast_charcoal       | 1.787  |
| 048_instant_noodle_black   | 5.646  | 049_instant_noodle_red       | 11.665 | 050_nabati_cheese_wafer      | 35.972 |
| 051_truffettes             | 5.892  | 052_acnes_cream              | 19.125 | 053_aveda_conditioner        | 16.498 |
| 054_banana_milk_drink      | 6.870  | 055_candle_beast             | 28.424 | 056_china_persimmon          | 15.538 |
| 057_danisa_butter_cookies  | 2.532  | 058_effaclar_duo             | 7.426  | 059_evelom_cleanser          | 14.753 |
| 060_glasses_box_blone      | 21.825 | 061_handcream_iris           | 0.025  | 062_handcream_lavender       | 0.000  |
| 063_handcream_rosewater    | 1.027  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 5.320  |
| 066_japanese_chocolate     | 31.953 | 067_kerastase_hair_treatment | 14.421 | 068_kiehls_serum             | 17.817 |
| 069_korean_beef_marinade   | 19.016 | 070_korean_doenjang          | 13.454 | 071_korean_gochujang         | 0.000  |
| 072_korean_ssamjang        | 9.820  | 073_loccitane_soap           | 19.472 | 074_marvis_toothpaste_purple | 44.259 |
| 075_mouse_thinkpad         | 3.235  | 076_oatly_chocolate          | 5.674  | 077_oatly_original           | 21.262 |
| 078_ousa_grated_cheese     | 4.094  | 079_polaroid_film            | 0.106  | 080_skinceuticals_be         | 50.235 |
| 081_skinceuticals_cf       | 22.814 | 082_skinceuticals_phyto      | 16.514 | 083_stapler_black            | 9.360  |
| 084_stapler_blue           | 13.490 | 085_sunscreen_blue           | 0.238  | 086_tempo_pocket_tissue      | 1.762  |
| 087_thermos_flask_purple   | 30.171 | 088_uha_matcha               | 12.287 | 089_urban_decay_spray        | 9.754  |
| 090_vitaboost_multivitamin | 5.506  | 091_watercolor_penbox        | 0.040  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 18.080 | 094_kaneyo_kitchen_bleach    | 14.926 | 095_lays_chip_bag_blue       | 12.442 |
| 096_lays_chip_bag_green    | 15.884 | 097_lays_chip_tube_auburn    | 11.212 | 098_lays_chip_tube_green     | 28.101 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/26 23:46:55] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/26 23:46:55] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/26 23:46:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/26 23:46:55] d2.evaluation.testing INFO: copypaste: 13.2803,22.0716,14.0804,6.4454,22.1732,20.1898
[02/27 00:35:37] detectron2 INFO: Rank of current process: 0. World size: 1
[02/27 00:35:37] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/27 00:35:37] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/27 00:35:37] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/27 00:35:37] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/27 00:35:37] detectron2 INFO: Full config saved to ./output/config.yaml
[02/27 00:35:37] d2.utils.env INFO: Using a generated random seed 38116830
[02/27 00:35:38] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/27 00:35:40] d2.data.datasets.coco INFO: Loading /media/nahyun/HDD//data_100/instances_train.json takes 2.24 seconds.
[02/27 00:35:40] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/27 00:35:41] d2.data.datasets.coco INFO: Loaded 19191 images in COCO format from /media/nahyun/HDD//data_100/instances_train.json
[02/27 00:35:42] d2.data.build INFO: Removed 0 images with no usable annotations. 19191 images left.
[02/27 00:35:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/27 00:35:42] d2.data.build INFO: Using training sampler TrainingSampler
[02/27 00:35:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/27 00:35:42] d2.data.common INFO: Serializing 19191 elements to byte tensors and concatenating them all ...
[02/27 00:35:42] d2.data.common INFO: Serialized dataset takes 80.55 MiB
[02/27 00:35:43] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/27 00:35:43] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[02/27 00:35:43] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/nahyun/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[02/27 00:35:43] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/27 00:35:43] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[02/27 00:35:43] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[02/27 00:35:43] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[02/27 00:35:43] d2.engine.train_loop INFO: Starting training from iteration 0
[02/27 00:36:02] d2.utils.events INFO:  eta: 1:01:19  iter: 19  total_loss: 2.727  loss_cls: 1.7  loss_box_reg: 1.028  time: 0.9022  last_time: 0.8774  data_time: 0.0661  last_data_time: 0.0689   lr: 0.00019981  max_mem: 21306M
[02/27 00:36:19] d2.utils.events INFO:  eta: 1:01:19  iter: 39  total_loss: 1.901  loss_cls: 1.195  loss_box_reg: 0.7098  time: 0.8876  last_time: 0.8709  data_time: 0.0589  last_data_time: 0.0595   lr: 0.00039961  max_mem: 21306M
[02/27 00:36:37] d2.utils.events INFO:  eta: 1:01:01  iter: 59  total_loss: 1.807  loss_cls: 1.144  loss_box_reg: 0.6654  time: 0.8793  last_time: 0.8685  data_time: 0.0572  last_data_time: 0.0586   lr: 0.00059941  max_mem: 21306M
[02/27 00:36:54] d2.utils.events INFO:  eta: 1:00:49  iter: 79  total_loss: 1.778  loss_cls: 1.136  loss_box_reg: 0.6409  time: 0.8770  last_time: 0.8841  data_time: 0.0585  last_data_time: 0.0695   lr: 0.00079921  max_mem: 21306M
[02/27 00:37:11] d2.utils.events INFO:  eta: 1:00:32  iter: 99  total_loss: 1.796  loss_cls: 1.161  loss_box_reg: 0.6396  time: 0.8756  last_time: 0.8810  data_time: 0.0578  last_data_time: 0.0666   lr: 0.00099901  max_mem: 21306M
[02/27 00:37:29] d2.utils.events INFO:  eta: 1:00:22  iter: 119  total_loss: 1.758  loss_cls: 1.143  loss_box_reg: 0.6141  time: 0.8753  last_time: 0.8724  data_time: 0.0592  last_data_time: 0.0583   lr: 0.0011988  max_mem: 21306M
[02/27 00:37:46] d2.utils.events INFO:  eta: 1:00:07  iter: 139  total_loss: 1.755  loss_cls: 1.149  loss_box_reg: 0.604  time: 0.8756  last_time: 0.8691  data_time: 0.0619  last_data_time: 0.0551   lr: 0.0013986  max_mem: 21306M
[02/27 00:38:04] d2.utils.events INFO:  eta: 0:59:51  iter: 159  total_loss: 1.727  loss_cls: 1.145  loss_box_reg: 0.5884  time: 0.8756  last_time: 0.8763  data_time: 0.0628  last_data_time: 0.0588   lr: 0.0015984  max_mem: 21306M
[02/27 00:38:22] d2.utils.events INFO:  eta: 0:59:37  iter: 179  total_loss: 1.745  loss_cls: 1.161  loss_box_reg: 0.5821  time: 0.8756  last_time: 0.8701  data_time: 0.0612  last_data_time: 0.0522   lr: 0.0017982  max_mem: 21306M
[02/27 00:38:39] d2.utils.events INFO:  eta: 0:59:22  iter: 199  total_loss: 1.681  loss_cls: 1.146  loss_box_reg: 0.5375  time: 0.8759  last_time: 0.8849  data_time: 0.0625  last_data_time: 0.0669   lr: 0.001998  max_mem: 21306M
[02/27 00:38:57] d2.utils.events INFO:  eta: 0:59:11  iter: 219  total_loss: 1.625  loss_cls: 1.124  loss_box_reg: 0.4932  time: 0.8760  last_time: 0.8877  data_time: 0.0636  last_data_time: 0.0701   lr: 0.0021978  max_mem: 21306M
[02/27 00:39:14] d2.utils.events INFO:  eta: 0:58:55  iter: 239  total_loss: 1.554  loss_cls: 1.093  loss_box_reg: 0.4611  time: 0.8759  last_time: 0.8694  data_time: 0.0609  last_data_time: 0.0505   lr: 0.0023976  max_mem: 21306M
[02/27 00:39:32] d2.utils.events INFO:  eta: 0:58:40  iter: 259  total_loss: 1.414  loss_cls: 0.9806  loss_box_reg: 0.4328  time: 0.8761  last_time: 0.8800  data_time: 0.0605  last_data_time: 0.0629   lr: 0.0025974  max_mem: 21306M
[02/27 00:39:49] d2.utils.events INFO:  eta: 0:58:25  iter: 279  total_loss: 1.249  loss_cls: 0.8549  loss_box_reg: 0.3979  time: 0.8762  last_time: 0.8832  data_time: 0.0604  last_data_time: 0.0647   lr: 0.0027972  max_mem: 21306M
[02/27 00:40:07] d2.utils.events INFO:  eta: 0:58:09  iter: 299  total_loss: 1.153  loss_cls: 0.7826  loss_box_reg: 0.375  time: 0.8761  last_time: 0.8834  data_time: 0.0612  last_data_time: 0.0652   lr: 0.002997  max_mem: 21306M
[02/27 00:40:24] d2.utils.events INFO:  eta: 0:57:53  iter: 319  total_loss: 1.092  loss_cls: 0.7417  loss_box_reg: 0.3509  time: 0.8762  last_time: 0.8746  data_time: 0.0619  last_data_time: 0.0564   lr: 0.0031968  max_mem: 21306M
[02/27 00:40:42] d2.utils.events INFO:  eta: 0:57:35  iter: 339  total_loss: 1.062  loss_cls: 0.7288  loss_box_reg: 0.3359  time: 0.8762  last_time: 0.8789  data_time: 0.0590  last_data_time: 0.0599   lr: 0.0033966  max_mem: 21306M
[02/27 00:40:59] d2.utils.events INFO:  eta: 0:57:19  iter: 359  total_loss: 1.038  loss_cls: 0.7091  loss_box_reg: 0.3262  time: 0.8762  last_time: 0.8756  data_time: 0.0632  last_data_time: 0.0559   lr: 0.0035964  max_mem: 21306M
[02/27 00:41:17] d2.utils.events INFO:  eta: 0:57:02  iter: 379  total_loss: 1.025  loss_cls: 0.7096  loss_box_reg: 0.3145  time: 0.8764  last_time: 0.8804  data_time: 0.0601  last_data_time: 0.0619   lr: 0.0037962  max_mem: 21306M
[02/27 00:41:34] d2.utils.events INFO:  eta: 0:56:45  iter: 399  total_loss: 1.004  loss_cls: 0.6981  loss_box_reg: 0.309  time: 0.8762  last_time: 0.8876  data_time: 0.0595  last_data_time: 0.0679   lr: 0.003996  max_mem: 21306M
[02/27 00:41:52] d2.utils.events INFO:  eta: 0:56:27  iter: 419  total_loss: 0.9788  loss_cls: 0.6838  loss_box_reg: 0.299  time: 0.8760  last_time: 0.8742  data_time: 0.0587  last_data_time: 0.0557   lr: 0.0041958  max_mem: 21306M
[02/27 00:42:10] d2.utils.events INFO:  eta: 0:56:10  iter: 439  total_loss: 0.9882  loss_cls: 0.6911  loss_box_reg: 0.2954  time: 0.8764  last_time: 0.8825  data_time: 0.0642  last_data_time: 0.0646   lr: 0.0043956  max_mem: 21306M
[02/27 00:42:27] d2.utils.events INFO:  eta: 0:55:53  iter: 459  total_loss: 0.9554  loss_cls: 0.6717  loss_box_reg: 0.2881  time: 0.8761  last_time: 0.8696  data_time: 0.0598  last_data_time: 0.0499   lr: 0.0045954  max_mem: 21306M
[02/27 00:42:45] d2.utils.events INFO:  eta: 0:55:35  iter: 479  total_loss: 0.9215  loss_cls: 0.6486  loss_box_reg: 0.2769  time: 0.8761  last_time: 0.8708  data_time: 0.0614  last_data_time: 0.0521   lr: 0.0047952  max_mem: 21306M
[02/27 00:43:02] d2.utils.events INFO:  eta: 0:55:18  iter: 499  total_loss: 0.9374  loss_cls: 0.6549  loss_box_reg: 0.2765  time: 0.8762  last_time: 0.8804  data_time: 0.0616  last_data_time: 0.0612   lr: 0.004995  max_mem: 21306M
[02/27 00:43:20] d2.utils.events INFO:  eta: 0:55:00  iter: 519  total_loss: 0.9237  loss_cls: 0.6493  loss_box_reg: 0.2754  time: 0.8762  last_time: 0.8871  data_time: 0.0614  last_data_time: 0.0681   lr: 0.0051948  max_mem: 21306M
[02/27 00:43:37] d2.utils.events INFO:  eta: 0:54:43  iter: 539  total_loss: 0.9002  loss_cls: 0.6328  loss_box_reg: 0.2678  time: 0.8760  last_time: 0.8684  data_time: 0.0601  last_data_time: 0.0498   lr: 0.0053946  max_mem: 21306M
[02/27 00:43:55] d2.utils.events INFO:  eta: 0:54:26  iter: 559  total_loss: 0.8805  loss_cls: 0.618  loss_box_reg: 0.2644  time: 0.8760  last_time: 0.8362  data_time: 0.0619  last_data_time: 0.0657   lr: 0.0055944  max_mem: 21306M
[02/27 00:44:12] d2.utils.events INFO:  eta: 0:54:08  iter: 579  total_loss: 0.8567  loss_cls: 0.6045  loss_box_reg: 0.2553  time: 0.8758  last_time: 0.8735  data_time: 0.0565  last_data_time: 0.0553   lr: 0.0057942  max_mem: 21306M
[02/27 00:44:29] d2.utils.events INFO:  eta: 0:53:50  iter: 599  total_loss: 0.8736  loss_cls: 0.6124  loss_box_reg: 0.2631  time: 0.8757  last_time: 0.8323  data_time: 0.0599  last_data_time: 0.0602   lr: 0.005994  max_mem: 21306M
[02/27 00:44:47] d2.utils.events INFO:  eta: 0:53:32  iter: 619  total_loss: 1.045  loss_cls: 0.7657  loss_box_reg: 0.2816  time: 0.8757  last_time: 0.8766  data_time: 0.0585  last_data_time: 0.0573   lr: 0.0061938  max_mem: 21306M
[02/27 00:45:04] d2.utils.events INFO:  eta: 0:53:15  iter: 639  total_loss: 0.9857  loss_cls: 0.7074  loss_box_reg: 0.282  time: 0.8756  last_time: 0.8681  data_time: 0.0570  last_data_time: 0.0501   lr: 0.0063936  max_mem: 21306M
[02/27 00:45:22] d2.utils.events INFO:  eta: 0:52:57  iter: 659  total_loss: 0.8655  loss_cls: 0.6162  loss_box_reg: 0.2538  time: 0.8755  last_time: 0.8285  data_time: 0.0580  last_data_time: 0.0582   lr: 0.0065934  max_mem: 21306M
[02/27 00:45:39] d2.utils.events INFO:  eta: 0:52:40  iter: 679  total_loss: 0.8452  loss_cls: 0.5994  loss_box_reg: 0.2446  time: 0.8753  last_time: 0.8759  data_time: 0.0583  last_data_time: 0.0565   lr: 0.0067932  max_mem: 21306M
[02/27 00:45:57] d2.utils.events INFO:  eta: 0:52:22  iter: 699  total_loss: 0.8263  loss_cls: 0.5848  loss_box_reg: 0.2437  time: 0.8753  last_time: 0.8787  data_time: 0.0597  last_data_time: 0.0598   lr: 0.006993  max_mem: 21306M
[02/27 00:46:14] d2.utils.events INFO:  eta: 0:52:04  iter: 719  total_loss: 0.7999  loss_cls: 0.5675  loss_box_reg: 0.2326  time: 0.8754  last_time: 0.8747  data_time: 0.0610  last_data_time: 0.0551   lr: 0.0071928  max_mem: 21306M
[02/27 00:46:32] d2.utils.events INFO:  eta: 0:51:47  iter: 739  total_loss: 0.8027  loss_cls: 0.5693  loss_box_reg: 0.2365  time: 0.8756  last_time: 0.8768  data_time: 0.0641  last_data_time: 0.0579   lr: 0.0073926  max_mem: 21306M
[02/27 00:46:50] d2.utils.events INFO:  eta: 0:51:30  iter: 759  total_loss: 0.8053  loss_cls: 0.5662  loss_box_reg: 0.2374  time: 0.8757  last_time: 0.8778  data_time: 0.0613  last_data_time: 0.0588   lr: 0.0075924  max_mem: 21306M
[02/27 00:47:07] d2.utils.events INFO:  eta: 0:51:12  iter: 779  total_loss: 1.267  loss_cls: 0.9964  loss_box_reg: 0.2715  time: 0.8755  last_time: 0.8838  data_time: 0.0614  last_data_time: 0.0653   lr: 0.0077922  max_mem: 21306M
[02/27 00:47:25] d2.utils.events INFO:  eta: 0:50:55  iter: 799  total_loss: 1.009  loss_cls: 0.7488  loss_box_reg: 0.2614  time: 0.8755  last_time: 0.8826  data_time: 0.0604  last_data_time: 0.0642   lr: 0.007992  max_mem: 21306M
[02/27 00:47:42] d2.utils.events INFO:  eta: 0:50:37  iter: 819  total_loss: 0.8115  loss_cls: 0.5896  loss_box_reg: 0.2313  time: 0.8756  last_time: 0.8746  data_time: 0.0622  last_data_time: 0.0556   lr: 0.0081918  max_mem: 21306M
[02/27 00:48:00] d2.utils.events INFO:  eta: 0:50:20  iter: 839  total_loss: 0.7886  loss_cls: 0.5532  loss_box_reg: 0.2329  time: 0.8755  last_time: 0.8821  data_time: 0.0594  last_data_time: 0.0642   lr: 0.0083916  max_mem: 21306M
[02/27 00:48:17] d2.utils.events INFO:  eta: 0:50:02  iter: 859  total_loss: 0.7511  loss_cls: 0.5208  loss_box_reg: 0.228  time: 0.8755  last_time: 0.8765  data_time: 0.0607  last_data_time: 0.0561   lr: 0.0085914  max_mem: 21306M
[02/27 00:48:35] d2.utils.events INFO:  eta: 0:49:44  iter: 879  total_loss: 0.7164  loss_cls: 0.4929  loss_box_reg: 0.2232  time: 0.8755  last_time: 0.8683  data_time: 0.0595  last_data_time: 0.0490   lr: 0.0087912  max_mem: 21306M
[02/27 00:48:52] d2.utils.events INFO:  eta: 0:49:27  iter: 899  total_loss: 0.7654  loss_cls: 0.5251  loss_box_reg: 0.2362  time: 0.8753  last_time: 0.7834  data_time: 0.0589  last_data_time: 0.0584   lr: 0.008991  max_mem: 21306M
[02/27 00:49:09] d2.utils.events INFO:  eta: 0:49:09  iter: 919  total_loss: 0.6987  loss_cls: 0.4741  loss_box_reg: 0.2281  time: 0.8752  last_time: 0.8821  data_time: 0.0621  last_data_time: 0.0648   lr: 0.0091908  max_mem: 21306M
[02/27 00:49:27] d2.utils.events INFO:  eta: 0:48:52  iter: 939  total_loss: 0.6514  loss_cls: 0.4349  loss_box_reg: 0.2203  time: 0.8752  last_time: 0.8898  data_time: 0.0614  last_data_time: 0.0714   lr: 0.0093906  max_mem: 21306M
[02/27 00:49:44] d2.utils.events INFO:  eta: 0:48:34  iter: 959  total_loss: 0.6455  loss_cls: 0.4266  loss_box_reg: 0.2196  time: 0.8752  last_time: 0.8758  data_time: 0.0626  last_data_time: 0.0569   lr: 0.0095904  max_mem: 21306M
[02/27 00:50:02] d2.utils.events INFO:  eta: 0:48:17  iter: 979  total_loss: 0.6202  loss_cls: 0.4024  loss_box_reg: 0.2135  time: 0.8751  last_time: 0.8753  data_time: 0.0607  last_data_time: 0.0570   lr: 0.0097902  max_mem: 21306M
[02/27 00:50:19] d2.utils.events INFO:  eta: 0:47:59  iter: 999  total_loss: 0.6042  loss_cls: 0.3937  loss_box_reg: 0.21  time: 0.8752  last_time: 0.8830  data_time: 0.0611  last_data_time: 0.0637   lr: 0.00999  max_mem: 21306M
[02/27 00:50:37] d2.utils.events INFO:  eta: 0:47:42  iter: 1019  total_loss: 0.574  loss_cls: 0.3692  loss_box_reg: 0.2082  time: 0.8753  last_time: 0.8899  data_time: 0.0619  last_data_time: 0.0700   lr: 0.01  max_mem: 21306M
[02/27 00:50:55] d2.utils.events INFO:  eta: 0:47:25  iter: 1039  total_loss: 0.5821  loss_cls: 0.3604  loss_box_reg: 0.2215  time: 0.8753  last_time: 0.8823  data_time: 0.0572  last_data_time: 0.0626   lr: 0.01  max_mem: 21306M
[02/27 00:51:12] d2.utils.events INFO:  eta: 0:47:08  iter: 1059  total_loss: 0.5469  loss_cls: 0.3344  loss_box_reg: 0.211  time: 0.8752  last_time: 0.8868  data_time: 0.0596  last_data_time: 0.0688   lr: 0.01  max_mem: 21306M
[02/27 00:51:29] d2.utils.events INFO:  eta: 0:46:51  iter: 1079  total_loss: 0.5349  loss_cls: 0.3226  loss_box_reg: 0.2133  time: 0.8751  last_time: 0.8202  data_time: 0.0598  last_data_time: 0.0491   lr: 0.01  max_mem: 21306M
[02/27 00:51:47] d2.utils.events INFO:  eta: 0:46:33  iter: 1099  total_loss: 0.5226  loss_cls: 0.3109  loss_box_reg: 0.2078  time: 0.8751  last_time: 0.8855  data_time: 0.0612  last_data_time: 0.0685   lr: 0.01  max_mem: 21306M
[02/27 00:52:04] d2.utils.events INFO:  eta: 0:46:16  iter: 1119  total_loss: 0.4953  loss_cls: 0.2909  loss_box_reg: 0.2052  time: 0.8750  last_time: 0.8717  data_time: 0.0614  last_data_time: 0.0530   lr: 0.01  max_mem: 21306M
[02/27 00:52:22] d2.utils.events INFO:  eta: 0:45:59  iter: 1139  total_loss: 0.4842  loss_cls: 0.283  loss_box_reg: 0.2046  time: 0.8751  last_time: 0.8745  data_time: 0.0613  last_data_time: 0.0542   lr: 0.01  max_mem: 21306M
[02/27 00:52:39] d2.utils.events INFO:  eta: 0:45:42  iter: 1159  total_loss: 0.4807  loss_cls: 0.2849  loss_box_reg: 0.2035  time: 0.8751  last_time: 0.8835  data_time: 0.0619  last_data_time: 0.0652   lr: 0.01  max_mem: 21306M
[02/27 00:52:57] d2.utils.events INFO:  eta: 0:45:24  iter: 1179  total_loss: 0.4763  loss_cls: 0.2668  loss_box_reg: 0.2048  time: 0.8752  last_time: 0.8848  data_time: 0.0597  last_data_time: 0.0657   lr: 0.01  max_mem: 21306M
[02/27 00:53:14] d2.utils.events INFO:  eta: 0:45:06  iter: 1199  total_loss: 0.4494  loss_cls: 0.2532  loss_box_reg: 0.1971  time: 0.8751  last_time: 0.8742  data_time: 0.0606  last_data_time: 0.0556   lr: 0.01  max_mem: 21306M
[02/27 00:53:32] d2.utils.events INFO:  eta: 0:44:48  iter: 1219  total_loss: 0.469  loss_cls: 0.2632  loss_box_reg: 0.2059  time: 0.8751  last_time: 0.8297  data_time: 0.0600  last_data_time: 0.0592   lr: 0.01  max_mem: 21306M
[02/27 00:53:50] d2.utils.events INFO:  eta: 0:44:30  iter: 1239  total_loss: 0.4416  loss_cls: 0.2435  loss_box_reg: 0.201  time: 0.8751  last_time: 0.8698  data_time: 0.0598  last_data_time: 0.0509   lr: 0.01  max_mem: 21306M
[02/27 00:54:07] d2.utils.events INFO:  eta: 0:44:13  iter: 1259  total_loss: 0.4311  loss_cls: 0.2334  loss_box_reg: 0.1969  time: 0.8751  last_time: 0.8827  data_time: 0.0623  last_data_time: 0.0640   lr: 0.01  max_mem: 21306M
[02/27 00:54:24] d2.utils.events INFO:  eta: 0:43:55  iter: 1279  total_loss: 0.429  loss_cls: 0.2328  loss_box_reg: 0.1987  time: 0.8751  last_time: 0.8678  data_time: 0.0584  last_data_time: 0.0502   lr: 0.01  max_mem: 21306M
[02/27 00:54:42] d2.utils.events INFO:  eta: 0:43:37  iter: 1299  total_loss: 0.4182  loss_cls: 0.2208  loss_box_reg: 0.196  time: 0.8752  last_time: 0.8868  data_time: 0.0614  last_data_time: 0.0693   lr: 0.01  max_mem: 21306M
[02/27 00:54:59] d2.utils.events INFO:  eta: 0:43:19  iter: 1319  total_loss: 0.413  loss_cls: 0.2181  loss_box_reg: 0.1943  time: 0.8750  last_time: 0.8756  data_time: 0.0598  last_data_time: 0.0569   lr: 0.01  max_mem: 21306M
[02/27 00:55:17] d2.utils.events INFO:  eta: 0:43:01  iter: 1339  total_loss: 0.4123  loss_cls: 0.2197  loss_box_reg: 0.1939  time: 0.8750  last_time: 0.8700  data_time: 0.0576  last_data_time: 0.0517   lr: 0.01  max_mem: 21306M
[02/27 00:55:34] d2.utils.events INFO:  eta: 0:42:43  iter: 1359  total_loss: 0.3993  loss_cls: 0.211  loss_box_reg: 0.1884  time: 0.8751  last_time: 0.8912  data_time: 0.0602  last_data_time: 0.0718   lr: 0.01  max_mem: 21306M
[02/27 00:55:52] d2.utils.events INFO:  eta: 0:42:25  iter: 1379  total_loss: 0.3973  loss_cls: 0.2093  loss_box_reg: 0.1882  time: 0.8749  last_time: 0.8737  data_time: 0.0566  last_data_time: 0.0556   lr: 0.01  max_mem: 21306M
[02/27 00:56:09] d2.utils.events INFO:  eta: 0:42:08  iter: 1399  total_loss: 0.3914  loss_cls: 0.2046  loss_box_reg: 0.1899  time: 0.8749  last_time: 0.8777  data_time: 0.0579  last_data_time: 0.0588   lr: 0.01  max_mem: 21306M
[02/27 00:56:27] d2.utils.events INFO:  eta: 0:41:50  iter: 1419  total_loss: 0.3939  loss_cls: 0.2074  loss_box_reg: 0.1885  time: 0.8749  last_time: 0.8674  data_time: 0.0601  last_data_time: 0.0493   lr: 0.01  max_mem: 21306M
[02/27 00:56:33] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0001426.pth
[02/27 00:56:34] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/27 00:56:34] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/27 00:56:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/27 00:56:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/27 00:56:34] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/27 00:56:34] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/27 00:56:34] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/27 00:56:35] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0004 s/iter. Inference: 0.0289 s/iter. Eval: 0.0002 s/iter. Total: 0.0295 s/iter. ETA=0:00:04
[02/27 00:56:39] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.672132 (0.030143 s / iter per device, on 1 devices)
[02/27 00:56:39] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.028979 s / iter per device, on 1 devices)
[02/27 00:56:39] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/27 00:56:39] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/27 00:56:40] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/27 00:56:40] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/27 00:56:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.20 seconds.
[02/27 00:56:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/27 00:56:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.11 seconds.
[02/27 00:56:40] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 10.806 | 18.195 | 11.273 | 4.244 | 18.673 | 29.368 |
[02/27 00:56:40] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 10.717 | 001_binder_clips_median      | 17.827 | 002_binder_clips_small       | 13.395 |
| 003_bombik_bucket          | 4.447  | 004_bonne_maman_blueberry    | 0.034  | 005_bonne_maman_raspberry    | 0.104  |
| 006_bonne_maman_strawberry | 0.124  | 007_costa_caramel            | 29.830 | 008_essential_oil_bergamot   | 12.493 |
| 009_garlic_toast_spread    | 3.657  | 010_handcream_avocado        | 0.859  | 011_hb_calcium               | 12.197 |
| 012_hb_grapeseed           | 8.518  | 013_hb_marine_collagen       | 11.549 | 014_hellmanns_mayonnaise     | 3.881  |
| 015_illy_blend             | 0.494  | 016_japanese_finger_cookies  | 1.188  | 017_john_west_canned_tuna    | 2.749  |
| 018_kerastase_shampoo      | 5.776  | 019_kiehls_facial_cream      | 21.222 | 020_kiihne_balsamic          | 2.223  |
| 021_kiihne_honey_mustard   | 8.956  | 022_lindor_matcha            | 24.112 | 023_lindor_salted_caramel    | 17.789 |
| 024_lush_mask              | 67.396 | 025_pasta_sauce_black_pepper | 1.216  | 026_pasta_sauce_tomato       | 6.234  |
| 027_pepsi                  | 34.293 | 028_portable_yogurt_machine  | 0.437  | 029_selfile_stick            | 0.517  |
| 030_sour_lemon_drops       | 4.509  | 031_sticky_notes             | 4.623  | 032_stridex_green            | 33.245 |
| 033_thermos_flask_cream    | 21.683 | 034_thermos_flask_muji       | 3.577  | 035_thermos_flask_sliver     | 0.334  |
| 036_tragata_olive_oil      | 2.071  | 037_tulip_luncheon_meat      | 0.990  | 038_unicharm_cotton_pad      | 37.766 |
| 039_vinda_tissue           | 33.351 | 040_wrigley_doublemint_gum   | 0.000  | 041_baseball_cap_black       | 15.015 |
| 042_baseball_cap_pink      | 20.980 | 043_bfe_facial_mask          | 26.360 | 044_corgi_doll               | 7.885  |
| 045_dinosaur_doll          | 41.166 | 046_geo_mocha                | 4.391  | 047_geo_roast_charcoal       | 1.659  |
| 048_instant_noodle_black   | 0.853  | 049_instant_noodle_red       | 27.330 | 050_nabati_cheese_wafer      | 25.525 |
| 051_truffettes             | 2.204  | 052_acnes_cream              | 16.634 | 053_aveda_conditioner        | 16.064 |
| 054_banana_milk_drink      | 2.018  | 055_candle_beast             | 9.431  | 056_china_persimmon          | 11.243 |
| 057_danisa_butter_cookies  | 1.730  | 058_effaclar_duo             | 4.106  | 059_evelom_cleanser          | 15.246 |
| 060_glasses_box_blone      | 22.155 | 061_handcream_iris           | 0.000  | 062_handcream_lavender       | 1.485  |
| 063_handcream_rosewater    | 0.085  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 1.134  |
| 066_japanese_chocolate     | 32.539 | 067_kerastase_hair_treatment | 4.324  | 068_kiehls_serum             | 21.184 |
| 069_korean_beef_marinade   | 22.114 | 070_korean_doenjang          | 8.189  | 071_korean_gochujang         | 0.000  |
| 072_korean_ssamjang        | 7.657  | 073_loccitane_soap           | 15.009 | 074_marvis_toothpaste_purple | 28.640 |
| 075_mouse_thinkpad         | 3.418  | 076_oatly_chocolate          | 6.251  | 077_oatly_original           | 13.184 |
| 078_ousa_grated_cheese     | 4.818  | 079_polaroid_film            | 1.599  | 080_skinceuticals_be         | 23.070 |
| 081_skinceuticals_cf       | 10.797 | 082_skinceuticals_phyto      | 12.033 | 083_stapler_black            | 8.785  |
| 084_stapler_blue           | 9.383  | 085_sunscreen_blue           | 0.248  | 086_tempo_pocket_tissue      | 0.127  |
| 087_thermos_flask_purple   | 24.358 | 088_uha_matcha               | 5.858  | 089_urban_decay_spray        | 6.347  |
| 090_vitaboost_multivitamin | 2.752  | 091_watercolor_penbox        | 0.396  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 14.376 | 094_kaneyo_kitchen_bleach    | 17.152 | 095_lays_chip_bag_blue       | 9.626  |
| 096_lays_chip_bag_green    | 3.412  | 097_lays_chip_tube_auburn    | 11.310 | 098_lays_chip_tube_green     | 10.572 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/27 00:56:40] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/27 00:56:40] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 00:56:40] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/27 00:56:40] d2.evaluation.testing INFO: copypaste: 10.8061,18.1951,11.2733,4.2443,18.6729,29.3679
[02/27 00:56:50] d2.utils.events INFO:  eta: 0:41:32  iter: 1439  total_loss: 0.3926  loss_cls: 0.2035  loss_box_reg: 0.1904  time: 0.8748  last_time: 0.8764  data_time: 0.0582  last_data_time: 0.0571   lr: 0.01  max_mem: 21306M
[02/27 00:57:08] d2.utils.events INFO:  eta: 0:41:14  iter: 1459  total_loss: 0.3853  loss_cls: 0.1974  loss_box_reg: 0.1884  time: 0.8748  last_time: 0.8844  data_time: 0.0580  last_data_time: 0.0664   lr: 0.01  max_mem: 21306M
[02/27 00:57:25] d2.utils.events INFO:  eta: 0:40:56  iter: 1479  total_loss: 0.3684  loss_cls: 0.1886  loss_box_reg: 0.1786  time: 0.8748  last_time: 0.8851  data_time: 0.0619  last_data_time: 0.0656   lr: 0.01  max_mem: 21306M
[02/27 00:57:43] d2.utils.events INFO:  eta: 0:40:39  iter: 1499  total_loss: 0.3743  loss_cls: 0.1894  loss_box_reg: 0.1832  time: 0.8748  last_time: 0.8843  data_time: 0.0583  last_data_time: 0.0654   lr: 0.01  max_mem: 21306M
[02/27 00:58:00] d2.utils.events INFO:  eta: 0:40:21  iter: 1519  total_loss: 0.3781  loss_cls: 0.1908  loss_box_reg: 0.1878  time: 0.8748  last_time: 0.8711  data_time: 0.0627  last_data_time: 0.0517   lr: 0.01  max_mem: 21306M
[02/27 00:58:18] d2.utils.events INFO:  eta: 0:40:04  iter: 1539  total_loss: 0.3666  loss_cls: 0.1829  loss_box_reg: 0.1804  time: 0.8749  last_time: 0.8818  data_time: 0.0600  last_data_time: 0.0628   lr: 0.01  max_mem: 21306M
[02/27 00:58:53] d2.utils.events INFO:  eta: 0:39:46  iter: 1559  total_loss: 0.3705  loss_cls: 0.1897  loss_box_reg: 0.1804  time: 0.8863  last_time: 0.8777  data_time: 0.9440  last_data_time: 0.0633   lr: 0.01  max_mem: 21306M
[02/27 00:59:11] d2.utils.events INFO:  eta: 0:39:29  iter: 1579  total_loss: 0.3504  loss_cls: 0.1752  loss_box_reg: 0.177  time: 0.8860  last_time: 0.8842  data_time: 0.0564  last_data_time: 0.0656   lr: 0.01  max_mem: 21306M
[02/27 00:59:28] d2.utils.events INFO:  eta: 0:39:11  iter: 1599  total_loss: 0.3544  loss_cls: 0.1747  loss_box_reg: 0.179  time: 0.8859  last_time: 0.8820  data_time: 0.0597  last_data_time: 0.0628   lr: 0.01  max_mem: 21306M
[02/27 00:59:46] d2.utils.events INFO:  eta: 0:38:54  iter: 1619  total_loss: 0.3524  loss_cls: 0.1733  loss_box_reg: 0.1798  time: 0.8858  last_time: 0.8733  data_time: 0.0597  last_data_time: 0.0552   lr: 0.01  max_mem: 21306M
[02/27 01:00:03] d2.utils.events INFO:  eta: 0:38:36  iter: 1639  total_loss: 0.352  loss_cls: 0.1738  loss_box_reg: 0.1789  time: 0.8857  last_time: 0.8752  data_time: 0.0591  last_data_time: 0.0571   lr: 0.01  max_mem: 21306M
[02/27 01:00:21] d2.utils.events INFO:  eta: 0:38:19  iter: 1659  total_loss: 0.3634  loss_cls: 0.1702  loss_box_reg: 0.1892  time: 0.8856  last_time: 0.8775  data_time: 0.0581  last_data_time: 0.0588   lr: 0.01  max_mem: 21306M
[02/27 01:00:38] d2.utils.events INFO:  eta: 0:38:01  iter: 1679  total_loss: 0.3498  loss_cls: 0.1704  loss_box_reg: 0.1816  time: 0.8855  last_time: 0.8815  data_time: 0.0591  last_data_time: 0.0636   lr: 0.01  max_mem: 21306M
[02/27 01:00:56] d2.utils.events INFO:  eta: 0:37:44  iter: 1699  total_loss: 0.3363  loss_cls: 0.1604  loss_box_reg: 0.175  time: 0.8854  last_time: 0.8768  data_time: 0.0583  last_data_time: 0.0577   lr: 0.01  max_mem: 21306M
[02/27 01:01:13] d2.utils.events INFO:  eta: 0:37:26  iter: 1719  total_loss: 0.3297  loss_cls: 0.1571  loss_box_reg: 0.1709  time: 0.8852  last_time: 0.8851  data_time: 0.0579  last_data_time: 0.0661   lr: 0.01  max_mem: 21306M
[02/27 01:01:31] d2.utils.events INFO:  eta: 0:37:08  iter: 1739  total_loss: 0.3437  loss_cls: 0.1638  loss_box_reg: 0.1801  time: 0.8851  last_time: 0.8773  data_time: 0.0570  last_data_time: 0.0584   lr: 0.01  max_mem: 21306M
[02/27 01:01:48] d2.utils.events INFO:  eta: 0:36:51  iter: 1759  total_loss: 0.3385  loss_cls: 0.164  loss_box_reg: 0.1753  time: 0.8850  last_time: 0.8688  data_time: 0.0600  last_data_time: 0.0502   lr: 0.01  max_mem: 21306M
[02/27 01:02:06] d2.utils.events INFO:  eta: 0:36:33  iter: 1779  total_loss: 0.3309  loss_cls: 0.1548  loss_box_reg: 0.1755  time: 0.8848  last_time: 0.8822  data_time: 0.0596  last_data_time: 0.0641   lr: 0.01  max_mem: 21306M
[02/27 01:02:23] d2.utils.events INFO:  eta: 0:36:16  iter: 1799  total_loss: 0.3391  loss_cls: 0.1609  loss_box_reg: 0.178  time: 0.8848  last_time: 0.8762  data_time: 0.0592  last_data_time: 0.0569   lr: 0.01  max_mem: 21306M
[02/27 01:02:41] d2.utils.events INFO:  eta: 0:35:58  iter: 1819  total_loss: 0.325  loss_cls: 0.158  loss_box_reg: 0.1694  time: 0.8847  last_time: 0.8847  data_time: 0.0592  last_data_time: 0.0664   lr: 0.01  max_mem: 21306M
[02/27 01:02:58] d2.utils.events INFO:  eta: 0:35:40  iter: 1839  total_loss: 0.3298  loss_cls: 0.1578  loss_box_reg: 0.173  time: 0.8846  last_time: 0.8713  data_time: 0.0591  last_data_time: 0.0519   lr: 0.01  max_mem: 21306M
[02/27 01:03:16] d2.utils.events INFO:  eta: 0:35:23  iter: 1859  total_loss: 0.3309  loss_cls: 0.1543  loss_box_reg: 0.1767  time: 0.8845  last_time: 0.8752  data_time: 0.0615  last_data_time: 0.0566   lr: 0.01  max_mem: 21306M
[02/27 01:03:33] d2.utils.events INFO:  eta: 0:35:05  iter: 1879  total_loss: 0.3196  loss_cls: 0.152  loss_box_reg: 0.1663  time: 0.8844  last_time: 0.8809  data_time: 0.0601  last_data_time: 0.0625   lr: 0.01  max_mem: 21306M
[02/27 01:03:51] d2.utils.events INFO:  eta: 0:34:48  iter: 1899  total_loss: 0.3265  loss_cls: 0.1535  loss_box_reg: 0.173  time: 0.8843  last_time: 0.8902  data_time: 0.0616  last_data_time: 0.0714   lr: 0.01  max_mem: 21306M
[02/27 01:04:08] d2.utils.events INFO:  eta: 0:34:31  iter: 1919  total_loss: 0.3372  loss_cls: 0.1608  loss_box_reg: 0.175  time: 0.8842  last_time: 0.8803  data_time: 0.0604  last_data_time: 0.0617   lr: 0.01  max_mem: 21306M
[02/27 01:04:26] d2.utils.events INFO:  eta: 0:34:13  iter: 1939  total_loss: 0.341  loss_cls: 0.1551  loss_box_reg: 0.1787  time: 0.8842  last_time: 0.8856  data_time: 0.0614  last_data_time: 0.0649   lr: 0.01  max_mem: 21306M
[02/27 01:04:43] d2.utils.events INFO:  eta: 0:33:56  iter: 1959  total_loss: 0.3145  loss_cls: 0.1476  loss_box_reg: 0.1688  time: 0.8840  last_time: 0.8700  data_time: 0.0594  last_data_time: 0.0511   lr: 0.01  max_mem: 21306M
[02/27 01:05:01] d2.utils.events INFO:  eta: 0:33:38  iter: 1979  total_loss: 0.3294  loss_cls: 0.1532  loss_box_reg: 0.175  time: 0.8839  last_time: 0.8258  data_time: 0.0598  last_data_time: 0.0537   lr: 0.01  max_mem: 21306M
[02/27 01:05:18] d2.utils.events INFO:  eta: 0:33:21  iter: 1999  total_loss: 0.3334  loss_cls: 0.157  loss_box_reg: 0.1745  time: 0.8838  last_time: 0.8384  data_time: 0.0624  last_data_time: 0.0677   lr: 0.01  max_mem: 21306M
[02/27 01:05:36] d2.utils.events INFO:  eta: 0:33:03  iter: 2019  total_loss: 0.3222  loss_cls: 0.148  loss_box_reg: 0.1708  time: 0.8837  last_time: 0.8830  data_time: 0.0596  last_data_time: 0.0644   lr: 0.01  max_mem: 21306M
[02/27 01:05:53] d2.utils.events INFO:  eta: 0:32:45  iter: 2039  total_loss: 0.3054  loss_cls: 0.1405  loss_box_reg: 0.1669  time: 0.8835  last_time: 0.7828  data_time: 0.0583  last_data_time: 0.0587   lr: 0.01  max_mem: 21306M
[02/27 01:06:11] d2.utils.events INFO:  eta: 0:32:28  iter: 2059  total_loss: 0.3119  loss_cls: 0.1424  loss_box_reg: 0.1691  time: 0.8835  last_time: 0.8828  data_time: 0.0616  last_data_time: 0.0655   lr: 0.01  max_mem: 21306M
[02/27 01:06:28] d2.utils.events INFO:  eta: 0:32:11  iter: 2079  total_loss: 0.3052  loss_cls: 0.1395  loss_box_reg: 0.168  time: 0.8834  last_time: 0.8759  data_time: 0.0616  last_data_time: 0.0576   lr: 0.01  max_mem: 21306M
[02/27 01:06:46] d2.utils.events INFO:  eta: 0:31:53  iter: 2099  total_loss: 0.3113  loss_cls: 0.1428  loss_box_reg: 0.1687  time: 0.8834  last_time: 0.8818  data_time: 0.0606  last_data_time: 0.0639   lr: 0.01  max_mem: 21306M
[02/27 01:07:03] d2.utils.events INFO:  eta: 0:31:35  iter: 2119  total_loss: 0.3031  loss_cls: 0.1409  loss_box_reg: 0.162  time: 0.8833  last_time: 0.8864  data_time: 0.0582  last_data_time: 0.0683   lr: 0.01  max_mem: 21306M
[02/27 01:07:21] d2.utils.events INFO:  eta: 0:31:18  iter: 2139  total_loss: 0.3051  loss_cls: 0.1385  loss_box_reg: 0.1651  time: 0.8832  last_time: 0.8827  data_time: 0.0583  last_data_time: 0.0636   lr: 0.01  max_mem: 21306M
[02/27 01:07:38] d2.utils.events INFO:  eta: 0:31:00  iter: 2159  total_loss: 0.2999  loss_cls: 0.1375  loss_box_reg: 0.162  time: 0.8831  last_time: 0.8779  data_time: 0.0600  last_data_time: 0.0588   lr: 0.01  max_mem: 21306M
[02/27 01:07:56] d2.utils.events INFO:  eta: 0:30:43  iter: 2179  total_loss: 0.3052  loss_cls: 0.1391  loss_box_reg: 0.1661  time: 0.8831  last_time: 0.8794  data_time: 0.0617  last_data_time: 0.0595   lr: 0.01  max_mem: 21306M
[02/27 01:08:14] d2.utils.events INFO:  eta: 0:30:25  iter: 2199  total_loss: 0.308  loss_cls: 0.1382  loss_box_reg: 0.1659  time: 0.8830  last_time: 0.8876  data_time: 0.0618  last_data_time: 0.0684   lr: 0.01  max_mem: 21306M
[02/27 01:08:31] d2.utils.events INFO:  eta: 0:30:08  iter: 2219  total_loss: 0.3041  loss_cls: 0.1432  loss_box_reg: 0.1637  time: 0.8830  last_time: 0.8830  data_time: 0.0599  last_data_time: 0.0635   lr: 0.01  max_mem: 21306M
[02/27 01:08:49] d2.utils.events INFO:  eta: 0:29:51  iter: 2239  total_loss: 0.304  loss_cls: 0.1365  loss_box_reg: 0.1619  time: 0.8829  last_time: 0.8725  data_time: 0.0623  last_data_time: 0.0541   lr: 0.01  max_mem: 21306M
[02/27 01:09:06] d2.utils.events INFO:  eta: 0:29:33  iter: 2259  total_loss: 0.3077  loss_cls: 0.1353  loss_box_reg: 0.1665  time: 0.8828  last_time: 0.8766  data_time: 0.0588  last_data_time: 0.0571   lr: 0.01  max_mem: 21306M
[02/27 01:09:24] d2.utils.events INFO:  eta: 0:29:16  iter: 2279  total_loss: 0.2963  loss_cls: 0.1315  loss_box_reg: 0.1629  time: 0.8828  last_time: 0.8847  data_time: 0.0600  last_data_time: 0.0646   lr: 0.01  max_mem: 21306M
[02/27 01:09:41] d2.utils.events INFO:  eta: 0:28:58  iter: 2299  total_loss: 0.2969  loss_cls: 0.1346  loss_box_reg: 0.1641  time: 0.8827  last_time: 0.8749  data_time: 0.0595  last_data_time: 0.0563   lr: 0.01  max_mem: 21306M
[02/27 01:09:59] d2.utils.events INFO:  eta: 0:28:41  iter: 2319  total_loss: 0.2941  loss_cls: 0.1338  loss_box_reg: 0.1607  time: 0.8827  last_time: 0.8818  data_time: 0.0596  last_data_time: 0.0632   lr: 0.01  max_mem: 21306M
[02/27 01:10:16] d2.utils.events INFO:  eta: 0:28:23  iter: 2339  total_loss: 0.2917  loss_cls: 0.1331  loss_box_reg: 0.1595  time: 0.8825  last_time: 0.8767  data_time: 0.0565  last_data_time: 0.0588   lr: 0.01  max_mem: 21306M
[02/27 01:10:34] d2.utils.events INFO:  eta: 0:28:06  iter: 2359  total_loss: 0.3027  loss_cls: 0.135  loss_box_reg: 0.1675  time: 0.8824  last_time: 0.8872  data_time: 0.0611  last_data_time: 0.0688   lr: 0.01  max_mem: 21306M
[02/27 01:10:51] d2.utils.events INFO:  eta: 0:27:48  iter: 2379  total_loss: 0.2953  loss_cls: 0.1335  loss_box_reg: 0.1611  time: 0.8824  last_time: 0.8852  data_time: 0.0623  last_data_time: 0.0667   lr: 0.01  max_mem: 21306M
[02/27 01:11:09] d2.utils.events INFO:  eta: 0:27:31  iter: 2399  total_loss: 0.3127  loss_cls: 0.1412  loss_box_reg: 0.1711  time: 0.8823  last_time: 0.8829  data_time: 0.0612  last_data_time: 0.0646   lr: 0.01  max_mem: 21306M
[02/27 01:11:26] d2.utils.events INFO:  eta: 0:27:13  iter: 2419  total_loss: 0.2933  loss_cls: 0.1319  loss_box_reg: 0.1593  time: 0.8822  last_time: 0.8666  data_time: 0.0599  last_data_time: 0.0485   lr: 0.01  max_mem: 21306M
[02/27 01:11:44] d2.utils.events INFO:  eta: 0:26:56  iter: 2439  total_loss: 0.2892  loss_cls: 0.1302  loss_box_reg: 0.1595  time: 0.8822  last_time: 0.8840  data_time: 0.0605  last_data_time: 0.0658   lr: 0.01  max_mem: 21306M
[02/27 01:12:01] d2.utils.events INFO:  eta: 0:26:39  iter: 2459  total_loss: 0.2887  loss_cls: 0.13  loss_box_reg: 0.1569  time: 0.8822  last_time: 0.8736  data_time: 0.0635  last_data_time: 0.0549   lr: 0.01  max_mem: 21306M
[02/27 01:12:19] d2.utils.events INFO:  eta: 0:26:21  iter: 2479  total_loss: 0.2832  loss_cls: 0.1274  loss_box_reg: 0.1582  time: 0.8821  last_time: 0.8730  data_time: 0.0608  last_data_time: 0.0512   lr: 0.01  max_mem: 21306M
[02/27 01:12:36] d2.utils.events INFO:  eta: 0:26:04  iter: 2499  total_loss: 0.2829  loss_cls: 0.129  loss_box_reg: 0.1574  time: 0.8821  last_time: 0.8857  data_time: 0.0616  last_data_time: 0.0667   lr: 0.01  max_mem: 21306M
[02/27 01:12:54] d2.utils.events INFO:  eta: 0:25:46  iter: 2519  total_loss: 0.2902  loss_cls: 0.1298  loss_box_reg: 0.1584  time: 0.8820  last_time: 0.8853  data_time: 0.0602  last_data_time: 0.0669   lr: 0.01  max_mem: 21306M
[02/27 01:13:11] d2.utils.events INFO:  eta: 0:25:29  iter: 2539  total_loss: 0.2819  loss_cls: 0.1273  loss_box_reg: 0.1581  time: 0.8819  last_time: 0.8913  data_time: 0.0620  last_data_time: 0.0724   lr: 0.01  max_mem: 21306M
[02/27 01:13:29] d2.utils.events INFO:  eta: 0:25:11  iter: 2559  total_loss: 0.2913  loss_cls: 0.1292  loss_box_reg: 0.1596  time: 0.8819  last_time: 0.8915  data_time: 0.0633  last_data_time: 0.0728   lr: 0.01  max_mem: 21306M
[02/27 01:13:46] d2.utils.events INFO:  eta: 0:24:54  iter: 2579  total_loss: 0.2832  loss_cls: 0.1264  loss_box_reg: 0.155  time: 0.8818  last_time: 0.8692  data_time: 0.0595  last_data_time: 0.0511   lr: 0.01  max_mem: 21306M
[02/27 01:14:04] d2.utils.events INFO:  eta: 0:24:36  iter: 2599  total_loss: 0.2774  loss_cls: 0.1219  loss_box_reg: 0.1554  time: 0.8818  last_time: 0.8838  data_time: 0.0627  last_data_time: 0.0648   lr: 0.01  max_mem: 21306M
[02/27 01:14:21] d2.utils.events INFO:  eta: 0:24:19  iter: 2619  total_loss: 0.2791  loss_cls: 0.1238  loss_box_reg: 0.1551  time: 0.8818  last_time: 0.8836  data_time: 0.0613  last_data_time: 0.0655   lr: 0.01  max_mem: 21306M
[02/27 01:14:39] d2.utils.events INFO:  eta: 0:24:01  iter: 2639  total_loss: 0.2816  loss_cls: 0.1241  loss_box_reg: 0.1562  time: 0.8817  last_time: 0.8684  data_time: 0.0633  last_data_time: 0.0488   lr: 0.01  max_mem: 21306M
[02/27 01:14:56] d2.utils.events INFO:  eta: 0:23:44  iter: 2659  total_loss: 0.2823  loss_cls: 0.1249  loss_box_reg: 0.1595  time: 0.8817  last_time: 0.8819  data_time: 0.0596  last_data_time: 0.0632   lr: 0.01  max_mem: 21306M
[02/27 01:15:14] d2.utils.events INFO:  eta: 0:23:26  iter: 2679  total_loss: 0.2795  loss_cls: 0.1241  loss_box_reg: 0.1557  time: 0.8816  last_time: 0.8687  data_time: 0.0607  last_data_time: 0.0504   lr: 0.01  max_mem: 21306M
[02/27 01:15:31] d2.utils.events INFO:  eta: 0:23:08  iter: 2699  total_loss: 0.2773  loss_cls: 0.122  loss_box_reg: 0.1523  time: 0.8816  last_time: 0.8873  data_time: 0.0612  last_data_time: 0.0684   lr: 0.01  max_mem: 21306M
[02/27 01:15:49] d2.utils.events INFO:  eta: 0:22:51  iter: 2719  total_loss: 0.2752  loss_cls: 0.1232  loss_box_reg: 0.1554  time: 0.8816  last_time: 0.8863  data_time: 0.0632  last_data_time: 0.0675   lr: 0.01  max_mem: 21306M
[02/27 01:16:07] d2.utils.events INFO:  eta: 0:22:34  iter: 2739  total_loss: 0.2863  loss_cls: 0.126  loss_box_reg: 0.1607  time: 0.8816  last_time: 0.8771  data_time: 0.0631  last_data_time: 0.0582   lr: 0.01  max_mem: 21306M
[02/27 01:16:24] d2.utils.events INFO:  eta: 0:22:17  iter: 2759  total_loss: 0.2706  loss_cls: 0.121  loss_box_reg: 0.1517  time: 0.8815  last_time: 0.8703  data_time: 0.0631  last_data_time: 0.0518   lr: 0.01  max_mem: 21306M
[02/27 01:16:42] d2.utils.events INFO:  eta: 0:21:59  iter: 2779  total_loss: 0.2758  loss_cls: 0.118  loss_box_reg: 0.1554  time: 0.8815  last_time: 0.8703  data_time: 0.0617  last_data_time: 0.0519   lr: 0.01  max_mem: 21306M
[02/27 01:16:59] d2.utils.events INFO:  eta: 0:21:42  iter: 2799  total_loss: 0.265  loss_cls: 0.1158  loss_box_reg: 0.1506  time: 0.8815  last_time: 0.8895  data_time: 0.0610  last_data_time: 0.0701   lr: 0.01  max_mem: 21306M
[02/27 01:17:17] d2.utils.events INFO:  eta: 0:21:25  iter: 2819  total_loss: 0.2688  loss_cls: 0.1181  loss_box_reg: 0.151  time: 0.8814  last_time: 0.8833  data_time: 0.0612  last_data_time: 0.0640   lr: 0.01  max_mem: 21306M
[02/27 01:17:34] d2.utils.events INFO:  eta: 0:21:07  iter: 2839  total_loss: 0.2702  loss_cls: 0.117  loss_box_reg: 0.1512  time: 0.8814  last_time: 0.8849  data_time: 0.0595  last_data_time: 0.0660   lr: 0.01  max_mem: 21306M
[02/27 01:17:47] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0002853.pth
[02/27 01:17:49] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/27 01:17:49] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/27 01:17:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/27 01:17:49] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/27 01:17:49] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/27 01:17:49] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/27 01:17:49] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/27 01:17:50] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0003 s/iter. Inference: 0.0287 s/iter. Eval: 0.0002 s/iter. Total: 0.0291 s/iter. ETA=0:00:04
[02/27 01:17:54] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.615646 (0.029778 s / iter per device, on 1 devices)
[02/27 01:17:54] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.028762 s / iter per device, on 1 devices)
[02/27 01:17:54] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/27 01:17:54] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/27 01:17:54] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/27 01:17:54] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/27 01:17:54] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.25 seconds.
[02/27 01:17:54] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/27 01:17:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.11 seconds.
[02/27 01:17:55] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 13.049 | 21.816 | 13.721 | 6.188 | 21.489 | 25.320 |
[02/27 01:17:55] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 9.215  | 001_binder_clips_median      | 22.491 | 002_binder_clips_small       | 12.871 |
| 003_bombik_bucket          | 12.701 | 004_bonne_maman_blueberry    | 0.104  | 005_bonne_maman_raspberry    | 0.806  |
| 006_bonne_maman_strawberry | 0.389  | 007_costa_caramel            | 20.659 | 008_essential_oil_bergamot   | 19.711 |
| 009_garlic_toast_spread    | 4.031  | 010_handcream_avocado        | 0.527  | 011_hb_calcium               | 13.818 |
| 012_hb_grapeseed           | 9.513  | 013_hb_marine_collagen       | 8.395  | 014_hellmanns_mayonnaise     | 5.676  |
| 015_illy_blend             | 0.600  | 016_japanese_finger_cookies  | 2.140  | 017_john_west_canned_tuna    | 10.502 |
| 018_kerastase_shampoo      | 9.554  | 019_kiehls_facial_cream      | 31.048 | 020_kiihne_balsamic          | 0.453  |
| 021_kiihne_honey_mustard   | 13.778 | 022_lindor_matcha            | 27.323 | 023_lindor_salted_caramel    | 29.038 |
| 024_lush_mask              | 69.250 | 025_pasta_sauce_black_pepper | 0.341  | 026_pasta_sauce_tomato       | 5.178  |
| 027_pepsi                  | 44.214 | 028_portable_yogurt_machine  | 0.091  | 029_selfile_stick            | 2.316  |
| 030_sour_lemon_drops       | 5.201  | 031_sticky_notes             | 8.862  | 032_stridex_green            | 46.157 |
| 033_thermos_flask_cream    | 31.760 | 034_thermos_flask_muji       | 1.206  | 035_thermos_flask_sliver     | 0.216  |
| 036_tragata_olive_oil      | 0.041  | 037_tulip_luncheon_meat      | 7.881  | 038_unicharm_cotton_pad      | 42.441 |
| 039_vinda_tissue           | 36.895 | 040_wrigley_doublemint_gum   | 0.374  | 041_baseball_cap_black       | 7.193  |
| 042_baseball_cap_pink      | 19.387 | 043_bfe_facial_mask          | 23.551 | 044_corgi_doll               | 7.571  |
| 045_dinosaur_doll          | 31.898 | 046_geo_mocha                | 3.685  | 047_geo_roast_charcoal       | 2.979  |
| 048_instant_noodle_black   | 3.080  | 049_instant_noodle_red       | 26.534 | 050_nabati_cheese_wafer      | 32.573 |
| 051_truffettes             | 9.827  | 052_acnes_cream              | 18.939 | 053_aveda_conditioner        | 19.945 |
| 054_banana_milk_drink      | 7.541  | 055_candle_beast             | 18.520 | 056_china_persimmon          | 13.087 |
| 057_danisa_butter_cookies  | 1.401  | 058_effaclar_duo             | 5.446  | 059_evelom_cleanser          | 28.384 |
| 060_glasses_box_blone      | 24.318 | 061_handcream_iris           | 0.124  | 062_handcream_lavender       | 0.068  |
| 063_handcream_rosewater    | 0.946  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 3.484  |
| 066_japanese_chocolate     | 31.293 | 067_kerastase_hair_treatment | 6.376  | 068_kiehls_serum             | 15.546 |
| 069_korean_beef_marinade   | 13.460 | 070_korean_doenjang          | 19.710 | 071_korean_gochujang         | 0.196  |
| 072_korean_ssamjang        | 9.987  | 073_loccitane_soap           | 4.910  | 074_marvis_toothpaste_purple | 41.499 |
| 075_mouse_thinkpad         | 6.325  | 076_oatly_chocolate          | 9.229  | 077_oatly_original           | 18.868 |
| 078_ousa_grated_cheese     | 3.022  | 079_polaroid_film            | 0.423  | 080_skinceuticals_be         | 46.001 |
| 081_skinceuticals_cf       | 19.498 | 082_skinceuticals_phyto      | 14.220 | 083_stapler_black            | 9.560  |
| 084_stapler_blue           | 11.649 | 085_sunscreen_blue           | 0.105  | 086_tempo_pocket_tissue      | 1.233  |
| 087_thermos_flask_purple   | 26.554 | 088_uha_matcha               | 12.341 | 089_urban_decay_spray        | 7.747  |
| 090_vitaboost_multivitamin | 1.442  | 091_watercolor_penbox        | 0.052  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 11.597 | 094_kaneyo_kitchen_bleach    | 27.459 | 095_lays_chip_bag_blue       | 12.793 |
| 096_lays_chip_bag_green    | 9.773  | 097_lays_chip_tube_auburn    | 11.557 | 098_lays_chip_tube_green     | 22.177 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/27 01:17:55] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/27 01:17:55] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 01:17:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/27 01:17:55] d2.evaluation.testing INFO: copypaste: 13.0485,21.8163,13.7215,6.1876,21.4891,25.3200
[02/27 01:17:58] d2.utils.events INFO:  eta: 0:20:49  iter: 2859  total_loss: 0.2697  loss_cls: 0.1146  loss_box_reg: 0.1536  time: 0.8813  last_time: 0.8298  data_time: 0.0592  last_data_time: 0.0580   lr: 0.01  max_mem: 21306M
[02/27 01:18:15] d2.utils.events INFO:  eta: 0:20:31  iter: 2879  total_loss: 0.2795  loss_cls: 0.1241  loss_box_reg: 0.1573  time: 0.8813  last_time: 0.8355  data_time: 0.0604  last_data_time: 0.0651   lr: 0.01  max_mem: 21306M
[02/27 01:18:33] d2.utils.events INFO:  eta: 0:20:14  iter: 2899  total_loss: 0.2651  loss_cls: 0.1178  loss_box_reg: 0.1473  time: 0.8813  last_time: 0.8878  data_time: 0.0589  last_data_time: 0.0699   lr: 0.01  max_mem: 21306M
[02/27 01:18:51] d2.utils.events INFO:  eta: 0:19:56  iter: 2919  total_loss: 0.2731  loss_cls: 0.1194  loss_box_reg: 0.1503  time: 0.8812  last_time: 0.8706  data_time: 0.0611  last_data_time: 0.0513   lr: 0.01  max_mem: 21306M
[02/27 01:19:08] d2.utils.events INFO:  eta: 0:19:39  iter: 2939  total_loss: 0.2756  loss_cls: 0.1243  loss_box_reg: 0.1499  time: 0.8812  last_time: 0.8856  data_time: 0.0616  last_data_time: 0.0667   lr: 0.01  max_mem: 21306M
[02/27 01:19:26] d2.utils.events INFO:  eta: 0:19:21  iter: 2959  total_loss: 0.2714  loss_cls: 0.1185  loss_box_reg: 0.1539  time: 0.8811  last_time: 0.8885  data_time: 0.0601  last_data_time: 0.0686   lr: 0.01  max_mem: 21306M
[02/27 01:19:43] d2.utils.events INFO:  eta: 0:19:04  iter: 2979  total_loss: 0.2632  loss_cls: 0.1153  loss_box_reg: 0.1501  time: 0.8811  last_time: 0.8414  data_time: 0.0644  last_data_time: 0.0708   lr: 0.01  max_mem: 21306M
[02/27 01:20:01] d2.utils.events INFO:  eta: 0:18:46  iter: 2999  total_loss: 0.2615  loss_cls: 0.1134  loss_box_reg: 0.147  time: 0.8811  last_time: 0.8377  data_time: 0.0660  last_data_time: 0.0659   lr: 0.01  max_mem: 21306M
[02/27 01:20:18] d2.utils.events INFO:  eta: 0:18:29  iter: 3019  total_loss: 0.2796  loss_cls: 0.1216  loss_box_reg: 0.1581  time: 0.8810  last_time: 0.8331  data_time: 0.0625  last_data_time: 0.0637   lr: 0.01  max_mem: 21306M
[02/27 01:20:36] d2.utils.events INFO:  eta: 0:18:12  iter: 3039  total_loss: 0.2692  loss_cls: 0.1145  loss_box_reg: 0.1551  time: 0.8810  last_time: 0.8728  data_time: 0.0625  last_data_time: 0.0541   lr: 0.01  max_mem: 21306M
[02/27 01:20:53] d2.utils.events INFO:  eta: 0:17:54  iter: 3059  total_loss: 0.2741  loss_cls: 0.1191  loss_box_reg: 0.1549  time: 0.8810  last_time: 0.8795  data_time: 0.0603  last_data_time: 0.0615   lr: 0.01  max_mem: 21306M
[02/27 01:21:11] d2.utils.events INFO:  eta: 0:17:36  iter: 3079  total_loss: 0.2566  loss_cls: 0.1117  loss_box_reg: 0.1465  time: 0.8810  last_time: 0.8851  data_time: 0.0622  last_data_time: 0.0653   lr: 0.01  max_mem: 21306M
[02/27 01:21:29] d2.utils.events INFO:  eta: 0:17:19  iter: 3099  total_loss: 0.2635  loss_cls: 0.1145  loss_box_reg: 0.1519  time: 0.8810  last_time: 0.8857  data_time: 0.0616  last_data_time: 0.0675   lr: 0.01  max_mem: 21306M
[02/27 01:21:46] d2.utils.events INFO:  eta: 0:17:01  iter: 3119  total_loss: 0.255  loss_cls: 0.112  loss_box_reg: 0.1442  time: 0.8810  last_time: 0.8757  data_time: 0.0625  last_data_time: 0.0560   lr: 0.01  max_mem: 21306M
[02/27 01:22:04] d2.utils.events INFO:  eta: 0:16:44  iter: 3139  total_loss: 0.2577  loss_cls: 0.1112  loss_box_reg: 0.1487  time: 0.8809  last_time: 0.8739  data_time: 0.0602  last_data_time: 0.0567   lr: 0.01  max_mem: 21306M
[02/27 01:22:21] d2.utils.events INFO:  eta: 0:16:26  iter: 3159  total_loss: 0.2624  loss_cls: 0.1136  loss_box_reg: 0.1501  time: 0.8809  last_time: 0.8865  data_time: 0.0607  last_data_time: 0.0682   lr: 0.01  max_mem: 21306M
[02/27 01:22:39] d2.utils.events INFO:  eta: 0:16:09  iter: 3179  total_loss: 0.2608  loss_cls: 0.1109  loss_box_reg: 0.1504  time: 0.8809  last_time: 0.8746  data_time: 0.0625  last_data_time: 0.0556   lr: 0.01  max_mem: 21306M
[02/27 01:22:56] d2.utils.events INFO:  eta: 0:15:51  iter: 3199  total_loss: 0.2685  loss_cls: 0.1111  loss_box_reg: 0.1526  time: 0.8809  last_time: 0.8881  data_time: 0.0598  last_data_time: 0.0704   lr: 0.01  max_mem: 21306M
[02/27 01:23:14] d2.utils.events INFO:  eta: 0:15:33  iter: 3219  total_loss: 0.2575  loss_cls: 0.1088  loss_box_reg: 0.1461  time: 0.8808  last_time: 0.8794  data_time: 0.0618  last_data_time: 0.0619   lr: 0.01  max_mem: 21306M
[02/27 01:23:31] d2.utils.events INFO:  eta: 0:15:16  iter: 3239  total_loss: 0.2589  loss_cls: 0.1104  loss_box_reg: 0.1469  time: 0.8808  last_time: 0.8718  data_time: 0.0623  last_data_time: 0.0536   lr: 0.01  max_mem: 21306M
[02/27 01:23:49] d2.utils.events INFO:  eta: 0:14:58  iter: 3259  total_loss: 0.2626  loss_cls: 0.1131  loss_box_reg: 0.1509  time: 0.8808  last_time: 0.8791  data_time: 0.0605  last_data_time: 0.0596   lr: 0.01  max_mem: 21306M
[02/27 01:24:07] d2.utils.events INFO:  eta: 0:14:41  iter: 3279  total_loss: 0.2622  loss_cls: 0.1125  loss_box_reg: 0.1473  time: 0.8808  last_time: 0.8840  data_time: 0.0597  last_data_time: 0.0661   lr: 0.01  max_mem: 21306M
[02/27 01:24:24] d2.utils.events INFO:  eta: 0:14:23  iter: 3299  total_loss: 0.2521  loss_cls: 0.1088  loss_box_reg: 0.1444  time: 0.8808  last_time: 0.8848  data_time: 0.0617  last_data_time: 0.0661   lr: 0.01  max_mem: 21306M
[02/27 01:24:42] d2.utils.events INFO:  eta: 0:14:06  iter: 3319  total_loss: 0.2643  loss_cls: 0.1124  loss_box_reg: 0.1509  time: 0.8808  last_time: 0.8850  data_time: 0.0618  last_data_time: 0.0667   lr: 0.01  max_mem: 21306M
[02/27 01:24:59] d2.utils.events INFO:  eta: 0:13:49  iter: 3339  total_loss: 0.2675  loss_cls: 0.1159  loss_box_reg: 0.1509  time: 0.8807  last_time: 0.8768  data_time: 0.0593  last_data_time: 0.0584   lr: 0.01  max_mem: 21306M
[02/27 01:25:17] d2.utils.events INFO:  eta: 0:13:31  iter: 3359  total_loss: 0.2667  loss_cls: 0.1102  loss_box_reg: 0.1536  time: 0.8807  last_time: 0.8713  data_time: 0.0587  last_data_time: 0.0521   lr: 0.01  max_mem: 21306M
[02/27 01:25:34] d2.utils.events INFO:  eta: 0:13:14  iter: 3379  total_loss: 0.2491  loss_cls: 0.1062  loss_box_reg: 0.1469  time: 0.8807  last_time: 0.8895  data_time: 0.0606  last_data_time: 0.0721   lr: 0.01  max_mem: 21306M
[02/27 01:25:52] d2.utils.events INFO:  eta: 0:12:56  iter: 3399  total_loss: 0.2531  loss_cls: 0.1091  loss_box_reg: 0.1442  time: 0.8806  last_time: 0.8757  data_time: 0.0636  last_data_time: 0.0575   lr: 0.01  max_mem: 21306M
[02/27 01:26:09] d2.utils.events INFO:  eta: 0:12:38  iter: 3419  total_loss: 0.2593  loss_cls: 0.1104  loss_box_reg: 0.1483  time: 0.8806  last_time: 0.8219  data_time: 0.0616  last_data_time: 0.0510   lr: 0.01  max_mem: 21306M
[02/27 01:26:27] d2.utils.events INFO:  eta: 0:12:21  iter: 3439  total_loss: 0.2577  loss_cls: 0.1086  loss_box_reg: 0.1489  time: 0.8806  last_time: 0.8741  data_time: 0.0604  last_data_time: 0.0546   lr: 0.01  max_mem: 21306M
[02/27 01:26:44] d2.utils.events INFO:  eta: 0:12:03  iter: 3459  total_loss: 0.2575  loss_cls: 0.1085  loss_box_reg: 0.1459  time: 0.8805  last_time: 0.8662  data_time: 0.0597  last_data_time: 0.0476   lr: 0.01  max_mem: 21306M
[02/27 01:27:02] d2.utils.events INFO:  eta: 0:11:46  iter: 3479  total_loss: 0.2528  loss_cls: 0.1066  loss_box_reg: 0.1462  time: 0.8805  last_time: 0.8826  data_time: 0.0634  last_data_time: 0.0637   lr: 0.01  max_mem: 21306M
[02/27 01:27:19] d2.utils.events INFO:  eta: 0:11:28  iter: 3499  total_loss: 0.2511  loss_cls: 0.108  loss_box_reg: 0.1426  time: 0.8805  last_time: 0.8791  data_time: 0.0611  last_data_time: 0.0609   lr: 0.01  max_mem: 21306M
[02/27 01:27:37] d2.utils.events INFO:  eta: 0:11:11  iter: 3519  total_loss: 0.2533  loss_cls: 0.1062  loss_box_reg: 0.146  time: 0.8805  last_time: 0.8840  data_time: 0.0643  last_data_time: 0.0651   lr: 0.01  max_mem: 21306M
[02/27 01:27:55] d2.utils.events INFO:  eta: 0:10:53  iter: 3539  total_loss: 0.2602  loss_cls: 0.1099  loss_box_reg: 0.1482  time: 0.8805  last_time: 0.8846  data_time: 0.0627  last_data_time: 0.0650   lr: 0.01  max_mem: 21306M
[02/27 01:28:12] d2.utils.events INFO:  eta: 0:10:35  iter: 3559  total_loss: 0.2612  loss_cls: 0.1106  loss_box_reg: 0.1496  time: 0.8805  last_time: 0.8831  data_time: 0.0628  last_data_time: 0.0645   lr: 0.01  max_mem: 21306M
[02/27 01:28:30] d2.utils.events INFO:  eta: 0:10:18  iter: 3579  total_loss: 0.2513  loss_cls: 0.1063  loss_box_reg: 0.1457  time: 0.8805  last_time: 0.8850  data_time: 0.0608  last_data_time: 0.0673   lr: 0.01  max_mem: 21306M
[02/27 01:28:47] d2.utils.events INFO:  eta: 0:10:00  iter: 3599  total_loss: 0.2488  loss_cls: 0.1062  loss_box_reg: 0.1434  time: 0.8804  last_time: 0.8827  data_time: 0.0601  last_data_time: 0.0644   lr: 0.01  max_mem: 21306M
[02/27 01:29:05] d2.utils.events INFO:  eta: 0:09:43  iter: 3619  total_loss: 0.2519  loss_cls: 0.1079  loss_box_reg: 0.1444  time: 0.8804  last_time: 0.8842  data_time: 0.0612  last_data_time: 0.0649   lr: 0.01  max_mem: 21306M
[02/27 01:29:22] d2.utils.events INFO:  eta: 0:09:25  iter: 3639  total_loss: 0.2422  loss_cls: 0.1055  loss_box_reg: 0.1413  time: 0.8804  last_time: 0.8672  data_time: 0.0606  last_data_time: 0.0489   lr: 0.01  max_mem: 21306M
[02/27 01:29:40] d2.utils.events INFO:  eta: 0:09:07  iter: 3659  total_loss: 0.2534  loss_cls: 0.1051  loss_box_reg: 0.1482  time: 0.8804  last_time: 0.8957  data_time: 0.0643  last_data_time: 0.0771   lr: 0.01  max_mem: 21306M
[02/27 01:29:58] d2.utils.events INFO:  eta: 0:08:50  iter: 3679  total_loss: 0.2512  loss_cls: 0.106  loss_box_reg: 0.1436  time: 0.8804  last_time: 0.8884  data_time: 0.0628  last_data_time: 0.0695   lr: 0.01  max_mem: 21306M
[02/27 01:30:15] d2.utils.events INFO:  eta: 0:08:32  iter: 3699  total_loss: 0.2427  loss_cls: 0.1029  loss_box_reg: 0.1394  time: 0.8804  last_time: 0.8912  data_time: 0.0601  last_data_time: 0.0721   lr: 0.01  max_mem: 21306M
[02/27 01:30:33] d2.utils.events INFO:  eta: 0:08:15  iter: 3719  total_loss: 0.2445  loss_cls: 0.1045  loss_box_reg: 0.1438  time: 0.8804  last_time: 0.8811  data_time: 0.0619  last_data_time: 0.0627   lr: 0.01  max_mem: 21306M
[02/27 01:30:50] d2.utils.events INFO:  eta: 0:07:57  iter: 3739  total_loss: 0.2489  loss_cls: 0.105  loss_box_reg: 0.1441  time: 0.8803  last_time: 0.8757  data_time: 0.0583  last_data_time: 0.0568   lr: 0.01  max_mem: 21306M
[02/27 01:31:08] d2.utils.events INFO:  eta: 0:07:39  iter: 3759  total_loss: 0.2455  loss_cls: 0.103  loss_box_reg: 0.1433  time: 0.8803  last_time: 0.8770  data_time: 0.0588  last_data_time: 0.0576   lr: 0.01  max_mem: 21306M
[02/27 01:31:25] d2.utils.events INFO:  eta: 0:07:22  iter: 3779  total_loss: 0.2573  loss_cls: 0.1073  loss_box_reg: 0.1503  time: 0.8802  last_time: 0.8873  data_time: 0.0603  last_data_time: 0.0660   lr: 0.01  max_mem: 21306M
[02/27 01:31:43] d2.utils.events INFO:  eta: 0:07:04  iter: 3799  total_loss: 0.2452  loss_cls: 0.1011  loss_box_reg: 0.1431  time: 0.8802  last_time: 0.8769  data_time: 0.0579  last_data_time: 0.0593   lr: 0.01  max_mem: 21306M
[02/27 01:32:00] d2.utils.events INFO:  eta: 0:06:47  iter: 3819  total_loss: 0.2371  loss_cls: 0.09997  loss_box_reg: 0.1373  time: 0.8802  last_time: 0.8736  data_time: 0.0590  last_data_time: 0.0551   lr: 0.01  max_mem: 21306M
[02/27 01:32:17] d2.utils.events INFO:  eta: 0:06:29  iter: 3839  total_loss: 0.2386  loss_cls: 0.0987  loss_box_reg: 0.1404  time: 0.8801  last_time: 0.8784  data_time: 0.0595  last_data_time: 0.0599   lr: 0.01  max_mem: 21306M
[02/27 01:32:35] d2.utils.events INFO:  eta: 0:06:11  iter: 3859  total_loss: 0.2472  loss_cls: 0.1035  loss_box_reg: 0.1437  time: 0.8801  last_time: 0.8832  data_time: 0.0618  last_data_time: 0.0654   lr: 0.01  max_mem: 21306M
[02/27 01:32:53] d2.utils.events INFO:  eta: 0:05:54  iter: 3879  total_loss: 0.2432  loss_cls: 0.1008  loss_box_reg: 0.1401  time: 0.8801  last_time: 0.8359  data_time: 0.0600  last_data_time: 0.0635   lr: 0.01  max_mem: 21306M
[02/27 01:33:10] d2.utils.events INFO:  eta: 0:05:36  iter: 3899  total_loss: 0.2556  loss_cls: 0.1074  loss_box_reg: 0.1495  time: 0.8801  last_time: 0.8345  data_time: 0.0631  last_data_time: 0.0638   lr: 0.01  max_mem: 21306M
[02/27 01:33:28] d2.utils.events INFO:  eta: 0:05:19  iter: 3919  total_loss: 0.2441  loss_cls: 0.1023  loss_box_reg: 0.1434  time: 0.8801  last_time: 0.8832  data_time: 0.0610  last_data_time: 0.0645   lr: 0.01  max_mem: 21306M
[02/27 01:33:45] d2.utils.events INFO:  eta: 0:05:01  iter: 3939  total_loss: 0.2455  loss_cls: 0.1018  loss_box_reg: 0.1418  time: 0.8800  last_time: 0.8885  data_time: 0.0616  last_data_time: 0.0692   lr: 0.01  max_mem: 21306M
[02/27 01:34:03] d2.utils.events INFO:  eta: 0:04:44  iter: 3959  total_loss: 0.2407  loss_cls: 0.09719  loss_box_reg: 0.1409  time: 0.8800  last_time: 0.8761  data_time: 0.0601  last_data_time: 0.0574   lr: 0.01  max_mem: 21306M
[02/27 01:34:20] d2.utils.events INFO:  eta: 0:04:26  iter: 3979  total_loss: 0.2442  loss_cls: 0.09803  loss_box_reg: 0.1434  time: 0.8800  last_time: 0.8877  data_time: 0.0618  last_data_time: 0.0692   lr: 0.01  max_mem: 21306M
[02/27 01:34:37] d2.utils.events INFO:  eta: 0:04:08  iter: 3999  total_loss: 0.2432  loss_cls: 0.1014  loss_box_reg: 0.1419  time: 0.8799  last_time: 0.8799  data_time: 0.0606  last_data_time: 0.0603   lr: 0.01  max_mem: 21306M
[02/27 01:34:55] d2.utils.events INFO:  eta: 0:03:51  iter: 4019  total_loss: 0.2432  loss_cls: 0.09876  loss_box_reg: 0.1424  time: 0.8798  last_time: 0.8198  data_time: 0.0602  last_data_time: 0.0481   lr: 0.01  max_mem: 21306M
[02/27 01:35:12] d2.utils.events INFO:  eta: 0:03:33  iter: 4039  total_loss: 0.2407  loss_cls: 0.101  loss_box_reg: 0.1412  time: 0.8798  last_time: 0.8954  data_time: 0.0616  last_data_time: 0.0767   lr: 0.01  max_mem: 21306M
[02/27 01:35:30] d2.utils.events INFO:  eta: 0:03:16  iter: 4059  total_loss: 0.2455  loss_cls: 0.1007  loss_box_reg: 0.145  time: 0.8798  last_time: 0.8869  data_time: 0.0637  last_data_time: 0.0680   lr: 0.01  max_mem: 21306M
[02/27 01:35:47] d2.utils.events INFO:  eta: 0:02:58  iter: 4079  total_loss: 0.2472  loss_cls: 0.1032  loss_box_reg: 0.1435  time: 0.8798  last_time: 0.8753  data_time: 0.0605  last_data_time: 0.0570   lr: 0.01  max_mem: 21306M
[02/27 01:36:05] d2.utils.events INFO:  eta: 0:02:40  iter: 4099  total_loss: 0.2423  loss_cls: 0.1018  loss_box_reg: 0.1426  time: 0.8798  last_time: 0.8748  data_time: 0.0607  last_data_time: 0.0566   lr: 0.01  max_mem: 21306M
[02/27 01:36:22] d2.utils.events INFO:  eta: 0:02:23  iter: 4119  total_loss: 0.2371  loss_cls: 0.09736  loss_box_reg: 0.1397  time: 0.8797  last_time: 0.8378  data_time: 0.0598  last_data_time: 0.0668   lr: 0.01  max_mem: 21306M
[02/27 01:36:40] d2.utils.events INFO:  eta: 0:02:05  iter: 4139  total_loss: 0.2313  loss_cls: 0.09366  loss_box_reg: 0.1378  time: 0.8797  last_time: 0.8854  data_time: 0.0618  last_data_time: 0.0667   lr: 0.01  max_mem: 21306M
[02/27 01:36:57] d2.utils.events INFO:  eta: 0:01:48  iter: 4159  total_loss: 0.2473  loss_cls: 0.1004  loss_box_reg: 0.1431  time: 0.8797  last_time: 0.8769  data_time: 0.0601  last_data_time: 0.0583   lr: 0.01  max_mem: 21306M
[02/27 01:37:15] d2.utils.events INFO:  eta: 0:01:30  iter: 4179  total_loss: 0.2365  loss_cls: 0.09906  loss_box_reg: 0.1384  time: 0.8797  last_time: 0.8230  data_time: 0.0584  last_data_time: 0.0526   lr: 0.01  max_mem: 21306M
[02/27 01:37:32] d2.utils.events INFO:  eta: 0:01:12  iter: 4199  total_loss: 0.2343  loss_cls: 0.0949  loss_box_reg: 0.1387  time: 0.8796  last_time: 0.8471  data_time: 0.0606  last_data_time: 0.0755   lr: 0.01  max_mem: 21306M
[02/27 01:37:50] d2.utils.events INFO:  eta: 0:00:55  iter: 4219  total_loss: 0.2323  loss_cls: 0.09602  loss_box_reg: 0.1358  time: 0.8796  last_time: 0.8824  data_time: 0.0631  last_data_time: 0.0643   lr: 0.01  max_mem: 21306M
[02/27 01:38:08] d2.utils.events INFO:  eta: 0:00:37  iter: 4239  total_loss: 0.2308  loss_cls: 0.09406  loss_box_reg: 0.1379  time: 0.8797  last_time: 0.8670  data_time: 0.0632  last_data_time: 0.0489   lr: 0.01  max_mem: 21306M
[02/27 01:38:25] d2.utils.events INFO:  eta: 0:00:20  iter: 4259  total_loss: 0.2301  loss_cls: 0.09246  loss_box_reg: 0.1361  time: 0.8796  last_time: 0.8757  data_time: 0.0610  last_data_time: 0.0575   lr: 0.01  max_mem: 21306M
[02/27 01:38:43] d2.utils.events INFO:  eta: 0:00:02  iter: 4279  total_loss: 0.2364  loss_cls: 0.09719  loss_box_reg: 0.1395  time: 0.8797  last_time: 0.8822  data_time: 0.0653  last_data_time: 0.0641   lr: 0.01  max_mem: 21306M
[02/27 01:38:44] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0004280.pth
[02/27 01:38:46] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_final.pth
[02/27 01:38:47] d2.utils.events INFO:  eta: 0:00:00  iter: 4282  total_loss: 0.2351  loss_cls: 0.09697  loss_box_reg: 0.1386  time: 0.8797  last_time: 0.8856  data_time: 0.0669  last_data_time: 0.0656   lr: 0.01  max_mem: 21306M
[02/27 01:38:47] d2.engine.hooks INFO: Overall training speed: 4281 iterations in 1:02:45 (0.8797 s / it)
[02/27 01:38:47] d2.engine.hooks INFO: Total training time: 1:03:01 (0:00:15 on hooks)
[02/27 01:38:47] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/27 01:38:47] d2.data.datasets.coco INFO: Loaded 160 images in COCO format from /media/nahyun/HDD//data_100/instances_test.json
[02/27 01:38:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/27 01:38:47] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/27 01:38:47] d2.data.common INFO: Serializing 160 elements to byte tensors and concatenating them all ...
[02/27 01:38:47] d2.data.common INFO: Serialized dataset takes 0.44 MiB
[02/27 01:38:47] d2.evaluation.evaluator INFO: Start inference on 160 batches
[02/27 01:38:48] d2.evaluation.evaluator INFO: Inference done 11/160. Dataloading: 0.0004 s/iter. Inference: 0.0289 s/iter. Eval: 0.0003 s/iter. Total: 0.0296 s/iter. ETA=0:00:04
[02/27 01:38:52] d2.evaluation.evaluator INFO: Total inference time: 0:00:04.669074 (0.030123 s / iter per device, on 1 devices)
[02/27 01:38:52] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.028994 s / iter per device, on 1 devices)
[02/27 01:38:52] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[02/27 01:38:52] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[02/27 01:38:52] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[02/27 01:38:52] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[02/27 01:38:53] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.24 seconds.
[02/27 01:38:53] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[02/27 01:38:53] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.11 seconds.
[02/27 01:38:53] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.778 | 24.539 | 15.880 | 7.445 | 23.998 | 25.159 |
[02/27 01:38:53] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category                   | AP     | category                     | AP     | category                     | AP     |
|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|
| 000_aveda_shampoo          | 15.813 | 001_binder_clips_median      | 26.478 | 002_binder_clips_small       | 14.863 |
| 003_bombik_bucket          | 14.354 | 004_bonne_maman_blueberry    | 0.278  | 005_bonne_maman_raspberry    | 0.574  |
| 006_bonne_maman_strawberry | 0.277  | 007_costa_caramel            | 29.450 | 008_essential_oil_bergamot   | 22.665 |
| 009_garlic_toast_spread    | 4.168  | 010_handcream_avocado        | 3.443  | 011_hb_calcium               | 16.902 |
| 012_hb_grapeseed           | 10.769 | 013_hb_marine_collagen       | 9.246  | 014_hellmanns_mayonnaise     | 7.961  |
| 015_illy_blend             | 3.805  | 016_japanese_finger_cookies  | 3.989  | 017_john_west_canned_tuna    | 11.988 |
| 018_kerastase_shampoo      | 8.972  | 019_kiehls_facial_cream      | 30.267 | 020_kiihne_balsamic          | 0.440  |
| 021_kiihne_honey_mustard   | 18.138 | 022_lindor_matcha            | 23.989 | 023_lindor_salted_caramel    | 29.574 |
| 024_lush_mask              | 73.379 | 025_pasta_sauce_black_pepper | 0.125  | 026_pasta_sauce_tomato       | 8.451  |
| 027_pepsi                  | 48.998 | 028_portable_yogurt_machine  | 0.264  | 029_selfile_stick            | 4.192  |
| 030_sour_lemon_drops       | 5.537  | 031_sticky_notes             | 17.898 | 032_stridex_green            | 45.699 |
| 033_thermos_flask_cream    | 43.049 | 034_thermos_flask_muji       | 1.987  | 035_thermos_flask_sliver     | 0.379  |
| 036_tragata_olive_oil      | 0.458  | 037_tulip_luncheon_meat      | 8.538  | 038_unicharm_cotton_pad      | 40.680 |
| 039_vinda_tissue           | 34.330 | 040_wrigley_doublemint_gum   | 0.645  | 041_baseball_cap_black       | 9.149  |
| 042_baseball_cap_pink      | 17.838 | 043_bfe_facial_mask          | 25.720 | 044_corgi_doll               | 7.244  |
| 045_dinosaur_doll          | 26.310 | 046_geo_mocha                | 11.176 | 047_geo_roast_charcoal       | 4.758  |
| 048_instant_noodle_black   | 6.587  | 049_instant_noodle_red       | 26.187 | 050_nabati_cheese_wafer      | 36.757 |
| 051_truffettes             | 9.021  | 052_acnes_cream              | 18.408 | 053_aveda_conditioner        | 19.593 |
| 054_banana_milk_drink      | 8.344  | 055_candle_beast             | 30.903 | 056_china_persimmon          | 15.342 |
| 057_danisa_butter_cookies  | 3.184  | 058_effaclar_duo             | 5.446  | 059_evelom_cleanser          | 21.179 |
| 060_glasses_box_blone      | 20.268 | 061_handcream_iris           | 0.225  | 062_handcream_lavender       | 0.000  |
| 063_handcream_rosewater    | 3.074  | 064_handcream_summer_hill    | 0.054  | 065_hr_serum                 | 2.913  |
| 066_japanese_chocolate     | 33.408 | 067_kerastase_hair_treatment | 8.065  | 068_kiehls_serum             | 17.114 |
| 069_korean_beef_marinade   | 19.244 | 070_korean_doenjang          | 19.318 | 071_korean_gochujang         | 0.188  |
| 072_korean_ssamjang        | 10.449 | 073_loccitane_soap           | 20.407 | 074_marvis_toothpaste_purple | 47.591 |
| 075_mouse_thinkpad         | 3.568  | 076_oatly_chocolate          | 12.754 | 077_oatly_original           | 20.664 |
| 078_ousa_grated_cheese     | 6.801  | 079_polaroid_film            | 0.495  | 080_skinceuticals_be         | 53.364 |
| 081_skinceuticals_cf       | 19.941 | 082_skinceuticals_phyto      | 16.683 | 083_stapler_black            | 8.524  |
| 084_stapler_blue           | 13.493 | 085_sunscreen_blue           | 0.068  | 086_tempo_pocket_tissue      | 1.478  |
| 087_thermos_flask_purple   | 30.337 | 088_uha_matcha               | 9.762  | 089_urban_decay_spray        | 12.156 |
| 090_vitaboost_multivitamin | 2.968  | 091_watercolor_penbox        | 0.081  | 092_youthlt_bilberry_complex | 0.000  |
| 093_daiso_mod_remover      | 16.554 | 094_kaneyo_kitchen_bleach    | 27.497 | 095_lays_chip_bag_blue       | 15.348 |
| 096_lays_chip_bag_green    | 10.578 | 097_lays_chip_tube_auburn    | 13.107 | 098_lays_chip_tube_green     | 33.086 |
| 099_mug_blue               | 0.000  |                              |        |                              |        |
[02/27 01:38:53] d2.engine.defaults INFO: Evaluation results for retinanet_test in csv format:
[02/27 01:38:53] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 01:38:53] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[02/27 01:38:53] d2.evaluation.testing INFO: copypaste: 14.7778,24.5391,15.8797,7.4451,23.9982,25.1589
[02/27 23:32:51] detectron2 INFO: Rank of current process: 0. World size: 1
[02/27 23:32:51] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
numpy                   1.24.2
detectron2              0.6 @/home/nahyun/.local/lib/python3.10/site-packages/detectron2
Compiler                GCC 11.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3080 Ti (arch=8.6)
Driver version          525.78.01
CUDA_HOME               None - invalid!
Pillow                  9.0.1
torchvision             0.14.1+cu117 @/home/nahyun/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  /home/nahyun/.local/lib/python3.10/site-packages/torchvision/_C.so
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[02/27 23:32:51] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[02/27 23:32:51] detectron2 INFO: Contents of args.config_file=../configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:
_BASE_: "../Base-RetinaNet.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[02/27 23:32:51] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/27 23:32:51] detectron2 INFO: Full config saved to ./output/config.yaml
[02/27 23:32:51] d2.utils.env INFO: Using a generated random seed 53536247
[02/27 23:32:52] d2.engine.defaults INFO: Model:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 900, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[02/27 23:32:54] d2.data.datasets.coco INFO: Loading /media/nahyun/HDD//data_100/instances_train.json takes 2.13 seconds.
[02/27 23:32:54] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[02/27 23:32:54] d2.data.datasets.coco INFO: Loaded 19191 images in COCO format from /media/nahyun/HDD//data_100/instances_train.json
[02/27 23:32:56] d2.data.build INFO: Removed 0 images with no usable annotations. 19191 images left.
[02/27 23:32:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/27 23:32:56] d2.data.build INFO: Using training sampler TrainingSampler
[02/27 23:32:56] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/27 23:32:56] d2.data.common INFO: Serializing 19191 elements to byte tensors and concatenating them all ...
[02/27 23:32:56] d2.data.common INFO: Serialized dataset takes 80.55 MiB
[02/27 23:32:56] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/27 23:32:56] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[02/27 23:32:56] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/nahyun/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[02/27 23:32:56] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/27 23:32:56] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[02/27 23:32:56] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[02/27 23:32:56] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[02/27 23:32:56] d2.engine.train_loop INFO: Starting training from iteration 0
[02/27 23:33:16] d2.utils.events INFO:  eta: 1:01:43  iter: 19  total_loss: 2.725  loss_cls: 1.701  loss_box_reg: 1.024  time: 0.9067  last_time: 0.8619  data_time: 0.0673  last_data_time: 0.0505   lr: 0.00019981  max_mem: 21012M
[02/27 23:33:19] d2.engine.hooks INFO: Overall training speed: 21 iterations in 0:00:19 (0.9438 s / it)
[02/27 23:33:19] d2.engine.hooks INFO: Total training time: 0:00:19 (0:00:00 on hooks)
[02/27 23:33:19] d2.utils.events INFO:  eta: 1:01:43  iter: 23  total_loss: 2.454  loss_cls: 1.538  loss_box_reg: 0.9208  time: 0.9015  last_time: 0.8750  data_time: 0.0614  last_data_time: 0.0657   lr: 0.00022978  max_mem: 21012M
